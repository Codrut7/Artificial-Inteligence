{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DarkNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DarkNet, self).__init__()\n",
    "        self.stride = 1\n",
    "        self.pad = 1\n",
    "        \n",
    "        self.max_pool_kernel_size = 2\n",
    "        self.max_pool_stride = 2\n",
    "        \n",
    "        # Activation function\n",
    "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
    "        # Maxpool functions\n",
    "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
    "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1, 1, 2)\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
    "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
    "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
    "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
    "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
    "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
    "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
    "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
    "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        \n",
    "        x = self.conv_1(inp)\n",
    "        x = self.batch_norm_1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = self.batch_norm_2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        \n",
    "        x = self.conv_3(x)\n",
    "        x = self.batch_norm_3(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool_1(x)\n",
    "\n",
    "        x = self.conv_4(x)\n",
    "        x = self.batch_norm_4(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        \n",
    "        x = self.conv_5(x)\n",
    "        x = self.batch_norm_5(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool_1(x)\n",
    "        \n",
    "        x = self.conv_6(x)\n",
    "        x = self.batch_norm_6(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.maxpool_2(x)\n",
    "\n",
    "        x = self.conv_7(x)\n",
    "        x = self.batch_norm_7(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        x = self.conv_8(x)\n",
    "        x = self.batch_norm_8(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        x = self.conv_9(x)\n",
    "\n",
    "        return x.reshape(x.shape[0], 5, x.shape[3], x.shape[3], 25).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 13, 13, 25])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#net = DarkNet()\n",
    "#net(torch.FloatTensor(1, 3, 416 ,416)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class WeightLoader(object):\n",
    "    def __init__(self):\n",
    "        super(WeightLoader, self).__init__()\n",
    "        self.start = 0\n",
    "        self.buf = None\n",
    "\n",
    "    def load_conv_bn(self, conv_model, bn_model):\n",
    "        num_w = conv_model.weight.numel()\n",
    "        num_b = bn_model.bias.numel()\n",
    "        bn_model.bias.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "        self.start = self.start + num_b\n",
    "        bn_model.weight.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "        self.start = self.start + num_b\n",
    "        bn_model.running_mean.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "        self.start = self.start + num_b\n",
    "        bn_model.running_var.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), bn_model.bias.size()))\n",
    "        self.start = self.start + num_b\n",
    "        conv_model.weight.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_w]), conv_model.weight.size()))\n",
    "        self.start = self.start + num_w\n",
    "\n",
    "    def load_conv(self, conv_model):\n",
    "        num_w = conv_model.weight.numel()\n",
    "        num_b = conv_model.bias.numel()\n",
    "        conv_model.bias.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_b]), conv_model.bias.size()))\n",
    "        self.start = self.start + num_b\n",
    "        conv_model.weight.data.copy_(\n",
    "            torch.reshape(torch.from_numpy(self.buf[self.start:self.start + num_w]), conv_model.weight.size()))\n",
    "        self.start = self.start + num_w\n",
    "\n",
    "    def dfs(self, m):\n",
    "        print(m)\n",
    "        children = list(m.children())\n",
    "        for i, c in enumerate(children):\n",
    "            if isinstance(c, torch.nn.Sequential):\n",
    "                self.dfs(c)\n",
    "            elif isinstance(c, torch.nn.Conv2d):\n",
    "                if c.bias is not None:\n",
    "                    self.load_conv(c)\n",
    "                else:\n",
    "                    self.load_conv_bn(c, children[i + 1])\n",
    "\n",
    "    def load(self, model, weights_file):\n",
    "        self.start = 0\n",
    "        fp = open(weights_file, 'rb')\n",
    "        header = np.fromfile(fp, count=4, dtype=np.int32)\n",
    "        self.buf = np.fromfile(fp, dtype=np.float32)\n",
    "        fp.close()\n",
    "        size = self.buf.size\n",
    "        self.dfs(model)\n",
    "\n",
    "        # make sure the loaded weight is right\n",
    "        assert size == self.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(weights_file, model):\n",
    "    weight_loader = WeightLoader()\n",
    "    weight_loader.load(model, weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import torch.nn as nn\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import optim\n",
      "import torch.nn.functional as F\n",
      "from tqdm import tqdm_notebook\n",
      "\n",
      "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "class ReorgLayer(nn.Module):\n",
      "    def __init__(self, stride=2):\n",
      "        super(ReorgLayer, self).__init__()\n",
      "        self.stride = stride\n",
      "\n",
      "    def forward(self, x):\n",
      "        B, C, H, W = x.data.size()\n",
      "        ws = self.stride\n",
      "        hs = self.stride\n",
      "        x = x.view(B, C, int(H / hs), hs, int(W / ws), ws).transpose(3, 4).contiguous()\n",
      "        x = x.view(B, C, int(H / hs * W / ws), hs * ws).transpose(2, 3).contiguous()\n",
      "        x = x.view(B, C, hs * ws, int(H / hs), int(W / ws)).transpose(1, 2).contiguous()\n",
      "        x = x.view(B, hs * ws * C, int(H / hs), int(W / ws))\n",
      "        return x\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1, 1, 2)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 2)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1, 1, 2)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 1)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1, 1, 2)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "import torch.nn as nn\n",
      "import numpy as np\n",
      "import torch\n",
      "from torch import optim\n",
      "import torch.nn.functional as F\n",
      "from tqdm import tqdm_notebook\n",
      "\n",
      "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
      "class ReorgLayer(nn.Module):\n",
      "    def __init__(self, stride=2):\n",
      "        super(ReorgLayer, self).__init__()\n",
      "        self.stride = stride\n",
      "\n",
      "    def forward(self, x):\n",
      "        B, C, H, W = x.data.size()\n",
      "        ws = self.stride\n",
      "        hs = self.stride\n",
      "        x = x.view(B, C, int(H / hs), hs, int(W / ws), ws).transpose(3, 4).contiguous()\n",
      "        x = x.view(B, C, int(H / hs * W / ws), hs * ws).transpose(2, 3).contiguous()\n",
      "        x = x.view(B, C, hs * ws, int(H / hs), int(W / ws)).transpose(1, 2).contiguous()\n",
      "        x = x.view(B, hs * ws * C, int(H / hs), int(W / ws))\n",
      "        return x\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 2)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 1)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 1, 2)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 1, 1)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 1, 0)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 2, 2)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 1, 2)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 1, 4)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 2, 1)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 1, 1, 2)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 1, 1, 1)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 1, 2, 2)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride, 1, 2, 1)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "class DarkNet(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(DarkNet, self).__init__()\n",
      "        self.stride = 1\n",
      "        self.pad = 1\n",
      "        \n",
      "        self.max_pool_kernel_size = 2\n",
      "        self.max_pool_stride = 2\n",
      "        \n",
      "        # Activation function\n",
      "        self.activation = nn.LeakyReLU(0.1, inplace=True)\n",
      "        # Maxpool functions\n",
      "        self.maxpool_1 = nn.MaxPool2d(self.max_pool_kernel_size, self.max_pool_stride)\n",
      "        self.maxpool_2 = nn.MaxPool2d(self.max_pool_kernel_size, 1, 1, 2)\n",
      "        \n",
      "        self.conv_1 = nn.Conv2d(3, 16, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_1 = nn.BatchNorm2d(16)\n",
      "        \n",
      "        self.conv_2 = nn.Conv2d(16, 32, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_2 = nn.BatchNorm2d(32)\n",
      "        \n",
      "        self.conv_3 = nn.Conv2d(32, 64, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_3 = nn.BatchNorm2d(64)\n",
      "        \n",
      "        self.conv_4 = nn.Conv2d(64, 128, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_4 = nn.BatchNorm2d(128)\n",
      "        \n",
      "        self.conv_5 = nn.Conv2d(128, 256, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_5 = nn.BatchNorm2d(256)\n",
      "        \n",
      "        self.conv_6 = nn.Conv2d(256, 512, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_6 = nn.BatchNorm2d(512)\n",
      "        \n",
      "        self.conv_7 = nn.Conv2d(512, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_7 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_8 = nn.Conv2d(1024, 1024, 3, self.stride, self.pad, bias=False)\n",
      "        self.batch_norm_8 = nn.BatchNorm2d(1024)\n",
      "        \n",
      "        self.conv_9 = nn.Conv2d(1024, 125, 1, self.stride)\n",
      "        \n",
      "    def forward(self, inp):\n",
      "        \n",
      "        x = self.conv_1(inp)\n",
      "        x = self.batch_norm_1(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_2(x)\n",
      "        x = self.batch_norm_2(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_3(x)\n",
      "        x = self.batch_norm_3(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "\n",
      "        x = self.conv_4(x)\n",
      "        x = self.batch_norm_4(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_5(x)\n",
      "        x = self.batch_norm_5(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_1(x)\n",
      "        \n",
      "        x = self.conv_6(x)\n",
      "        x = self.batch_norm_6(x)\n",
      "        x = self.activation(x)\n",
      "        x = self.maxpool_2(x)\n",
      "\n",
      "        x = self.conv_7(x)\n",
      "        x = self.batch_norm_7(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_8(x)\n",
      "        x = self.batch_norm_8(x)\n",
      "        x = self.activation(x)\n",
      "\n",
      "        x = self.conv_9(x)\n",
      "\n",
      "        return x.reshape(x.shape[0], 25*5, x.shape[3], x.shape[3]).contiguous()\n",
      "net = DarkNet()\n",
      "net(torch.FloatTensor(1, 3, 416 ,416)).shape\n",
      "%history\n"
     ]
    }
   ],
   "source": [
    "%history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
