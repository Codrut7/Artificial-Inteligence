{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from dark_net.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import dark_net\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import math\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classes(namesfile):\n",
    "    fp = open(namesfile, \"r\")\n",
    "    names = fp.read().split(\"\\n\")[:-1]\n",
    "    return names\n",
    "\n",
    "classes = load_classes(os.path.join(os.getcwd(), 'coco.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = dark_net.Darknet(os.path.join(os.getcwd(), 'yolov3.txt')).cuda()\n",
    "net.load_weights('yolov3.weights')\n",
    "net.eval()\n",
    "test_batch = torch.FloatTensor(1, 3, 608, 608).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(tensor):\n",
    "    tensor_np = tensor.cpu().numpy()\n",
    "    unique_np = np.unique(tensor_np)\n",
    "    unique_tensor = torch.from_numpy(unique_np)\n",
    "    \n",
    "    tensor_res = tensor.new(unique_tensor.shape)\n",
    "    tensor_res.copy_(unique_tensor)\n",
    "    return tensor_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Returns the IoU of two bounding boxes \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #Get the coordinates of bounding boxes\n",
    "    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:,0], box1[:,1], box1[:,2], box1[:,3]\n",
    "    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:,0], box2[:,1], box2[:,2], box2[:,3]\n",
    "    \n",
    "    #get the corrdinates of the intersection rectangle\n",
    "    inter_rect_x1 =  torch.max(b1_x1, b2_x1)\n",
    "    inter_rect_y1 =  torch.max(b1_y1, b2_y1)\n",
    "    inter_rect_x2 =  torch.min(b1_x2, b2_x2)\n",
    "    inter_rect_y2 =  torch.min(b1_y2, b2_y2)\n",
    "    \n",
    "    #Intersection area\n",
    "    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)\n",
    "\n",
    "    #Union Area\n",
    "    b1_area = (b1_x2 - b1_x1 + 1)*(b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1)*(b2_y2 - b2_y1 + 1)\n",
    "    \n",
    "    iou = inter_area / (b1_area + b2_area - inter_area)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(prediction, confidence=0.5, num_classes=80, nms_conf=0.4):\n",
    "    \n",
    "    # [B, num_anchors * grid * grid]\n",
    "    conf_mask = (prediction[:, :, 4] > confidence).float().unsqueeze(2)\n",
    "    prediction = prediction * conf_mask\n",
    "    \n",
    "    box_corner = prediction.new(prediction.shape)\n",
    "    box_corner[:,:,0] = (prediction[:,:,0] - prediction[:,:,2]/2)\n",
    "    box_corner[:,:,1] = (prediction[:,:,1] - prediction[:,:,3]/2)\n",
    "    box_corner[:,:,2] = (prediction[:,:,0] + prediction[:,:,2]/2) \n",
    "    box_corner[:,:,3] = (prediction[:,:,1] + prediction[:,:,3]/2)\n",
    "    prediction[:,:,:4] = box_corner[:,:,:4]\n",
    "    \n",
    "    batch_size = prediction.size(0)\n",
    "    write = False\n",
    "    \n",
    "    for ind in range(batch_size):\n",
    "        image_pred = prediction[ind]          #image Tensor\n",
    "        #confidence threshholding \n",
    "        #NMS\n",
    "\n",
    "        max_conf, max_conf_score = torch.max(image_pred[:,5:5+ num_classes], 1)\n",
    "        max_conf = max_conf.float().unsqueeze(1)\n",
    "        max_conf_score = max_conf_score.float().unsqueeze(1)\n",
    "        seq = (image_pred[:,:5], max_conf, max_conf_score)\n",
    "        image_pred = torch.cat(seq, 1)\n",
    "\n",
    "        non_zero_ind =  (torch.nonzero(image_pred[:,4]))\n",
    "        try:\n",
    "            image_pred_ = image_pred[non_zero_ind.squeeze(),:].view(-1,7)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if image_pred_.shape[0] == 0:\n",
    "            continue       \n",
    "        \n",
    "        # [grids, (x, y, h, w, confidence, max_conf_class, max_conf_class_idx)]\n",
    "        \n",
    "        #Get the various classes detected in the image\n",
    "        img_classes = unique(image_pred_[:,-1])  # -1 index holds the class index\n",
    "        \n",
    "        for cls in img_classes:\n",
    "            #perform NMS\n",
    "\n",
    "        \n",
    "            #get the detections with one particular class\n",
    "            cls_mask = image_pred_*(image_pred_[:,-1] == cls).float().unsqueeze(1)\n",
    "            class_mask_ind = torch.nonzero(cls_mask[:,-2]).squeeze()\n",
    "            image_pred_class = image_pred_[class_mask_ind].view(-1,7)\n",
    "            \n",
    "            #sort the detections such that the entry with the maximum objectness\n",
    "            #confidence is at the top\n",
    "            conf_sort_index = torch.sort(image_pred_class[:,4], descending = True )[1]\n",
    "            image_pred_class = image_pred_class[conf_sort_index]\n",
    "            idx = image_pred_class.size(0)   #Number of detections\n",
    "            \n",
    "            for i in range(idx):\n",
    "                #Get the IOUs of all boxes that come after the one we are looking at \n",
    "                #in the loop\n",
    "                try:\n",
    "                    ious = bbox_iou(image_pred_class[i].unsqueeze(0), image_pred_class[i+1:])\n",
    "                except ValueError:\n",
    "                    break\n",
    "            \n",
    "                except IndexError:\n",
    "                    break\n",
    "            \n",
    "                #Zero out all the detections that have IoU > treshhold\n",
    "                iou_mask = (ious < nms_conf).float().unsqueeze(1)\n",
    "                image_pred_class[i+1:] *= iou_mask       \n",
    "            \n",
    "                #Remove the non-zero entries\n",
    "                non_zero_ind = torch.nonzero(image_pred_class[:,4]).squeeze()\n",
    "                image_pred_class = image_pred_class[non_zero_ind].view(-1,7)\n",
    "                \n",
    "            batch_ind = image_pred_class.new(image_pred_class.size(0), 1).fill_(ind)      #Repeat the batch_id for as many detections of the class cls in the image\n",
    "            seq = batch_ind, image_pred_class\n",
    "            \n",
    "            if not write:\n",
    "                output = torch.cat(seq,1)\n",
    "                write = True\n",
    "            else:\n",
    "                out = torch.cat(seq,1)\n",
    "                output = torch.cat((output,out))\n",
    "\n",
    "    try:\n",
    "        return output\n",
    "    except:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def preprocess_img(img, inp_dim):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    img_w, img_h = img.shape[1], img.shape[0]\n",
    "    w, h = inp_dim\n",
    "    new_w = int(img_w * min(w/img_w, h/img_h))\n",
    "    new_h = int(img_h * min(w/img_w, h/img_h))\n",
    "    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    # put a canvas of the NN input dimension\n",
    "    canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)\n",
    "    # Add the resized image to the canvas\n",
    "    canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,  :] = resized_image\n",
    "    \n",
    "    img = canvas[:,:,::-1].transpose((2,0,1)).copy()\n",
    "    img = torch.from_numpy(img).float().div(255.0).unsqueeze(0)\n",
    "    \n",
    "    return img, canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_grid(image, prediction):\n",
    "    \n",
    "    for obj in prediction:\n",
    "        \n",
    "        x_min = int(obj[1].item())\n",
    "        y_min = int(obj[2].item())\n",
    "        \n",
    "        x_max = int(obj[3].item())\n",
    "        y_max = int(obj[4].item())\n",
    "        \n",
    "        cls = int(obj[7].item())\n",
    "        \n",
    "        pos = (x_min - 15, y_min - 15) if x_min - 15 > 0 and y_min > 0 else (x_min, y_min)\n",
    "        image = cv2.putText(image, classes[cls], pos, cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0),2)\n",
    "        image = cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 1)\n",
    "    \n",
    "    return image\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img): \n",
    "    h, w, _ = img.shape\n",
    "    scaling_factor = min(608 / w,  608 / h)\n",
    "\n",
    "    copy_img = img.copy()\n",
    "    img, canvas = preprocess_img(img, (608, 608))\n",
    "\n",
    "    img = img.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = net(img, True)\n",
    "\n",
    "    results = post_process(predictions)\n",
    "\n",
    "    results[:, [1,3]] -= (608 - scaling_factor*w)/2\n",
    "    results[:, [2,4]] -= (608 - scaling_factor*h)/2\n",
    "    results[:, 1:5] /= scaling_factor\n",
    "    results[:, [1,3]] = torch.clamp(results[:, [1,3]], 0.0, w)\n",
    "    results[:, [2,4]] = torch.clamp(results[:, [2,4]], 0.0, h)\n",
    "\n",
    "\n",
    "    copy_img = draw_grid(copy_img, results)\n",
    "    return copy_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object and read from input file \n",
    "cap = cv2.VideoCapture('movie.mp4')\n",
    "\n",
    "# Check if camera opened successfully \n",
    "if (cap.isOpened()== False):  \n",
    "    print(\"Error opening video  file\") \n",
    "\n",
    "# Read until video is completed \n",
    "while(cap.isOpened()): \n",
    "      \n",
    "    # Capture frame-by-frame \n",
    "    ret, frame = cap.read() \n",
    "    if ret == True: \n",
    "\n",
    "        # Display the resulting frame \n",
    "        cv2.imshow('Frame', predict_image(frame)) \n",
    "        cv2.waitKey(0)\n",
    "        # Press Q on keyboard to  exit \n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "            break\n",
    "\n",
    "        # Break the loop \n",
    "        else:  \n",
    "            break\n",
    "\n",
    "    # When everything done, release  \n",
    "    # the video capture object \n",
    "    cap.release() \n",
    "\n",
    "    # Closes all the frames \n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
