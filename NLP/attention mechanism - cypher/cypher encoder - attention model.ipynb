{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import unicodedata\n",
    "import string\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import re\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([13,  7, 15, 15, 19, 14], device='cuda:0'),\n",
       " tensor([20,  5,  6,  7, 19,  7,  1], device='cuda:0'))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Util():\n",
    "    \"\"\"\n",
    "        Util class used in order to load the training text.\n",
    "       The text is loaded from a file.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        # ammount of shit in the caesar cypher\n",
    "        self.shift = 1\n",
    "        # tuple of sentence -> target\n",
    "        self.data = self.read_file(file_path)\n",
    "        # Data dictionary (character based)\n",
    "        self.word_2_index = self.create_dictionary(self.data)\n",
    "        # Inverse dictionary (transform charcter code to the given character)\n",
    "        self.index_2_word = {v: k for k, v in self.word_2_index.items()}\n",
    "        \n",
    "    # Turn a Unicode string to plain ASCII, thanks to\n",
    "    # https://stackoverflow.com/a/518232/2809427\n",
    "    def unicodeToAscii(self, s):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "        )\n",
    "    \n",
    "    def read_file(self, file_path):\n",
    "        \"\"\" \n",
    "            Read the training data file and append the sentence -> target\n",
    "            to the data array.\n",
    "        \"\"\"\n",
    "        \n",
    "        f = open(file_path)\n",
    "        data = []\n",
    "        \n",
    "        for line in f.readlines():\n",
    "            line = line.split('\\t')[0]\n",
    "            sentence = line.split(' ') # split into words\n",
    "            sentence = [word.lower() for word in sentence] # make all the words lowercase\n",
    "            sentence = [word.translate(str.maketrans('', '', string.punctuation)) for word in sentence]\n",
    "            # convert characters to asci and remove non letters\n",
    "            sentence = [self.unicodeToAscii(word.strip()) for word in sentence]\n",
    "            sentence = [re.sub(r\"([.!?}{])\", r\" \\1\", word) for word in sentence]\n",
    "            sentence = [re.sub(r\"[^a-zA-Z.!?}{]+\", r\"\", word) for word in sentence]\n",
    " \n",
    "            target = []\n",
    "            for word in sentence:\n",
    "                stri = \"\"\n",
    "                coded = [chr(ord(x) + self.shift) if x !='z' else x for x in word ]\n",
    "                for x in coded:\n",
    "                    stri += x\n",
    "                target.append(stri)\n",
    "            \n",
    "            data.append((sentence,target))\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def create_dictionary(self, data):\n",
    "        \"\"\" \n",
    "            Iterate over each sentence in the data and add the characters\n",
    "            to the dictionary used. Based on it create an inverse dictionary\n",
    "            that maps the numbers to character.\n",
    "        \"\"\"\n",
    "        word_2_index = {}\n",
    "        \n",
    "        word_2_index[\"SOS\"] = 0\n",
    "        word_2_index[\"EOS\"] = 1\n",
    "        \n",
    "        for sentence, target in data:\n",
    "            for word in sentence:\n",
    "                for char in word:\n",
    "                    if char not in word_2_index:\n",
    "                        word_2_index[char] = len(word_2_index)\n",
    "                        \n",
    "            for word in target:\n",
    "                for char in word:\n",
    "                    if char not in word_2_index:\n",
    "                        word_2_index[char] = len(word_2_index)\n",
    "                    \n",
    "        return word_2_index\n",
    "    \n",
    "    def get_values(self, inp, output):\n",
    "        \"\"\"\n",
    "            Get a normal sentence and transform it to a tensor of dictionary values.\n",
    "        \"\"\"\n",
    "        input_tensor = [self.word_2_index[char] for word in inp for char in word]\n",
    "        output_tensor = [self.word_2_index[char] for word in output for char in word]\n",
    "        \n",
    "        output_tensor.append(1)\n",
    "        \n",
    "        return torch.tensor(input_tensor).to(device), torch.tensor(output_tensor).to(device)\n",
    "        \n",
    "util = Util(\"ron.txt\")\n",
    "util.get_values(util.data[25][0], util.data[25][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, hidden_size, emb_size, vocab_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Define the layers size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        # Transformations used\n",
    "        # LSTM layer used to encode the embedding output\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        # Embedding layer for the input of a sentence (char or word)\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.emb_size)\n",
    "        # Linear layer to map the embedding dimension to the hidden unit dimension\n",
    "        self.lin = nn.Linear(self.emb_size, self.hidden_size)\n",
    "        \n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size).to(device), torch.zeros(1, 1, self.hidden_size).to(device))\n",
    "            \n",
    "    \n",
    "    def forward(self, inputs, hidden):\n",
    "        # Embedd each character to a higher space\n",
    "        x = self.embedding(inputs).view(1, 1, -1)\n",
    "        # Transform the higher space to the lstm space (50 ->256)\n",
    "        x = self.lin(x)\n",
    "        # Non-linear activation\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Apply the sequential LSTM to each input\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_hidden, hidden_size):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        # vocab dimension, embedding space dimenson, hidden space dimension\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_hidden = emb_hidden\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # create the nn layers for the decoding part\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.emb_hidden)\n",
    "        self.dense = nn.Linear(self.emb_hidden, self.hidden_size)\n",
    "        self.attn = nn.Linear(3 * hidden_size, 1)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.input_combine = nn.Linear(2 * hidden_size, hidden_size)\n",
    "        self.last = nn.Linear(self.hidden_size, self.vocab_size)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size).to(device), torch.zeros(1, 1, self.hidden_size).to(device))\n",
    "    \n",
    "    def forward(self, x, decoder_hidden, encoder_outputs):\n",
    "        # Embedd each input to a higher space\n",
    "        x = self.embedding(x).view(1, 1, -1)\n",
    "        # Transform the higher space to the lstm space (50 ->256)\n",
    "        x = self.dense(x)\n",
    "        # Non-linear activation\n",
    "        x = F.relu(x)\n",
    "        attention_values = []\n",
    "        \n",
    "        for i in range(len(encoder_outputs)):\n",
    "            # concatinate encoder_output at i with the decoder hidden state (tuple cause lstm has 2) -> 3 * hidden_size \n",
    "            enc_dec_concat = torch.cat((encoder_outputs[i].view(1, 1, -1), torch.cat((decoder_hidden[0], decoder_hidden[1]), 2)), 2)\n",
    "            \n",
    "            attn_value = self.attn(enc_dec_concat)\n",
    "            attention_values.append(attn_value)\n",
    "        alphas = torch.cat(attention_values, 1)\n",
    "        alphas_norm = F.softmax(alphas, dim=1)\n",
    "        # Weight multiplication for each encoder output to denote it's importance \n",
    "        c = torch.bmm(alphas_norm.view(1, 1, -1), encoder_outputs.view(1, -1, self.hidden_size))\n",
    "        \n",
    "        x = torch.cat((x.view(1, 1, -1), c.view(1, 1, -1)), 2)\n",
    "        x = self.input_combine(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        out, decoder_hidden = self.lstm(x, decoder_hidden)\n",
    "        out = self.last(out[0])\n",
    "        \n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        \n",
    "        return out, decoder_hidden\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder and decoder architecture\n",
    "encoder = Encoder(256, 50, len(util.word_2_index)).to(device)\n",
    "decoder = AttentionDecoder(len(util.word_2_index), 50, 256).to(device)\n",
    "learning_rate = 0.01\n",
    "# Define optimizers for each architecture used\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define a criterion to calculate the error\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(input_tensor, target_tensor):\n",
    "    \"\"\"\n",
    "        Method used to iterate and train over one sentence.\n",
    "    \"\"\"\n",
    "    # Initiate the encoder hidden layer for the lstm\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    # Define the attention encoder outputs\n",
    "    encoder_outputs = torch.zeros([len(input_tensor), 1, 256]).cuda()\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    #clear the last gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    # Encode the inputs in order to get the encoder outputs for the context vector\n",
    "    for i in range(len(input_tensor)):\n",
    "        encoder_out, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
    "        encoder_outputs[i] = encoder_out\n",
    "    \n",
    "    out = torch.tensor([0]).cuda() # sos\n",
    "    # Decoder lstm input gets its values from the encoder lstm output\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    for i, targ in enumerate(target_tensor):\n",
    "        # decoder output softmax of vocab size\n",
    "        decoder_out, decoder_hidden = decoder(out.cuda(), decoder_hidden, encoder_outputs)\n",
    "        # get the max value and the max index\n",
    "        topv, topi = decoder_out.topk(1)\n",
    "        # transform the max index in a tensor and feed it as an input\n",
    "        out = topi.detach().long().cuda()\n",
    "        # calculate the loss [batch_size, output_softmax], long_target_value\n",
    "        loss += criterion(decoder_out.squeeze().unsqueeze(0).to(device), target_tensor[i].unsqueeze(0).to(device))\n",
    "        if out.item() == 1:\n",
    "            break\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()   \n",
    "    \n",
    "    \n",
    "    return loss / len(target_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cordu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b2b89a09df4c08934807a8794b7235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.6894, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e683fb0b4c784037b6390ca8148f91e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.6745, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3975c884d64ae6a1eb0453e99b3022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.6603, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d295ed8ac742e7891f4c646f60e2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.6467, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9210adc69d4aa0bf9e303b68de504d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.6336, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957b51c2faee40648e02606c791a27f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(0.6210, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    for i in range(6):\n",
    "        loss = 0\n",
    "        for inp, target in tqdm_notebook(util.data):\n",
    "            inp_tensor, output_tensor = util.get_values(inp, target)\n",
    "            loss += learn(inp_tensor, output_tensor)\n",
    "        \n",
    "        print(loss)\n",
    "        \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_code_sentence(tensor_vec):\n",
    "    \n",
    "    sentence = [util.index_2_word[i.item()] for i in tensor_vec]\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_sentence(inp_tensor, target_tensor):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct_predictions = 0\n",
    "        encoder_outputs = torch.zeros([len(inp_tensor), 1, 256]).cuda()\n",
    "        encoder_hidden = encoder.init_hidden()\n",
    "            \n",
    "        for i, inp in enumerate(inp_tensor):\n",
    "            encoder_out, encoder_hidden = encoder(inp.cuda(), encoder_hidden)\n",
    "            encoder_outputs[i] = encoder_out\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        out = torch.tensor([0]).cuda() # EOS\n",
    "        \n",
    "        for i, target in enumerate(target_tensor):\n",
    "            # decoder output softmax of vocab size\n",
    "            decoder_out, decoder_hidden = decoder(out.cuda(), decoder_hidden, encoder_outputs)\n",
    "            # get the max value and the max index\n",
    "            topv, topi = decoder_out.topk(1)\n",
    "            # transform the max index in a tensor and feed it as an input\n",
    "            out = topi.detach().long().cuda()\n",
    "\n",
    "            if out.item() == target:\n",
    "                correct_predictions += 1\n",
    "            if out.item() == 1:\n",
    "                break\n",
    "    \n",
    "    return correct_predictions, len(target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cordu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df281413dd44ef1b3c43fa63e660801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1290\n",
      "4800\n",
      "26.875\n"
     ]
    }
   ],
   "source": [
    "util2 = Util(\"ron_validation.txt\")\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for inp, target in tqdm_notebook(util2.data):\n",
    "    inp, target = util.get_values(inp, target)\n",
    "    correct_it, total_it = validate_sentence(inp, target)\n",
    "    correct_predictions += correct_it\n",
    "    total_predictions += total_it\n",
    "\n",
    "print(correct_predictions)\n",
    "print(total_predictions)\n",
    "print((correct_predictions / total_predictions) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'm', 'i', 'b', 'a', 'g', 'p', 'l']\n"
     ]
    }
   ],
   "source": [
    "inpts, _ = util.get_values(\"imibagpl\", \"asae\")\n",
    "print(transform_code_sentence(inpts))\n",
    "encoder_outputs = torch.zeros([len(inpts), 1, 256]).cuda()\n",
    "encoder_hidden = encoder.init_hidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4]], device='cuda:0')\n",
      "tensor([[7]], device='cuda:0')\n",
      "tensor([[4]], device='cuda:0')\n",
      "tensor([[23]], device='cuda:0')\n",
      "tensor([[15]], device='cuda:0')\n",
      "tensor([[2]], device='cuda:0')\n",
      "tensor([[4]], device='cuda:0')\n",
      "tensor([[14]], device='cuda:0')\n",
      "tensor([[2]], device='cuda:0')\n",
      "tensor([[23]], device='cuda:0')\n",
      "tensor([[7]], device='cuda:0')\n",
      "tensor([[4]], device='cuda:0')\n",
      "tensor([[18]], device='cuda:0')\n",
      "tensor([[23]], device='cuda:0')\n",
      "tensor([[2]], device='cuda:0')\n",
      "['j', 'n', 'j', 'b', 'e', 'h', 'j', 'f', 'h', 'b', 'n', 'j', 'm', 'b', 'h']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, inp in enumerate(inpts):\n",
    "        encoder_out, encoder_hidden = encoder(inp.cuda(), encoder_hidden)\n",
    "        encoder_outputs[i] = encoder_out\n",
    "\n",
    "    out = torch.tensor([0]).cuda() # EOS\n",
    "    decoder_hidden = encoder_hidden\n",
    "    result = []\n",
    "    for i in range(15):\n",
    "        # decoder output softmax of vocab size\n",
    "        decoder_out, decoder_hidden = decoder(out.cuda(), decoder_hidden, encoder_outputs)\n",
    "        # get the max value and the max index\n",
    "        topv, topi = decoder_out.topk(1)\n",
    "        # transform the max index in a tensor and feed it as an input\n",
    "        out = topi.detach().long().cuda()\n",
    "        result.append(out)\n",
    "        print(out)\n",
    "        if out.item() == 1:\n",
    "            break\n",
    "            \n",
    "    print(transform_code_sentence(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
