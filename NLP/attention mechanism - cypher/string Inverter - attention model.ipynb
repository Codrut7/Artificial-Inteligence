{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import unicodedata\n",
    "import string\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook\n",
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder class used on each input variable.\n",
    "       Will be used in the decoder arhitecture to create the context vector.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_size, hidden_size, vocab_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros([1, 1, self.hidden_size]).to(device), torch.zeros([1, 1, self.hidden_size]).to(device))\n",
    "    \n",
    "    def forward(self, inp, hidden):\n",
    "        x = self.embedding(inp).view(1, 1, -1).to(device)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    \"\"\"Decoder architecture.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, output_size, embedding_size, vocab_size):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, output_size)\n",
    "        self.attn_lin = nn.Linear(3 * self.hidden_size, 1)\n",
    "        self.input_lin = nn.Linear(2 * self.hidden_size, hidden_size)\n",
    "        self.last_lin = nn.Linear(self.hidden_size, self.vocab_size)\n",
    "        \n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros([1, 1, self.hidden_size]).to(device), torch.zeros([1, 1, self.hidden_size]).to(device))\n",
    "    \n",
    "    def forward(self, inputs, hidden, encoder_outputs):\n",
    "        x = self.embedding(inputs).view(1, 1, -1)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        attn_values = []\n",
    "        \n",
    "        for i in range(len(encoder_outputs)):\n",
    "            hidden_dec = torch.cat((hidden[0], hidden[1]), dim=2)\n",
    "            concat_values = torch.cat((hidden_dec, encoder_outputs[i].view(1, 1, -1)), dim=2)\n",
    "            attn_value = self.attn_lin(concat_values)\n",
    "            attn_values.append(attn_value)\n",
    "        # Create the attention weights to make the weighted average of the encoder values    \n",
    "        alphas = torch.cat(attn_values, 1) # concat them to the second dimension [1, weights, 1]\n",
    "        alphas_norm = F.softmax(alphas, dim=1)\n",
    "        # Calculate the weighted average [1, 1, nr_encoded_words] * [ 1, nr_enoded_words, hidden_siz] -> [1, 1, hidd_siz]\n",
    "        context_vec = torch.bmm(alphas_norm.view(1, 1, -1), encoder_outputs.view(1, -1, self.hidden_size))\n",
    "       \n",
    "        # Append the context vector to the last output\n",
    "        decoder_input = torch.cat((context_vec, x), dim=2)\n",
    "        # Make the input dimension usable for the lstm\n",
    "        decoder_input = self.input_lin(decoder_input)\n",
    "        decoder_input = F.relu(decoder_input)\n",
    "        \n",
    "        out, hidden = self.lstm(decoder_input, hidden)\n",
    "        out = self.last_lin(out[0])\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return out, hidden\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Util():\n",
    "    def __init__(self, file_path):\n",
    "        self.data = self.read_file(file_path)\n",
    "        self.word_2_index, self.index_2_word = self.create_dictionaries(self.data)\n",
    "        \n",
    "        \n",
    "    def read_file(self, file_path):\n",
    "        f = open(file_path, encoding=\"mbcs\")\n",
    "        data = []\n",
    "        \n",
    "        for line in f.readlines():\n",
    "            sentence = line.split('\\t')[0]\n",
    "            sentence = sentence.split(' ') # split into words\n",
    "            sentence = [word.lower() for word in sentence] # make all the words lowercase\n",
    "            sentence = [word.translate(str.maketrans('', '', string.punctuation)) for word in sentence]\n",
    "            inverse = sentence[::-1]\n",
    "            data.append((sentence, inverse))\n",
    "            \n",
    "        return data\n",
    "        \n",
    "    def create_dictionaries(self, data):\n",
    "        word_2_index = {}\n",
    "        index_2_word = {}\n",
    "        \n",
    "        word_2_index[\"SOS\"] = 0\n",
    "        index_2_word[0] = \"SOS\"\n",
    "        word_2_index[\"EOS\"] = 1\n",
    "        index_2_word[1] = \"EOS\"\n",
    "        \n",
    "        for sentence, target in data:\n",
    "            for word in sentence:\n",
    "                if word not in word_2_index:\n",
    "                    word_2_index[word] = len(word_2_index)\n",
    "                    index_2_word[len(index_2_word)] = word\n",
    "        \n",
    "        \n",
    "        return word_2_index, index_2_word\n",
    "    \n",
    "    def create_tensor_from_sentence(self, input_sentence, target_sentence):\n",
    "        inp = []\n",
    "        out = []\n",
    "        \n",
    "        inp.append(0)\n",
    "        \n",
    "        for word in input_sentence:\n",
    "            inp.append(self.word_2_index[word])\n",
    "        inp.append(1)\n",
    "        \n",
    "        out = inp[::-1]\n",
    "        \n",
    "        return torch.tensor(inp).cuda(), torch.tensor(out).cuda()\n",
    "        \n",
    "        \n",
    "util = Util(\"ron.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(util.word_2_index) # ?? IDK\n",
    "\n",
    "\n",
    "encoder = Encoder(256, 256, VOCAB_SIZE).to(device)\n",
    "decoder = AttentionDecoder(256, 256, 256, VOCAB_SIZE).to(device)\n",
    "\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(input_tensor, target_tensor):\n",
    "    \n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs = torch.zeros([len(input_tensor), 1, 256]).cuda()\n",
    "    loss = 0\n",
    "    \n",
    "    #clear the last gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    for i in range(len(input_tensor)):\n",
    "        encoder_out, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
    "        encoder_outputs[i] = encoder_out\n",
    "    \n",
    "    out = torch.tensor([1]).cuda() # eos\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    for i, targ in enumerate(target_tensor):\n",
    "        # decoder output softmax of vocab size\n",
    "        decoder_out, decoder_hidden = decoder(out.cuda(), decoder_hidden, encoder_outputs)\n",
    "        # get the max value and the max index\n",
    "        topv, topi = decoder_out.topk(1)\n",
    "        # transform the max index in a tensor and feed it as an input\n",
    "        out = topi.detach().long().cuda()\n",
    "        # calculate the loss [batch_size, output_softmax], long_target_value\n",
    "        loss += criterion(decoder_out.squeeze().unsqueeze(0).to(device), target_tensor[i].unsqueeze(0).to(device))\n",
    "        \n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()   \n",
    "    \n",
    "    \n",
    "    return loss / len(target_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cordu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92f5f00a2e14ed9929af1b1021d5abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(6953.5405, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6971758d484cc580493bf70c7bcfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(4244.9434, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fdf818ced84701af5ac7aa02a90f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(2841.9692, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ac2d7a46f64f8cb81ef5fb505ee40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(1701.8900, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ece94c004aa4e3193a5445453bc5ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(855.6002, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbae125c1bc4bf3b4f406b53bc7ddfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(386.4748, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82d749cd26343e29fd09fce065ff87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(170.8110, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7daac317e547b8aa1d1f0deb4e4e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(97.6114, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283def266ffc466b9b0456fd42fe332c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(59.6171, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dded48d303a949159a170c2900c7c3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(38.5835, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78b5f6e657048e6bdde9962c730808b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(26.1143, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b9968f72d14190a16bf0ccc545ea5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(24.4430, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d64314aa774c1288969d2a728a903a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(22.2199, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5179f7100820455784b5bd99289b3bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(16.0705, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6547e106fe7f406b9dda37f52816766e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(6.7259, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb2865ad33b465dbd96d00ff10b3718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(7.5887, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17f30b02be541019c020fafdda0e8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(9.6806, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cd2501d11144d08cbcf6e6990c4b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(5.8662, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52ba9fde9364318893f672eb88f49de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(11.5039, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef91c3f164764ccfa67559ff6367ca5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(19.5564, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a78f4a7d2c4e98a482faa295acf65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(6.3272, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c164d858144b08b2c88b01a7484a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(1.1088, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b367b5df8d540c294b0279b4f56fcaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(6.5465, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94467b70d16c40b99d33e73144378659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(14.3894, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a064b58413574af0bd6ced6acf928065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2165.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor(7.2304, device='cuda:0', grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    for i in range(25):\n",
    "        loss = 0\n",
    "        for inp, target in tqdm_notebook(util.data):\n",
    "            inp_tensor, output_tensor = util.create_tensor_from_sentence(inp, target)\n",
    "            loss += learn(inp_tensor, output_tensor)\n",
    "        \n",
    "        print(loss)\n",
    "        \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SOS': 0,\n",
       " 'EOS': 1,\n",
       " 'hi': 2,\n",
       " 'run': 3,\n",
       " 'who': 4,\n",
       " 'fire': 5,\n",
       " 'help': 6,\n",
       " 'jump': 7,\n",
       " 'stop': 8,\n",
       " 'wait': 9,\n",
       " 'hello': 10,\n",
       " 'hurry': 11,\n",
       " 'relax': 12,\n",
       " 'smile': 13,\n",
       " 'attack': 14,\n",
       " 'cheers': 15,\n",
       " 'freeze': 16,\n",
       " 'get': 17,\n",
       " 'up': 18,\n",
       " 'really': 19,\n",
       " 'ask': 20,\n",
       " 'tom': 21,\n",
       " 'awesome': 22,\n",
       " 'call': 23,\n",
       " 'me': 24,\n",
       " 'out': 25,\n",
       " 'go': 26,\n",
       " 'away': 27,\n",
       " 'goodbye': 28,\n",
       " 'hold': 29,\n",
       " 'on': 30,\n",
       " 'i': 31,\n",
       " 'agree': 32,\n",
       " 'im': 33,\n",
       " 'ill': 34,\n",
       " 'sad': 35,\n",
       " 'its': 36,\n",
       " 'ok': 37,\n",
       " 'keep': 38,\n",
       " 'it': 39,\n",
       " 'open': 40,\n",
       " 'perfect': 41,\n",
       " 'tell': 42,\n",
       " 'why': 43,\n",
       " 'not': 44,\n",
       " 'grab': 45,\n",
       " 'him': 46,\n",
       " 'how': 47,\n",
       " 'cute': 48,\n",
       " 'pay': 49,\n",
       " 'back': 50,\n",
       " 'calm': 51,\n",
       " 'free': 52,\n",
       " 'here': 53,\n",
       " 'home': 54,\n",
       " 'numb': 55,\n",
       " 'sick': 56,\n",
       " 'hurts': 57,\n",
       " 'marry': 58,\n",
       " 'may': 59,\n",
       " 'terrific': 60,\n",
       " 'fled': 61,\n",
       " 'left': 62,\n",
       " 'too': 63,\n",
       " 'late': 64,\n",
       " 'trust': 65,\n",
       " 'use': 66,\n",
       " 'this': 67,\n",
       " 'fell': 68,\n",
       " 'paid': 69,\n",
       " 'bless': 70,\n",
       " 'you': 71,\n",
       " 'down': 72,\n",
       " 'come': 73,\n",
       " 'dont': 74,\n",
       " 'fantastic': 75,\n",
       " 'he': 76,\n",
       " 'is': 77,\n",
       " 'hes': 78,\n",
       " 'fast': 79,\n",
       " 'am': 80,\n",
       " 'beg': 81,\n",
       " 'can': 82,\n",
       " 'ski': 83,\n",
       " 'win': 84,\n",
       " 'hope': 85,\n",
       " 'so': 86,\n",
       " 'will': 87,\n",
       " 'lose': 88,\n",
       " 'bored': 89,\n",
       " 'drunk': 90,\n",
       " 'happy': 91,\n",
       " 'sorry': 92,\n",
       " 'tired': 93,\n",
       " 'bad': 94,\n",
       " 'far': 95,\n",
       " 'snowed': 96,\n",
       " 'cold': 97,\n",
       " 'easy': 98,\n",
       " 'cool': 99,\n",
       " 'that': 100,\n",
       " 'them': 101,\n",
       " 'warm': 102,\n",
       " 'look': 103,\n",
       " 'pardon': 104,\n",
       " 'seriously': 105,\n",
       " 'she': 106,\n",
       " 'cried': 107,\n",
       " 'stay': 108,\n",
       " 'take': 109,\n",
       " 'care': 110,\n",
       " 'they': 111,\n",
       " 'toms': 112,\n",
       " 'shy': 113,\n",
       " 'we': 114,\n",
       " 'waited': 115,\n",
       " 'choose': 116,\n",
       " 'one': 117,\n",
       " 'definitely': 118,\n",
       " 'did': 119,\n",
       " 'do': 120,\n",
       " 'in': 121,\n",
       " 'kind': 122,\n",
       " 'made': 123,\n",
       " 'doubt': 124,\n",
       " 'got': 125,\n",
       " 'know': 126,\n",
       " 'now': 127,\n",
       " 'love': 128,\n",
       " 'miss': 129,\n",
       " 'ran': 130,\n",
       " 'want': 131,\n",
       " 'was': 132,\n",
       " 'coming': 133,\n",
       " 'scared': 134,\n",
       " 'sleepy': 135,\n",
       " 'fat': 136,\n",
       " 'going': 137,\n",
       " 'notes': 138,\n",
       " 'quiet': 139,\n",
       " 'still': 140,\n",
       " 'swim': 141,\n",
       " 'no': 142,\n",
       " 'kidding': 143,\n",
       " 'problem': 144,\n",
       " 'shes': 145,\n",
       " 'busy': 146,\n",
       " 'talk': 147,\n",
       " 'to': 148,\n",
       " 'looked': 149,\n",
       " 'weak': 150,\n",
       " 'well': 151,\n",
       " 'were': 152,\n",
       " 'even': 153,\n",
       " 'where': 154,\n",
       " 'whos': 155,\n",
       " 'next': 156,\n",
       " 'youre': 157,\n",
       " 'old': 158,\n",
       " 'are': 159,\n",
       " 'mad': 160,\n",
       " 'be': 161,\n",
       " 'watchful': 162,\n",
       " 'panic': 163,\n",
       " 'with': 164,\n",
       " 'a': 165,\n",
       " 'nerd': 166,\n",
       " 'strong': 167,\n",
       " 'adore': 168,\n",
       " 'taller': 169,\n",
       " 'came': 170,\n",
       " 'cant': 171,\n",
       " 'eat': 172,\n",
       " 'fly': 173,\n",
       " 'bread': 174,\n",
       " 'feel': 175,\n",
       " 'felt': 176,\n",
       " 'had': 177,\n",
       " 'heard': 178,\n",
       " 'like': 179,\n",
       " 'jazz': 180,\n",
       " 'rock': 181,\n",
       " 'snow': 182,\n",
       " 'golf': 183,\n",
       " 'must': 184,\n",
       " 'hide': 185,\n",
       " 'need': 186,\n",
       " 'mine': 187,\n",
       " 'right': 188,\n",
       " 'work': 189,\n",
       " 'wont': 190,\n",
       " 'die': 191,\n",
       " 'nurse': 192,\n",
       " 'at': 193,\n",
       " 'curious': 194,\n",
       " 'married': 195,\n",
       " 'nervous': 196,\n",
       " 'serious': 197,\n",
       " 'starved': 198,\n",
       " 'thirsty': 199,\n",
       " 'white': 200,\n",
       " 'moving': 201,\n",
       " 'trying': 202,\n",
       " 'let': 203,\n",
       " 'lets': 204,\n",
       " 'make': 205,\n",
       " 'list': 206,\n",
       " 'wish': 207,\n",
       " 'nobody': 208,\n",
       " 'please': 209,\n",
       " 'bit': 210,\n",
       " 'crazy': 211,\n",
       " 'thats': 212,\n",
       " 'blushed': 213,\n",
       " 'tomll': 214,\n",
       " 'good': 215,\n",
       " 'ate': 216,\n",
       " 'eggs': 217,\n",
       " 'promised': 218,\n",
       " 'what': 219,\n",
       " 'pity': 220,\n",
       " 'wheres': 221,\n",
       " 'all': 222,\n",
       " 'anybody': 223,\n",
       " 'nuts': 224,\n",
       " 'sure': 225,\n",
       " 'us': 226,\n",
       " 'drive': 227,\n",
       " 'slowly': 228,\n",
       " 'school': 229,\n",
       " 'evening': 230,\n",
       " 'my': 231,\n",
       " 'hand': 232,\n",
       " 'easter': 233,\n",
       " 'has': 234,\n",
       " 'money': 235,\n",
       " 'likes': 236,\n",
       " 'tea': 237,\n",
       " 'brave': 238,\n",
       " 'jealous': 239,\n",
       " 'caviar': 240,\n",
       " 'blamed': 241,\n",
       " 'drank': 242,\n",
       " 'milk': 243,\n",
       " 'drink': 244,\n",
       " 'have': 245,\n",
       " 'cat': 246,\n",
       " 'candy': 247,\n",
       " 'understand': 248,\n",
       " 'walk': 249,\n",
       " 'lot': 250,\n",
       " 'doctor': 251,\n",
       " 'doubtful': 252,\n",
       " 'rational': 253,\n",
       " 'the': 254,\n",
       " 'best': 255,\n",
       " 'book': 256,\n",
       " 'alive': 257,\n",
       " 'an': 258,\n",
       " 'omen': 259,\n",
       " 'raining': 260,\n",
       " 'snowing': 261,\n",
       " 'just': 262,\n",
       " 'fake': 263,\n",
       " 'dancing': 264,\n",
       " 'digging': 265,\n",
       " 'driving': 266,\n",
       " 'focused': 267,\n",
       " 'looking': 268,\n",
       " 'reading': 269,\n",
       " 'running': 270,\n",
       " 'singing': 271,\n",
       " 'smiling': 272,\n",
       " 'talking': 273,\n",
       " 'walking': 274,\n",
       " 'working': 275,\n",
       " 'writing': 276,\n",
       " 'try': 277,\n",
       " 'guess': 278,\n",
       " 'real': 279,\n",
       " 'move': 280,\n",
       " 'quietly': 281,\n",
       " 'feet': 282,\n",
       " 'hurt': 283,\n",
       " 'theyre': 284,\n",
       " 'unbelievable': 285,\n",
       " 'apologize': 286,\n",
       " 'leave': 287,\n",
       " 'both': 288,\n",
       " 'rain': 289,\n",
       " 'rest': 290,\n",
       " 'war': 291,\n",
       " 'famous': 292,\n",
       " 'welcome': 293,\n",
       " 'built': 294,\n",
       " 'cruel': 295,\n",
       " 'air': 296,\n",
       " 'futon': 297,\n",
       " 'angry': 298,\n",
       " 'lying': 299,\n",
       " 'everyone': 300,\n",
       " 'sang': 301,\n",
       " 'eats': 302,\n",
       " 'maid': 303,\n",
       " 'boss': 304,\n",
       " 'very': 305,\n",
       " 'rope': 306,\n",
       " 'backed': 307,\n",
       " 'believe': 308,\n",
       " 'steal': 309,\n",
       " 'unwell': 310,\n",
       " 'asleep': 311,\n",
       " 'hate': 312,\n",
       " 'winter': 313,\n",
       " 'boston': 314,\n",
       " 'apples': 315,\n",
       " 'rowing': 316,\n",
       " 'sweets': 317,\n",
       " 'tennis': 318,\n",
       " 'lost': 319,\n",
       " 'key': 320,\n",
       " 'loan': 321,\n",
       " 'read': 322,\n",
       " 'saw': 323,\n",
       " 'fight': 324,\n",
       " 'dog': 325,\n",
       " 'see': 326,\n",
       " 'house': 327,\n",
       " 'told': 328,\n",
       " 'correct': 329,\n",
       " 'lenient': 330,\n",
       " 'watch': 331,\n",
       " 'tv': 332,\n",
       " 'exhausted': 333,\n",
       " 'impartial': 334,\n",
       " 'sensitive': 335,\n",
       " 'poor': 336,\n",
       " 'ive': 337,\n",
       " 'returned': 338,\n",
       " 'painful': 339,\n",
       " 'fox': 340,\n",
       " 'clear': 341,\n",
       " 'flaw': 342,\n",
       " 'joke': 343,\n",
       " 'itll': 344,\n",
       " 'fault': 345,\n",
       " 'loud': 346,\n",
       " 'worth': 347,\n",
       " 'climbing': 348,\n",
       " 'fighting': 349,\n",
       " 'hustling': 350,\n",
       " 'touch': 351,\n",
       " 'paddling': 352,\n",
       " 'life': 353,\n",
       " 'short': 354,\n",
       " 'sweet': 355,\n",
       " 'lock': 356,\n",
       " 'door': 357,\n",
       " 'safe': 358,\n",
       " 'choice': 359,\n",
       " 'offer': 360,\n",
       " 'brief': 361,\n",
       " 'quick': 362,\n",
       " 'your': 363,\n",
       " 'bed': 364,\n",
       " 'head': 365,\n",
       " 'aches': 366,\n",
       " 'names': 367,\n",
       " 'step': 368,\n",
       " 'oh': 369,\n",
       " 'hood': 370,\n",
       " 'pace': 371,\n",
       " 'yourself': 372,\n",
       " 'put': 373,\n",
       " 'send': 374,\n",
       " 'loves': 375,\n",
       " 'shut': 376,\n",
       " 'start': 377,\n",
       " 'stir': 378,\n",
       " 'soup': 379,\n",
       " 'gambling': 380,\n",
       " 'straighten': 381,\n",
       " 'boy': 382,\n",
       " 'simple': 383,\n",
       " 'theirs': 384,\n",
       " 'some': 385,\n",
       " 'pun': 386,\n",
       " 'cheap': 387,\n",
       " 'mature': 388,\n",
       " 'upbeat': 389,\n",
       " 'looks': 390,\n",
       " 'sat': 391,\n",
       " 'seems': 392,\n",
       " 'shot': 393,\n",
       " 'mary': 394,\n",
       " 'dirty': 395,\n",
       " 'went': 396,\n",
       " 'won': 397,\n",
       " 'again': 398,\n",
       " 'fist': 399,\n",
       " 'minute': 400,\n",
       " 'speak': 401,\n",
       " 'wrong': 402,\n",
       " 'cousins': 403,\n",
       " 'leaving': 404,\n",
       " 'owe': 405,\n",
       " 'does': 406,\n",
       " 'wants': 407,\n",
       " 'pie': 408,\n",
       " 'winning': 409,\n",
       " 'say': 410,\n",
       " 'fine': 411,\n",
       " 'boil': 412,\n",
       " 'water': 413,\n",
       " 'coffee': 414,\n",
       " 'cows': 415,\n",
       " 'grass': 416,\n",
       " 'cut': 417,\n",
       " 'engine': 418,\n",
       " 'silly': 419,\n",
       " 'tempt': 420,\n",
       " 'everybody': 421,\n",
       " 'knows': 422,\n",
       " 'car': 423,\n",
       " 'give': 424,\n",
       " 'beer': 425,\n",
       " 'new': 426,\n",
       " 'year': 427,\n",
       " 'counts': 428,\n",
       " 'uncle': 429,\n",
       " 'dumb': 430,\n",
       " 'off': 431,\n",
       " 'makes': 432,\n",
       " 'sense': 433,\n",
       " 'song': 434,\n",
       " 'walked': 435,\n",
       " 'much': 436,\n",
       " 'hug': 437,\n",
       " 'for': 438,\n",
       " 'created': 439,\n",
       " 'didnt': 440,\n",
       " 'cheat': 441,\n",
       " 'gave': 442,\n",
       " 'glanced': 443,\n",
       " 'dream': 444,\n",
       " 'company': 445,\n",
       " 'cooking': 446,\n",
       " 'lasagna': 447,\n",
       " 'wife': 448,\n",
       " 'nominate': 449,\n",
       " 'said': 450,\n",
       " 'stepped': 451,\n",
       " 'wasnt': 452,\n",
       " 'there': 453,\n",
       " 'race': 454,\n",
       " 'soon': 455,\n",
       " 'man': 456,\n",
       " 'crying': 457,\n",
       " 'excited': 458,\n",
       " 'undressing': 459,\n",
       " 'unemployed': 460,\n",
       " 'used': 461,\n",
       " 'been': 462,\n",
       " 'moved': 463,\n",
       " 'sleeping': 464,\n",
       " 'secret': 465,\n",
       " 'smells': 466,\n",
       " 'mouse': 467,\n",
       " 'dangerous': 468,\n",
       " 'listening': 469,\n",
       " 'posted': 470,\n",
       " 'searching': 471,\n",
       " 'alone': 472,\n",
       " 'lend': 473,\n",
       " 'happen': 474,\n",
       " 'larger': 475,\n",
       " 'more': 476,\n",
       " 'needed': 477,\n",
       " 'dad': 478,\n",
       " 'heart': 479,\n",
       " 'joints': 480,\n",
       " 'ache': 481,\n",
       " 'name': 482,\n",
       " 'hit': 483,\n",
       " 'meter': 484,\n",
       " 'grew': 485,\n",
       " 'roses': 486,\n",
       " 'train': 487,\n",
       " 'hotel': 488,\n",
       " 'table': 489,\n",
       " 'idea': 490,\n",
       " 'law': 491,\n",
       " 'their': 492,\n",
       " 'eyes': 493,\n",
       " 'met': 494,\n",
       " 'lips': 495,\n",
       " 'could': 496,\n",
       " 'afraid': 497,\n",
       " 'allies': 498,\n",
       " 'throw': 499,\n",
       " 'dice': 500,\n",
       " 'time': 501,\n",
       " 'todays': 502,\n",
       " 'hectic': 503,\n",
       " 'drove': 504,\n",
       " 'isnt': 505,\n",
       " 'missed': 506,\n",
       " 'should': 507,\n",
       " 'helped': 508,\n",
       " 'unbiased': 509,\n",
       " 'letdown': 510,\n",
       " 'cup': 511,\n",
       " 'plays': 512,\n",
       " 'women': 513,\n",
       " 'loved': 514,\n",
       " 'quit': 515,\n",
       " 'answer': 516,\n",
       " 'type': 517,\n",
       " 'unlucky': 518,\n",
       " 'bees': 519,\n",
       " 'honey': 520,\n",
       " 'bite': 521,\n",
       " 'bullet': 522,\n",
       " 'police': 523,\n",
       " 'cats': 524,\n",
       " 'boxes': 525,\n",
       " 'check': 526,\n",
       " 'close': 527,\n",
       " 'hatch': 528,\n",
       " 'later': 529,\n",
       " 'already': 530,\n",
       " 'towards': 531,\n",
       " 'congratulations': 532,\n",
       " 'cover': 533,\n",
       " 'anyone': 534,\n",
       " 'hear': 535,\n",
       " 'fish': 536,\n",
       " 'remember': 537,\n",
       " 'greedy': 538,\n",
       " 'stingy': 539,\n",
       " 'stupid': 540,\n",
       " 'double': 541,\n",
       " 'bet': 542,\n",
       " 'carefully': 543,\n",
       " 'inside': 544,\n",
       " 'popcorn': 545,\n",
       " 'god': 546,\n",
       " 'stuff': 547,\n",
       " 'painter': 548,\n",
       " 'chains': 549,\n",
       " 'lied': 550,\n",
       " 'readily': 551,\n",
       " 'girl': 552,\n",
       " 'laid': 553,\n",
       " 'writes': 554,\n",
       " 'books': 555,\n",
       " 'gardener': 556,\n",
       " 'pushover': 557,\n",
       " 'photogenic': 558,\n",
       " 'tighter': 559,\n",
       " 'candle': 560,\n",
       " 'abhor': 561,\n",
       " 'spiders': 562,\n",
       " 'almost': 563,\n",
       " 'forgot': 564,\n",
       " 'from': 565,\n",
       " 'egypt': 566,\n",
       " 'eating': 567,\n",
       " 'amused': 568,\n",
       " 'myself': 569,\n",
       " 'baked': 570,\n",
       " 'cookies': 571,\n",
       " 'called': 572,\n",
       " 'find': 573,\n",
       " 'chickened': 574,\n",
       " 'peace': 575,\n",
       " 'deserved': 576,\n",
       " 'forget': 577,\n",
       " 'listen': 578,\n",
       " 'notice': 579,\n",
       " 'scream': 580,\n",
       " 'shower': 581,\n",
       " 'disobeyed': 582,\n",
       " 'downloaded': 583,\n",
       " 'two': 584,\n",
       " 'screams': 585,\n",
       " 'yelling': 586,\n",
       " 'elbow': 587,\n",
       " 'finished': 588,\n",
       " 'panicked': 589,\n",
       " 'showered': 590,\n",
       " 'his': 591,\n",
       " 'interest': 592,\n",
       " 'brownies': 593,\n",
       " 'supper': 594,\n",
       " 'pencil': 595,\n",
       " 'somebody': 596,\n",
       " 'study': 597,\n",
       " 'ordered': 598,\n",
       " 'pizza': 599,\n",
       " 'outwitted': 600,\n",
       " 'taxes': 601,\n",
       " 'prefer': 602,\n",
       " 'biking': 603,\n",
       " 'letter': 604,\n",
       " 'remembered': 605,\n",
       " 'every': 606,\n",
       " 'day': 607,\n",
       " 'something': 608,\n",
       " 'scored': 609,\n",
       " 'goal': 610,\n",
       " 'sent': 611,\n",
       " 'her': 612,\n",
       " 'threw': 613,\n",
       " 'totally': 614,\n",
       " 'guitar': 615,\n",
       " 'assaulted': 616,\n",
       " 'concerned': 617,\n",
       " 'convicted': 618,\n",
       " 'desperate': 619,\n",
       " 'impressed': 620,\n",
       " 'kidnapped': 621,\n",
       " 'negligent': 622,\n",
       " 'petrified': 623,\n",
       " 'skeptical': 624,\n",
       " 'surprised': 625,\n",
       " 'terrified': 626,\n",
       " 'hungry': 627,\n",
       " 'id': 628,\n",
       " 'grateful': 629,\n",
       " 'around': 630,\n",
       " 'about': 631,\n",
       " 'ready': 632,\n",
       " 'engineer': 633,\n",
       " 'competitive': 634,\n",
       " 'doing': 635,\n",
       " 'great': 636,\n",
       " 'ashamed': 637,\n",
       " 'bike': 638,\n",
       " 'actor': 639,\n",
       " 'teacher': 640,\n",
       " 'hot': 641,\n",
       " 'surprise': 642,\n",
       " 'our': 643,\n",
       " 'system': 644,\n",
       " 'practicing': 645,\n",
       " 'change': 646,\n",
       " 'large': 647,\n",
       " 'kites': 648,\n",
       " 'behind': 649,\n",
       " 'decision': 650,\n",
       " 'smaller': 651,\n",
       " 'noise': 652,\n",
       " 'marys': 653,\n",
       " 'niece': 654,\n",
       " 'merry': 655,\n",
       " 'christmas': 656,\n",
       " 'might': 657,\n",
       " 'never': 658,\n",
       " 'mouth': 659,\n",
       " 'pick': 660,\n",
       " 'gun': 661,\n",
       " 'prices': 662,\n",
       " 'high': 663,\n",
       " 'singer': 664,\n",
       " 'carefree': 665,\n",
       " 'impatient': 666,\n",
       " 'terrible': 667,\n",
       " 'odd': 668,\n",
       " 'opened': 669,\n",
       " 'died': 670,\n",
       " 'lake': 671,\n",
       " 'big': 672,\n",
       " 'leaves': 673,\n",
       " 'light': 674,\n",
       " 'soups': 675,\n",
       " 'theres': 676,\n",
       " 'team': 677,\n",
       " 'hugged': 678,\n",
       " 'angered': 679,\n",
       " 'actors': 680,\n",
       " 'pretty': 681,\n",
       " 'caught': 682,\n",
       " 'feared': 683,\n",
       " 'ignored': 684,\n",
       " 'seem': 685,\n",
       " 'lucky': 686,\n",
       " 'young': 687,\n",
       " 'theyll': 688,\n",
       " 'today': 689,\n",
       " 'friday': 690,\n",
       " 'monday': 691,\n",
       " 'became': 692,\n",
       " 'checked': 693,\n",
       " 'exaggerates': 694,\n",
       " 'rabbits': 695,\n",
       " 'stamina': 696,\n",
       " 'muslim': 697,\n",
       " 'divorced': 698,\n",
       " 'painting': 699,\n",
       " 'terminal': 700,\n",
       " 'passed': 701,\n",
       " 'turned': 702,\n",
       " 'healthy': 703,\n",
       " 'spoiled': 704,\n",
       " 'mean': 705,\n",
       " 'wore': 706,\n",
       " 'vest': 707,\n",
       " 'unlock': 708,\n",
       " 'picnics': 709,\n",
       " 'energetic': 710,\n",
       " 'fortunate': 711,\n",
       " 'resilient': 712,\n",
       " 'weve': 713,\n",
       " 'blessing': 714,\n",
       " 'whats': 715,\n",
       " 'age': 716,\n",
       " 'when': 717,\n",
       " 'end': 718,\n",
       " 'whod': 719,\n",
       " 'write': 720,\n",
       " 'naughty': 721,\n",
       " 'youll': 722,\n",
       " 'coward': 723,\n",
       " 'angel': 724,\n",
       " 'lion': 725,\n",
       " 'japanese': 726,\n",
       " 'positive': 727,\n",
       " 'students': 728,\n",
       " 'sometime': 729,\n",
       " 'tomorrow': 730,\n",
       " 'number': 731,\n",
       " 'drawer': 732,\n",
       " 'and': 733,\n",
       " 'dogs': 734,\n",
       " 'barking': 735,\n",
       " 'deceive': 736,\n",
       " 'mislead': 737,\n",
       " 'provoke': 738,\n",
       " 'rip': 739,\n",
       " 'grinned': 740,\n",
       " 'everyones': 741,\n",
       " 'point': 742,\n",
       " 'without': 743,\n",
       " 'trip': 744,\n",
       " 'joy': 745,\n",
       " 'backward': 746,\n",
       " 'picasso': 747,\n",
       " 'unsociable': 748,\n",
       " 'keeps': 749,\n",
       " 'diary': 750,\n",
       " 'existed': 751,\n",
       " 'speaks': 752,\n",
       " 'french': 753,\n",
       " 'acquitted': 754,\n",
       " 'waved': 755,\n",
       " 'sophomore': 756,\n",
       " 'tongue': 757,\n",
       " 'brazil': 758,\n",
       " 'of': 759,\n",
       " 'show': 760,\n",
       " 'found': 761,\n",
       " 'chemistry': 762,\n",
       " 'over': 763,\n",
       " 'job': 764,\n",
       " 'score': 765,\n",
       " 'chocolate': 766,\n",
       " 'lemon': 767,\n",
       " 'lamp': 768,\n",
       " 'traveling': 769,\n",
       " 'live': 770,\n",
       " 'europe': 771,\n",
       " 'near': 772,\n",
       " 'travel': 773,\n",
       " 'badly': 774,\n",
       " 'meat': 775,\n",
       " 'regret': 776,\n",
       " 'nothing': 777,\n",
       " 'face': 778,\n",
       " 'shoot': 779,\n",
       " 'protect': 780,\n",
       " '18': 781,\n",
       " 'years': 782,\n",
       " '25': 783,\n",
       " 'avoiding': 784,\n",
       " 'parent': 785,\n",
       " 'if': 786,\n",
       " 'order': 787,\n",
       " 'bank': 788,\n",
       " 'deep': 789,\n",
       " 'son': 790,\n",
       " 'impossible': 791,\n",
       " 'phone': 792,\n",
       " 'sunflower': 793,\n",
       " 'bag': 794,\n",
       " 'neat': 795,\n",
       " 'informed': 796,\n",
       " 'begin': 797,\n",
       " 'way': 798,\n",
       " 'pulse': 799,\n",
       " 'nice': 800,\n",
       " 'meet': 801,\n",
       " 'thinks': 802,\n",
       " 'pain': 803,\n",
       " 'gain': 804,\n",
       " 'taught': 805,\n",
       " 'done': 806,\n",
       " 'funny': 807,\n",
       " 'polite': 808,\n",
       " 'cry': 809,\n",
       " 'beautiful': 810,\n",
       " 'kept': 811,\n",
       " 'worships': 812,\n",
       " 'stand': 813,\n",
       " 'amazing': 814,\n",
       " 'incorrect': 815,\n",
       " 'plausible': 816,\n",
       " 'true': 817,\n",
       " 'bill': 818,\n",
       " 'empty': 819,\n",
       " 'curtain': 820,\n",
       " 'pot': 821,\n",
       " 'towel': 822,\n",
       " 'dry': 823,\n",
       " 'waters': 824,\n",
       " 'week': 825,\n",
       " 'drowned': 826,\n",
       " 'doctors': 827,\n",
       " 'singers': 828,\n",
       " 'food': 829,\n",
       " 'greeted': 830,\n",
       " 'hurried': 831,\n",
       " 'recluse': 832,\n",
       " 'deceitful': 833,\n",
       " 'reluctant': 834,\n",
       " 'woke': 835,\n",
       " 'horses': 836,\n",
       " 'weaker': 837,\n",
       " 'twice': 838,\n",
       " 'hero': 839,\n",
       " 'retire': 840,\n",
       " 'breakfast': 841,\n",
       " 'evacuate': 842,\n",
       " 'fascinated': 843,\n",
       " 'having': 844,\n",
       " 'fun': 845,\n",
       " 'lifeguards': 846,\n",
       " 'brush': 847,\n",
       " 'which': 848,\n",
       " 'brought': 849,\n",
       " 'hopeless': 850,\n",
       " 'wavering': 851,\n",
       " 'showed': 852,\n",
       " 'sleep': 853,\n",
       " 'prevail': 854,\n",
       " 'friend': 855,\n",
       " 'red': 856,\n",
       " 'leaf': 857,\n",
       " 'falling': 858,\n",
       " 'add': 859,\n",
       " 'little': 860,\n",
       " 'admission': 861,\n",
       " 'error': 862,\n",
       " 'american': 863,\n",
       " 'student': 864,\n",
       " 'rush': 865,\n",
       " 'avoid': 866,\n",
       " 'honest': 867,\n",
       " 'birds': 868,\n",
       " 'build': 869,\n",
       " 'nests': 870,\n",
       " 'ambulance': 871,\n",
       " 'closer': 872,\n",
       " 'insist': 873,\n",
       " 'admit': 874,\n",
       " 'sake': 875,\n",
       " 'sushi': 876,\n",
       " 'mom': 877,\n",
       " 'laughed': 878,\n",
       " 'everybodys': 879,\n",
       " 'weapons': 880,\n",
       " 'haste': 881,\n",
       " 'waste': 882,\n",
       " 'appeared': 883,\n",
       " 'arrived': 884,\n",
       " 'safely': 885,\n",
       " 'cannot': 886,\n",
       " 'himself': 887,\n",
       " 'yesterday': 888,\n",
       " 'wink': 889,\n",
       " 'physicist': 890,\n",
       " 'everything': 891,\n",
       " 'took': 892,\n",
       " 'picture': 893,\n",
       " 'violated': 894,\n",
       " 'wrote': 895,\n",
       " 'getting': 896,\n",
       " 'heres': 897,\n",
       " 'handrail': 898,\n",
       " 'person': 899,\n",
       " 'asked': 900,\n",
       " 'after': 901,\n",
       " 'boarded': 902,\n",
       " 'bus': 903,\n",
       " 'burned': 904,\n",
       " 'cake': 905,\n",
       " 'by': 906,\n",
       " 'couldnt': 907,\n",
       " 'defended': 908,\n",
       " 'fruit': 909,\n",
       " 'tools': 910,\n",
       " 'headache': 911,\n",
       " 'buy': 912,\n",
       " 'music': 913,\n",
       " 'beard': 914,\n",
       " 'liked': 915,\n",
       " 'luggage': 916,\n",
       " 'hamburgers': 917,\n",
       " 'outlive': 918,\n",
       " 'once': 919,\n",
       " 'ashtray': 920,\n",
       " 'assistance': 921,\n",
       " 'pushed': 922,\n",
       " 'feeling': 923,\n",
       " 'taken': 924,\n",
       " 'aback': 925,\n",
       " 'endorse': 926,\n",
       " 'foot': 927,\n",
       " 'worked': 928,\n",
       " 'overtime': 929,\n",
       " 'gym': 930,\n",
       " 'as': 931,\n",
       " 'bee': 932,\n",
       " 'drinking': 933,\n",
       " 'zonked': 934,\n",
       " 'taking': 935,\n",
       " 'bath': 936,\n",
       " 'criminal': 937,\n",
       " 'tie': 938,\n",
       " 'clean': 939,\n",
       " 'seat': 940,\n",
       " 'depends': 941,\n",
       " 'act': 942,\n",
       " 'snows': 943,\n",
       " 'paris': 944,\n",
       " 'tremendous': 945,\n",
       " 'lovely': 946,\n",
       " 'dark': 947,\n",
       " 'hard': 948,\n",
       " 'jam': 949,\n",
       " 'comes': 950,\n",
       " 'jars': 951,\n",
       " 'sight': 952,\n",
       " 'prediction': 953,\n",
       " 'arms': 954,\n",
       " 'hair': 955,\n",
       " 'kinky': 956,\n",
       " 'hands': 957,\n",
       " 'tied': 958,\n",
       " 'horse': 959,\n",
       " 'failed': 960,\n",
       " 'volunteers': 961,\n",
       " 'nothings': 962,\n",
       " 'missing': 963,\n",
       " 'cooks': 964,\n",
       " 'rich': 965,\n",
       " 'tvs': 966,\n",
       " 'boring': 967,\n",
       " 'wild': 968,\n",
       " 'mustve': 969,\n",
       " 'deal': 970,\n",
       " 'enemy': 971,\n",
       " 'meager': 972,\n",
       " 'plane': 973,\n",
       " 'crashed': 974,\n",
       " 'room': 975,\n",
       " 'melted': 976,\n",
       " 'bought': 977,\n",
       " 'dead': 978,\n",
       " 'fishing': 979,\n",
       " 'criminals': 980,\n",
       " 'theyve': 981,\n",
       " 'gone': 982,\n",
       " 'ludicrous': 983,\n",
       " 'mother': 984,\n",
       " 'tasteless': 985,\n",
       " 'saturday': 986,\n",
       " 'thursday': 987,\n",
       " 'follow': 988,\n",
       " 'suddenly': 989,\n",
       " 'potential': 990,\n",
       " 'hates': 991,\n",
       " 'spinach': 992,\n",
       " 'guy': 993,\n",
       " 'being': 994,\n",
       " 'downstairs': 995,\n",
       " 'gregarious': 996,\n",
       " 'control': 997,\n",
       " 'insightful': 998,\n",
       " 'miles': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.word_2_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpts = torch.tensor([5, 4, 2, 1, 2])\n",
    "\n",
    "encoder_outputs = torch.zeros([5, 1, 256]).cuda()\n",
    "encoder_hidden = encoder.init_hidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]], device='cuda:0')\n",
      "tensor([[927]], device='cuda:0')\n",
      "tensor([[30]], device='cuda:0')\n",
      "tensor([[26]], device='cuda:0')\n",
      "tensor([[18]], device='cuda:0')\n",
      "tensor([[27]], device='cuda:0')\n",
      "tensor([[18]], device='cuda:0')\n",
      "tensor([[1090]], device='cuda:0')\n",
      "tensor([[0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, inp in enumerate(inpts):\n",
    "        encoder_out, encoder_hidden = encoder(inp.cuda(), encoder_hidden)\n",
    "        encoder_outputs[i] = encoder_out\n",
    "\n",
    "    out = torch.tensor([1]).cuda() # EOS\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    for i in range(15):\n",
    "        # decoder output softmax of vocab size\n",
    "        decoder_out, decoder_hidden = decoder(out.cuda(), decoder_hidden, encoder_outputs)\n",
    "        # get the max value and the max index\n",
    "        topv, topi = decoder_out.topk(1)\n",
    "        # transform the max index in a tensor and feed it as an input\n",
    "        out = topi.detach().long().cuda()\n",
    "        print(out)\n",
    "        if out.item() == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
