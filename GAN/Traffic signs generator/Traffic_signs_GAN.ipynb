{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Traffic signs GAN.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C91bETbup3o1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6qeVUKwp3o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"C:\\\\Users\\\\Cordu\\\\traffic signs\\\\\"\n",
        "images = np.empty([len(os.listdir(path)),64,64,3])\n",
        "i = 0\n",
        "\n",
        "for file in os.listdir(path):\n",
        "    image = cv2.imread(path + file)\n",
        "    img = cv2.resize(image,(64,64))\n",
        "    im_array = np.asarray(img) / 255\n",
        "    images[i] = im_array\n",
        "    i = i + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjcLeWOgp3o6",
        "colab_type": "code",
        "outputId": "d950134c-61e0-4f8b-8568-b681d41301a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "im = images[542]\n",
        "print(im.shape)\n",
        "plt.imshow(im)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 64, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1c2f2b70ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-nMBBDOp3o9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c1bdb17-5fb8-4638-a3fd-2ed2aa820f8f"
      },
      "source": [
        "import keras\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Conv2DTranspose, GaussianNoise, InputLayer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UXOsxCJp3o_",
        "colab_type": "code",
        "outputId": "d33364f0-f65d-45a1-ebe9-603372b4cad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "source": [
        "def create_generator():\n",
        "    epsilon = 0.00001 # Small float added to variance to avoid dividing by zero in the BatchNorm layers.\n",
        "    noise_shape = (100,)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(4*4*512, activation='linear', input_shape=(100,)))\n",
        "    model.add(Reshape((4, 4, 512)))\n",
        "\n",
        "    model.add(Conv2DTranspose(256, kernel_size=[5,5], strides=[2,2], padding=\"same\",\n",
        "                              kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))\n",
        "    model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2DTranspose(256, kernel_size=[5,5], strides=[2,2], padding=\"same\",\n",
        "                              kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))\n",
        "    model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, kernel_size=[5,5], strides=[2,2], padding=\"same\",\n",
        "                              kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))\n",
        "    model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2DTranspose(64, kernel_size=[5,5], strides=[2,2], padding=\"same\",\n",
        "                              kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))\n",
        "    model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv2DTranspose(3, kernel_size=[5,5], strides=[1,1], padding=\"same\",\n",
        "                              kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))\n",
        "    # Standard activation for the generator of a GAN\n",
        "    model.add(Activation(\"tanh\"))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=(100,))\n",
        "    img = model(noise)\n",
        "\n",
        "    return Model(noise, img)\n",
        "\n",
        "generator = create_generator()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Cordu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 8192)              827392    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 256)         3277056   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 32, 32, 128)       819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTr (None, 64, 64, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTr (None, 64, 64, 3)         4803      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 64, 64, 3)         0         \n",
            "=================================================================\n",
            "Total params: 6,774,915\n",
            "Trainable params: 6,773,507\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hic0s_bdp3pC",
        "colab_type": "code",
        "outputId": "14c76816-3a04-4743-b6fd-b45070548ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        }
      },
      "source": [
        "def build_discriminator():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(64,64,3)))\n",
        "    model.add(GaussianNoise(0.2))\n",
        "    model.add(Conv2D(32, (3, 3), strides=[2,2],padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(.3))\n",
        "    model.add(Conv2D(64, (3, 3),strides=[2,2], kernel_initializer='he_uniform', padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(.3))\n",
        "    model.add(Conv2D(128, (3, 3),strides=[2,2], kernel_initializer='he_uniform', padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(.3))\n",
        "    model.add(Conv2D(256, (3, 3),strides=[2,2], kernel_initializer='he_uniform', padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(.3))\n",
        "    model.add(Conv2D(512, (3, 3),strides=[2,2], kernel_initializer='he_uniform', padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(.3))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "        \n",
        "    model.summary()\n",
        "        \n",
        "    img = Input(shape=(64,64,3))\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)\n",
        "\n",
        "discriminator = build_discriminator()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Cordu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gaussian_noise_1 (GaussianNo (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 2, 2, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,574,593\n",
            "Trainable params: 1,572,609\n",
            "Non-trainable params: 1,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j76eurUwp3pE",
        "colab_type": "code",
        "outputId": "61ab613a-e1b3-4c7b-ea61-9c5a2edb6178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "def get_gan():\n",
        "    model = Sequential()\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "gan = get_gan()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model_1 (Model)              (None, 64, 64, 3)         6774915   \n",
            "_________________________________________________________________\n",
            "model_2 (Model)              (None, 1)                 1574593   \n",
            "=================================================================\n",
            "Total params: 8,349,508\n",
            "Trainable params: 8,346,116\n",
            "Non-trainable params: 3,392\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSfT_8_Zp3pG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(0.0002,0.5)\n",
        "discriminator.compile(loss='binary_crossentropy', \n",
        "                                   optimizer=optimizer,\n",
        "                                   metrics=['accuracy'])\n",
        "discriminator.trainable = False\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZKmRkmkp3pI",
        "colab_type": "code",
        "outputId": "5e55c1e9-c694-4283-8c00-61d3f22213e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "discriminator = load_model('traffic_discriminator.h5')\n",
        "generator = load_model('traffic_generator.h5')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Cordu\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "  warnings.warn('Error in loading the saved optimizer '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9c56ANOp3pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "def save_images(epoch):\n",
        "        noise = np.random.normal(0, 1, [100, 100])\n",
        "        image_array = np.empty([25,64,64,3])\n",
        "        gen_imgs = generator.predict(noise)\n",
        "        image_count = 0\n",
        "        for i in range(5):\n",
        "                image_array[i] = gen_imgs[i]\n",
        "                im = np.asarray(image_array[i] * 255)\n",
        "                cv2.imwrite(\"C:\\\\Users\\\\Cordu\\\\trafficSigns2\\\\image_%d.png\" % (epoch + i) ,im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrqFsxurp3pN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a5fcc380-5f13-4779-dcae-5fa7a322f88a"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "epochs = 100000\n",
        "d_loss = [0,0]\n",
        "g_loss = 0\n",
        "mean_d_loss=[0,0]\n",
        "mean_g_loss=0\n",
        "\n",
        "def train_stuff():\n",
        "    d_loss = [0,0]\n",
        "    g_loss = 0\n",
        "    for i in range(epochs):\n",
        "        noise= np.random.normal(0,1, [64, 100])\n",
        "        fake_images = generator.predict(noise)\n",
        "        fake_output = np.full((64, 1), 0.9)\n",
        "        indexes = np.random.randint(0, len(os.listdir(path)), 64)\n",
        "        real_images = images[indexes]\n",
        "        real_output = np.ones((64,1))\n",
        "        d_loss = np.add(d_loss, discriminator.train_on_batch(fake_images, fake_output))\n",
        "        d_loss = np.add(d_loss, discriminator.train_on_batch(real_images, real_output))\n",
        "        d_loss = d_loss * 0.5\n",
        "        noise= np.random.normal(0,1, [128, 100])\n",
        "        g_loss += gan.train_on_batch(noise,np.full((128, 1), 1))\n",
        "        #g_loss += gan.train_on_batch(noise,np.full((128, 1), 1))\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print(d_loss)\n",
        "            print(g_loss)\n",
        "            d_loss = [0,0]\n",
        "            g_loss = 0\n",
        "            save_images(i)\n",
        "        if i % 1000 == 0:\n",
        "            discriminator.save('traffic_discriminator.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "            generator.save('traffic_generator.h5')\n",
        "\n",
        "                           \n",
        "train_stuff()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.17035612 0.5       ]\n",
            "0.07815942168235779\n",
            "[0.33682042 1.        ]\n",
            "6.099033806473017\n",
            "[0.33886766 1.        ]\n",
            "5.3131190445274115\n",
            "[0.34342051 1.        ]\n",
            "4.50166585482657\n",
            "[0.34292802 1.        ]\n",
            "4.338348468765616\n",
            "[0.33998114 1.        ]\n",
            "3.917978683486581\n",
            "[0.33958762 1.        ]\n",
            "3.592452509328723\n",
            "[0.33827457 1.        ]\n",
            "3.336326526477933\n",
            "[0.33809267 1.        ]\n",
            "3.051804857328534\n",
            "[0.3405548 1.       ]\n",
            "2.8630552031099796\n",
            "[0.3549954 1.       ]\n",
            "2.4260390289127827\n",
            "[0.3399342 1.       ]\n",
            "2.193451332859695\n",
            "[0.33610534 1.        ]\n",
            "1.922171564772725\n",
            "[0.3332523 1.       ]\n",
            "1.6771135870367289\n",
            "[0.34610835 1.        ]\n",
            "1.5498236482962966\n",
            "[0.33159786 1.        ]\n",
            "1.4178434247151017\n",
            "[0.33227175 1.        ]\n",
            "1.276349431835115\n",
            "[0.34106925 1.        ]\n",
            "1.115956143476069\n",
            "[0.34091549 1.        ]\n",
            "1.0503346603363752\n",
            "[0.34163408 1.        ]\n",
            "0.9602141892537475\n",
            "[0.33155591 1.        ]\n",
            "0.8803793219849467\n",
            "[0.3352328 1.       ]\n",
            "0.816393066663295\n",
            "[0.33421599 1.        ]\n",
            "0.7168760960921645\n",
            "[0.33207985 1.        ]\n",
            "0.6585962492972612\n",
            "[0.3347974 1.       ]\n",
            "0.6120770387351513\n",
            "[0.33512942 1.        ]\n",
            "0.5621649681124836\n",
            "[0.33781055 1.        ]\n",
            "0.5154625305440277\n",
            "[0.33238908 1.        ]\n",
            "0.4650051910430193\n",
            "[0.33059974 1.        ]\n",
            "0.433720616158098\n",
            "[0.33076199 1.        ]\n",
            "0.38985932106152177\n",
            "[0.33390312 1.        ]\n",
            "0.36979855387471616\n",
            "[0.33454699 1.        ]\n",
            "0.3390327622182667\n",
            "[0.33093283 1.        ]\n",
            "0.3126920668873936\n",
            "[0.3321721 1.       ]\n",
            "0.2873072676593438\n",
            "[0.33082545 1.        ]\n",
            "0.25870739738456905\n",
            "[0.33602876 1.        ]\n",
            "0.23818580573424697\n",
            "[0.33047827 1.        ]\n",
            "0.21251453482545912\n",
            "[0.33372333 1.        ]\n",
            "0.20010239025577903\n",
            "[0.32879363 1.        ]\n",
            "0.17631198244635016\n",
            "[0.33129075 1.        ]\n",
            "0.1585396773298271\n",
            "[0.32886131 1.        ]\n",
            "0.15339722618227825\n",
            "[0.329872 1.      ]\n",
            "0.13700258522294462\n",
            "[0.33234911 1.        ]\n",
            "0.11902372480835766\n",
            "[0.32860042 1.        ]\n",
            "0.11441146623110399\n",
            "[0.3284587 1.       ]\n",
            "0.10158853535540402\n",
            "[0.32866124 1.        ]\n",
            "0.09235832089325413\n",
            "[0.32927336 1.        ]\n",
            "0.0838679488224443\n",
            "[0.33184422 1.        ]\n",
            "0.07592142518842593\n",
            "[0.3279482 1.       ]\n",
            "0.07134902846883051\n",
            "[0.32892398 1.        ]\n",
            "0.06237254195730202\n",
            "[0.33438097 1.        ]\n",
            "0.060755252226954326\n",
            "[0.32978809 1.        ]\n",
            "0.05419593714759685\n",
            "[0.33060328 1.        ]\n",
            "0.05139456255710684\n",
            "[0.32706633 1.        ]\n",
            "0.046782043791608885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5JDxGQJp3pP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}