{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>255 254 255 254 254 179 122 107 95 124 149 150...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>30 24 21 23 25 25 49 67 84 103 120 125 130 139...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>39 75 78 58 58 45 49 48 103 156 81 45 41 38 49...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>219 213 206 202 209 217 216 215 219 218 223 23...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>148 144 130 129 119 122 129 131 139 153 140 12...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>4 2 13 41 56 62 67 87 95 62 65 70 80 107 127 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>107 107 109 109 109 109 110 101 123 140 144 14...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>14 14 18 28 27 22 21 30 42 61 77 86 88 95 100 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>255 255 255 255 255 255 255 255 255 255 255 25...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>134 124 167 180 197 194 203 210 204 203 209 20...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>219 192 179 148 208 254 192 98 121 103 145 185...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 7 12 23 45 38 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>174 51 37 37 38 41 22 25 22 24 35 51 70 83 98 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>123 125 124 142 209 226 234 236 231 232 235 22...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>8 9 14 21 26 32 37 46 52 62 72 70 71 73 76 83 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>252 250 246 229 182 140 98 72 53 44 67 95 95 8...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>224 227 219 217 215 210 187 177 189 200 206 21...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>162 200 187 180 197 198 196 192 176 152 136 11...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>236 230 225 226 228 209 199 193 196 211 199 19...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>210 210 210 210 211 207 147 103 68 60 47 70 12...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>50 44 74 141 187 187 169 113 80 128 181 172 76...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35857</th>\n",
       "      <td>5</td>\n",
       "      <td>253 255 229 150 89 61 54 60 55 49 61 50 56 45 ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35858</th>\n",
       "      <td>4</td>\n",
       "      <td>11 11 11 13 20 27 38 41 38 34 20 13 10 39 85 1...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35859</th>\n",
       "      <td>4</td>\n",
       "      <td>11 13 16 27 24 26 89 161 190 197 201 206 210 2...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35860</th>\n",
       "      <td>3</td>\n",
       "      <td>27 42 62 91 112 118 122 123 119 124 129 131 13...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35861</th>\n",
       "      <td>6</td>\n",
       "      <td>233 232 208 188 194 179 177 167 157 180 185 19...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35862</th>\n",
       "      <td>2</td>\n",
       "      <td>73 54 63 76 82 71 67 69 73 72 92 98 117 119 14...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35863</th>\n",
       "      <td>5</td>\n",
       "      <td>196 196 197 197 198 198 198 196 176 148 122 10...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35864</th>\n",
       "      <td>4</td>\n",
       "      <td>68 59 65 78 118 131 137 141 142 135 135 137 13...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35865</th>\n",
       "      <td>3</td>\n",
       "      <td>102 109 109 106 104 107 112 109 116 119 117 12...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35866</th>\n",
       "      <td>6</td>\n",
       "      <td>87 82 59 61 72 102 143 130 90 95 143 173 146 1...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35867</th>\n",
       "      <td>3</td>\n",
       "      <td>198 198 197 196 196 197 196 196 196 195 196 18...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35868</th>\n",
       "      <td>2</td>\n",
       "      <td>204 209 215 218 214 214 214 217 205 175 170 16...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35869</th>\n",
       "      <td>3</td>\n",
       "      <td>217 220 222 223 223 224 225 223 223 225 223 22...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35870</th>\n",
       "      <td>2</td>\n",
       "      <td>6 8 4 5 30 48 61 70 76 79 98 117 130 137 143 1...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35871</th>\n",
       "      <td>6</td>\n",
       "      <td>112 102 98 89 98 133 164 185 180 179 185 169 1...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35872</th>\n",
       "      <td>5</td>\n",
       "      <td>131 159 90 59 10 0 1 1 1 0 1 1 0 0 2 2 5 7 9 1...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35873</th>\n",
       "      <td>4</td>\n",
       "      <td>54 57 77 122 121 76 73 80 58 22 26 27 35 41 66...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35874</th>\n",
       "      <td>5</td>\n",
       "      <td>43 43 51 73 94 97 102 95 99 107 126 144 154 17...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35875</th>\n",
       "      <td>5</td>\n",
       "      <td>248 251 239 144 102 95 82 77 91 138 153 145 14...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35876</th>\n",
       "      <td>6</td>\n",
       "      <td>29 29 27 31 49 56 29 19 22 20 34 43 55 71 85 9...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35877</th>\n",
       "      <td>6</td>\n",
       "      <td>139 143 145 154 159 168 176 181 190 191 195 19...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35878</th>\n",
       "      <td>3</td>\n",
       "      <td>0 39 81 80 104 97 51 64 68 46 41 67 53 68 70 5...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35879</th>\n",
       "      <td>2</td>\n",
       "      <td>0 0 6 16 19 31 47 18 26 19 17 8 15 3 4 2 14 20...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35880</th>\n",
       "      <td>2</td>\n",
       "      <td>164 172 175 171 172 173 178 181 188 192 197 20...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35881</th>\n",
       "      <td>0</td>\n",
       "      <td>181 177 176 156 178 144 136 132 122 107 131 16...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>6</td>\n",
       "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>3</td>\n",
       "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>2</td>\n",
       "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35887 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                             pixels        Usage\n",
       "0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n",
       "1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n",
       "2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n",
       "3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n",
       "4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n",
       "5            2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...     Training\n",
       "6            4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...     Training\n",
       "7            3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...     Training\n",
       "8            3  85 84 90 121 101 102 133 153 153 169 177 189 1...     Training\n",
       "9            2  255 254 255 254 254 179 122 107 95 124 149 150...     Training\n",
       "10           0  30 24 21 23 25 25 49 67 84 103 120 125 130 139...     Training\n",
       "11           6  39 75 78 58 58 45 49 48 103 156 81 45 41 38 49...     Training\n",
       "12           6  219 213 206 202 209 217 216 215 219 218 223 23...     Training\n",
       "13           6  148 144 130 129 119 122 129 131 139 153 140 12...     Training\n",
       "14           3  4 2 13 41 56 62 67 87 95 62 65 70 80 107 127 1...     Training\n",
       "15           5  107 107 109 109 109 109 110 101 123 140 144 14...     Training\n",
       "16           3  14 14 18 28 27 22 21 30 42 61 77 86 88 95 100 ...     Training\n",
       "17           2  255 255 255 255 255 255 255 255 255 255 255 25...     Training\n",
       "18           6  134 124 167 180 197 194 203 210 204 203 209 20...     Training\n",
       "19           4  219 192 179 148 208 254 192 98 121 103 145 185...     Training\n",
       "20           4  1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 7 12 23 45 38 ...     Training\n",
       "21           2  174 51 37 37 38 41 22 25 22 24 35 51 70 83 98 ...     Training\n",
       "22           0  123 125 124 142 209 226 234 236 231 232 235 22...     Training\n",
       "23           0  8 9 14 21 26 32 37 46 52 62 72 70 71 73 76 83 ...     Training\n",
       "24           3  252 250 246 229 182 140 98 72 53 44 67 95 95 8...     Training\n",
       "25           3  224 227 219 217 215 210 187 177 189 200 206 21...     Training\n",
       "26           5  162 200 187 180 197 198 196 192 176 152 136 11...     Training\n",
       "27           0  236 230 225 226 228 209 199 193 196 211 199 19...     Training\n",
       "28           3  210 210 210 210 211 207 147 103 68 60 47 70 12...     Training\n",
       "29           5  50 44 74 141 187 187 169 113 80 128 181 172 76...     Training\n",
       "...        ...                                                ...          ...\n",
       "35857        5  253 255 229 150 89 61 54 60 55 49 61 50 56 45 ...  PrivateTest\n",
       "35858        4  11 11 11 13 20 27 38 41 38 34 20 13 10 39 85 1...  PrivateTest\n",
       "35859        4  11 13 16 27 24 26 89 161 190 197 201 206 210 2...  PrivateTest\n",
       "35860        3  27 42 62 91 112 118 122 123 119 124 129 131 13...  PrivateTest\n",
       "35861        6  233 232 208 188 194 179 177 167 157 180 185 19...  PrivateTest\n",
       "35862        2  73 54 63 76 82 71 67 69 73 72 92 98 117 119 14...  PrivateTest\n",
       "35863        5  196 196 197 197 198 198 198 196 176 148 122 10...  PrivateTest\n",
       "35864        4  68 59 65 78 118 131 137 141 142 135 135 137 13...  PrivateTest\n",
       "35865        3  102 109 109 106 104 107 112 109 116 119 117 12...  PrivateTest\n",
       "35866        6  87 82 59 61 72 102 143 130 90 95 143 173 146 1...  PrivateTest\n",
       "35867        3  198 198 197 196 196 197 196 196 196 195 196 18...  PrivateTest\n",
       "35868        2  204 209 215 218 214 214 214 217 205 175 170 16...  PrivateTest\n",
       "35869        3  217 220 222 223 223 224 225 223 223 225 223 22...  PrivateTest\n",
       "35870        2  6 8 4 5 30 48 61 70 76 79 98 117 130 137 143 1...  PrivateTest\n",
       "35871        6  112 102 98 89 98 133 164 185 180 179 185 169 1...  PrivateTest\n",
       "35872        5  131 159 90 59 10 0 1 1 1 0 1 1 0 0 2 2 5 7 9 1...  PrivateTest\n",
       "35873        4  54 57 77 122 121 76 73 80 58 22 26 27 35 41 66...  PrivateTest\n",
       "35874        5  43 43 51 73 94 97 102 95 99 107 126 144 154 17...  PrivateTest\n",
       "35875        5  248 251 239 144 102 95 82 77 91 138 153 145 14...  PrivateTest\n",
       "35876        6  29 29 27 31 49 56 29 19 22 20 34 43 55 71 85 9...  PrivateTest\n",
       "35877        6  139 143 145 154 159 168 176 181 190 191 195 19...  PrivateTest\n",
       "35878        3  0 39 81 80 104 97 51 64 68 46 41 67 53 68 70 5...  PrivateTest\n",
       "35879        2  0 0 6 16 19 31 47 18 26 19 17 8 15 3 4 2 14 20...  PrivateTest\n",
       "35880        2  164 172 175 171 172 173 178 181 188 192 197 20...  PrivateTest\n",
       "35881        0  181 177 176 156 178 144 136 132 122 107 131 16...  PrivateTest\n",
       "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
       "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
       "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
       "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
       "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n",
       "\n",
       "[35887 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('fer2013.csv')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate de data as input and output\n",
    "\n",
    "x_train_ps = dataframe[\"pixels\"].to_numpy()\n",
    "y_train_ps = dataframe[\"emotion\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "\n",
    "\n",
    "def process_input(panda_dataframe):\n",
    "    x = np.empty(shape=(len(panda_dataframe), 48, 48))\n",
    "    i = 0\n",
    "    for line in panda_dataframe:\n",
    "        arranged_line = np.fromstring(line, dtype=int, sep=' ').reshape((48, 48)) / 255\n",
    "        if i != 0:\n",
    "            x[i] = arranged_line\n",
    "        else:\n",
    "            x[i] = arranged_line    \n",
    "        i = i + 1\n",
    "        update_progress(i / len(panda_dataframe))\n",
    "    return x\n",
    "\n",
    "\n",
    "def process_output(panda_dataframe):\n",
    "    x = np.zeros([len(panda_dataframe),7])\n",
    "    i = 0\n",
    "    for line in panda_dataframe:\n",
    "        x[i][line] = 1.0\n",
    "        i = i + 1\n",
    "        update_progress(i / len(panda_dataframe))\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "faces = process_input(x_train_ps)\n",
    "emotions = process_output(y_train_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imgplot = plt.imshow(faces[553])\n",
    "\n",
    "np.save('faces', faces)\n",
    "np.save('emotions', emotions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 1000\n",
    "input_shape = (48, 48,1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same',\n",
    "                        name='image_array', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Convolution2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Convolution2D(filters=num_classes, kernel_size=(3, 3), padding='same'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax',name='predictions'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_array (Conv2D)         (None, 48, 48, 16)        800       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 48, 48, 16)        12560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 24, 24, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_7 (Average (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 6, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 7)           16135     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "predictions (Activation)     (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 642,935\n",
      "Trainable params: 641,463\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Cordu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "897/897 [==============================] - 31s 34ms/step - loss: 1.7694 - acc: 0.2893 - val_loss: 1.6943 - val_acc: 0.3193\n",
      "Epoch 2/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.6365 - acc: 0.3531 - val_loss: 1.5549 - val_acc: 0.3732\n",
      "Epoch 3/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.5761 - acc: 0.3817 - val_loss: 1.5459 - val_acc: 0.3973\n",
      "Epoch 4/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.5301 - acc: 0.3995 - val_loss: 1.3989 - val_acc: 0.4505\n",
      "Epoch 5/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.4864 - acc: 0.4206 - val_loss: 1.3911 - val_acc: 0.4597\n",
      "Epoch 6/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.4559 - acc: 0.4327 - val_loss: 1.3367 - val_acc: 0.4960\n",
      "Epoch 7/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.4309 - acc: 0.4475 - val_loss: 1.3077 - val_acc: 0.4965\n",
      "Epoch 8/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.4110 - acc: 0.4594 - val_loss: 1.2916 - val_acc: 0.5075\n",
      "Epoch 9/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.3984 - acc: 0.4638 - val_loss: 1.2591 - val_acc: 0.5220\n",
      "Epoch 10/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.3835 - acc: 0.4691 - val_loss: 1.2583 - val_acc: 0.5166\n",
      "Epoch 11/1000\n",
      "897/897 [==============================] - 18s 20ms/step - loss: 1.3748 - acc: 0.4746 - val_loss: 1.2163 - val_acc: 0.5386\n",
      "Epoch 12/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.3648 - acc: 0.4763 - val_loss: 1.2588 - val_acc: 0.5111\n",
      "Epoch 13/1000\n",
      "897/897 [==============================] - 18s 21ms/step - loss: 1.3500 - acc: 0.4848 - val_loss: 1.1997 - val_acc: 0.5492\n",
      "Epoch 14/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.3432 - acc: 0.4841 - val_loss: 1.1894 - val_acc: 0.5474\n",
      "Epoch 15/1000\n",
      "897/897 [==============================] - 18s 21ms/step - loss: 1.3379 - acc: 0.4860 - val_loss: 1.1887 - val_acc: 0.5563\n",
      "Epoch 16/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.3274 - acc: 0.4926 - val_loss: 1.1789 - val_acc: 0.5542\n",
      "Epoch 17/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.3261 - acc: 0.4953 - val_loss: 1.1636 - val_acc: 0.5578\n",
      "Epoch 18/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.3192 - acc: 0.4969 - val_loss: 1.1774 - val_acc: 0.5514\n",
      "Epoch 19/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.3160 - acc: 0.4969 - val_loss: 1.1564 - val_acc: 0.5637\n",
      "Epoch 20/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.3138 - acc: 0.4991 - val_loss: 1.1557 - val_acc: 0.5613\n",
      "Epoch 21/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.3010 - acc: 0.5018 - val_loss: 1.1966 - val_acc: 0.5528\n",
      "Epoch 22/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.3076 - acc: 0.5042 - val_loss: 1.1390 - val_acc: 0.5687\n",
      "Epoch 23/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.3000 - acc: 0.5066 - val_loss: 1.1311 - val_acc: 0.5684\n",
      "Epoch 24/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.3005 - acc: 0.5039 - val_loss: 1.1318 - val_acc: 0.5726\n",
      "Epoch 25/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.2844 - acc: 0.5126 - val_loss: 1.1428 - val_acc: 0.5756\n",
      "Epoch 26/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2925 - acc: 0.5091 - val_loss: 1.1351 - val_acc: 0.5673\n",
      "Epoch 27/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2776 - acc: 0.5131 - val_loss: 1.1430 - val_acc: 0.5632\n",
      "Epoch 28/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2842 - acc: 0.5098 - val_loss: 1.1341 - val_acc: 0.5706\n",
      "Epoch 29/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2763 - acc: 0.5144 - val_loss: 1.1185 - val_acc: 0.5762\n",
      "Epoch 30/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2721 - acc: 0.5163 - val_loss: 1.1224 - val_acc: 0.5761\n",
      "Epoch 31/1000\n",
      "897/897 [==============================] - 18s 20ms/step - loss: 1.2749 - acc: 0.5164 - val_loss: 1.1058 - val_acc: 0.5762\n",
      "Epoch 32/1000\n",
      "897/897 [==============================] - 18s 20ms/step - loss: 1.2707 - acc: 0.5177 - val_loss: 1.1101 - val_acc: 0.5809\n",
      "Epoch 33/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2654 - acc: 0.5205 - val_loss: 1.1122 - val_acc: 0.5794\n",
      "Epoch 34/1000\n",
      "897/897 [==============================] - 18s 20ms/step - loss: 1.2616 - acc: 0.5206 - val_loss: 1.1169 - val_acc: 0.5737\n",
      "Epoch 35/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2669 - acc: 0.5184 - val_loss: 1.1079 - val_acc: 0.5754\n",
      "Epoch 36/1000\n",
      "897/897 [==============================] - 18s 20ms/step - loss: 1.2649 - acc: 0.5200 - val_loss: 1.1106 - val_acc: 0.5761\n",
      "Epoch 37/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2666 - acc: 0.5216 - val_loss: 1.1042 - val_acc: 0.5816\n",
      "Epoch 38/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2608 - acc: 0.5172 - val_loss: 1.0950 - val_acc: 0.5801\n",
      "Epoch 39/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.2604 - acc: 0.5204 - val_loss: 1.0887 - val_acc: 0.5855\n",
      "Epoch 40/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2574 - acc: 0.5223 - val_loss: 1.0936 - val_acc: 0.5828\n",
      "Epoch 41/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2493 - acc: 0.5260 - val_loss: 1.0927 - val_acc: 0.5871\n",
      "Epoch 42/1000\n",
      "897/897 [==============================] - 18s 21ms/step - loss: 1.2551 - acc: 0.5224 - val_loss: 1.1168 - val_acc: 0.5744\n",
      "Epoch 43/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2488 - acc: 0.5261 - val_loss: 1.0787 - val_acc: 0.5906\n",
      "Epoch 44/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2494 - acc: 0.5263 - val_loss: 1.0838 - val_acc: 0.5847\n",
      "Epoch 45/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2480 - acc: 0.5279 - val_loss: 1.0798 - val_acc: 0.5929\n",
      "Epoch 46/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2519 - acc: 0.5263 - val_loss: 1.0914 - val_acc: 0.5830\n",
      "Epoch 47/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2455 - acc: 0.5240 - val_loss: 1.0680 - val_acc: 0.6011\n",
      "Epoch 48/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2428 - acc: 0.5260 - val_loss: 1.0859 - val_acc: 0.5893\n",
      "Epoch 49/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2437 - acc: 0.5255 - val_loss: 1.0946 - val_acc: 0.5862\n",
      "Epoch 50/1000\n",
      "897/897 [==============================] - 18s 20ms/step - loss: 1.2381 - acc: 0.5298 - val_loss: 1.0650 - val_acc: 0.5965\n",
      "Epoch 51/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2365 - acc: 0.5300 - val_loss: 1.0755 - val_acc: 0.5893\n",
      "Epoch 52/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2383 - acc: 0.5294 - val_loss: 1.0832 - val_acc: 0.5926\n",
      "Epoch 53/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2377 - acc: 0.5257 - val_loss: 1.0709 - val_acc: 0.5950\n",
      "Epoch 54/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2374 - acc: 0.5287 - val_loss: 1.0842 - val_acc: 0.5833\n",
      "Epoch 55/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2284 - acc: 0.5299 - val_loss: 1.0780 - val_acc: 0.5914\n",
      "Epoch 56/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2333 - acc: 0.5300 - val_loss: 1.0703 - val_acc: 0.5942\n",
      "Epoch 57/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2351 - acc: 0.5295 - val_loss: 1.1076 - val_acc: 0.5812\n",
      "Epoch 58/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2340 - acc: 0.5300 - val_loss: 1.0701 - val_acc: 0.5942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2312 - acc: 0.5331 - val_loss: 1.0868 - val_acc: 0.5861\n",
      "Epoch 60/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2256 - acc: 0.5328 - val_loss: 1.0883 - val_acc: 0.5809\n",
      "Epoch 61/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2333 - acc: 0.5311 - val_loss: 1.0758 - val_acc: 0.5928\n",
      "Epoch 62/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2224 - acc: 0.5356 - val_loss: 1.0940 - val_acc: 0.5899\n",
      "Epoch 63/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2261 - acc: 0.5335 - val_loss: 1.0729 - val_acc: 0.5917\n",
      "Epoch 64/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2261 - acc: 0.5345 - val_loss: 1.0789 - val_acc: 0.5883\n",
      "Epoch 65/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.2214 - acc: 0.5352 - val_loss: 1.0561 - val_acc: 0.5989\n",
      "Epoch 66/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2223 - acc: 0.5340 - val_loss: 1.0591 - val_acc: 0.5965\n",
      "Epoch 67/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.2214 - acc: 0.5367 - val_loss: 1.0413 - val_acc: 0.6067\n",
      "Epoch 68/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2187 - acc: 0.5330 - val_loss: 1.0617 - val_acc: 0.5921\n",
      "Epoch 69/1000\n",
      "897/897 [==============================] - 18s 20ms/step - loss: 1.2231 - acc: 0.5365 - val_loss: 1.0632 - val_acc: 0.5943\n",
      "Epoch 70/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2161 - acc: 0.5363 - val_loss: 1.0590 - val_acc: 0.5935\n",
      "Epoch 71/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2205 - acc: 0.5334 - val_loss: 1.0533 - val_acc: 0.5995\n",
      "Epoch 72/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2153 - acc: 0.5371 - val_loss: 1.0661 - val_acc: 0.5952\n",
      "Epoch 73/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2147 - acc: 0.5367 - val_loss: 1.0635 - val_acc: 0.5922\n",
      "Epoch 74/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2157 - acc: 0.5375 - val_loss: 1.0580 - val_acc: 0.5991\n",
      "Epoch 75/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2160 - acc: 0.5411 - val_loss: 1.0803 - val_acc: 0.5876\n",
      "Epoch 76/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.2150 - acc: 0.5385 - val_loss: 1.0544 - val_acc: 0.6048\n",
      "Epoch 77/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2183 - acc: 0.5372 - val_loss: 1.0575 - val_acc: 0.5993\n",
      "Epoch 78/1000\n",
      "897/897 [==============================] - 18s 21ms/step - loss: 1.2137 - acc: 0.5366 - val_loss: 1.0793 - val_acc: 0.5935\n",
      "Epoch 79/1000\n",
      "897/897 [==============================] - 18s 20ms/step - loss: 1.2093 - acc: 0.5428 - val_loss: 1.0534 - val_acc: 0.6003\n",
      "Epoch 80/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2131 - acc: 0.5389 - val_loss: 1.0519 - val_acc: 0.6021\n",
      "Epoch 81/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.2111 - acc: 0.5387 - val_loss: 1.0334 - val_acc: 0.6085\n",
      "Epoch 82/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2088 - acc: 0.5418 - val_loss: 1.0364 - val_acc: 0.6091\n",
      "Epoch 83/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2096 - acc: 0.5410 - val_loss: 1.0443 - val_acc: 0.6027\n",
      "Epoch 84/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2079 - acc: 0.5405 - val_loss: 1.0544 - val_acc: 0.6046\n",
      "Epoch 85/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2090 - acc: 0.5412 - val_loss: 1.0636 - val_acc: 0.6003\n",
      "Epoch 86/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2039 - acc: 0.5412 - val_loss: 1.0653 - val_acc: 0.5997\n",
      "Epoch 87/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2027 - acc: 0.5450 - val_loss: 1.0390 - val_acc: 0.6067\n",
      "Epoch 88/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2081 - acc: 0.5426 - val_loss: 1.0437 - val_acc: 0.6077\n",
      "Epoch 89/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.2061 - acc: 0.5385 - val_loss: 1.0326 - val_acc: 0.6067\n",
      "Epoch 90/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.2070 - acc: 0.5421 - val_loss: 1.0653 - val_acc: 0.5929\n",
      "Epoch 91/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1998 - acc: 0.5467 - val_loss: 1.0401 - val_acc: 0.6095\n",
      "Epoch 92/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.2082 - acc: 0.5423 - val_loss: 1.0533 - val_acc: 0.5972\n",
      "Epoch 93/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1993 - acc: 0.5456 - val_loss: 1.0560 - val_acc: 0.6110\n",
      "Epoch 94/1000\n",
      "897/897 [==============================] - 18s 21ms/step - loss: 1.1998 - acc: 0.5399 - val_loss: 1.0565 - val_acc: 0.6052\n",
      "Epoch 95/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1965 - acc: 0.5433 - val_loss: 1.0288 - val_acc: 0.6106\n",
      "Epoch 96/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1967 - acc: 0.5475 - val_loss: 1.0470 - val_acc: 0.6084\n",
      "Epoch 97/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2025 - acc: 0.5418 - val_loss: 1.0499 - val_acc: 0.6066\n",
      "Epoch 98/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.2030 - acc: 0.5437 - val_loss: 1.0486 - val_acc: 0.6020\n",
      "Epoch 99/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1992 - acc: 0.5449 - val_loss: 1.0395 - val_acc: 0.6067\n",
      "Epoch 100/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1945 - acc: 0.5439 - val_loss: 1.0375 - val_acc: 0.6126\n",
      "Epoch 101/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1923 - acc: 0.5485 - val_loss: 1.0494 - val_acc: 0.6011\n",
      "Epoch 102/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1965 - acc: 0.5437 - val_loss: 1.0510 - val_acc: 0.6013\n",
      "Epoch 103/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1923 - acc: 0.5505 - val_loss: 1.0248 - val_acc: 0.6141\n",
      "Epoch 104/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1925 - acc: 0.5478 - val_loss: 1.0303 - val_acc: 0.6137\n",
      "Epoch 105/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1986 - acc: 0.5455 - val_loss: 1.0495 - val_acc: 0.6035\n",
      "Epoch 106/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1882 - acc: 0.5486 - val_loss: 1.0514 - val_acc: 0.6028\n",
      "Epoch 107/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.2001 - acc: 0.5415 - val_loss: 1.0542 - val_acc: 0.5971\n",
      "Epoch 108/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1927 - acc: 0.5460 - val_loss: 1.0401 - val_acc: 0.6003\n",
      "Epoch 109/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1875 - acc: 0.5515 - val_loss: 1.0377 - val_acc: 0.6043\n",
      "Epoch 110/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1935 - acc: 0.5433 - val_loss: 1.0431 - val_acc: 0.6089\n",
      "Epoch 111/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1952 - acc: 0.5440 - val_loss: 1.0388 - val_acc: 0.6027\n",
      "Epoch 112/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1821 - acc: 0.5531 - val_loss: 1.0436 - val_acc: 0.6023\n",
      "Epoch 113/1000\n",
      "897/897 [==============================] - 18s 21ms/step - loss: 1.1888 - acc: 0.5518 - val_loss: 1.0407 - val_acc: 0.6069\n",
      "Epoch 114/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1907 - acc: 0.5506 - val_loss: 1.0448 - val_acc: 0.6023\n",
      "Epoch 115/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1864 - acc: 0.5486 - val_loss: 1.0323 - val_acc: 0.6110\n",
      "Epoch 116/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1972 - acc: 0.5460 - val_loss: 1.0451 - val_acc: 0.5995\n",
      "Epoch 117/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1845 - acc: 0.5509 - val_loss: 1.0259 - val_acc: 0.6120\n",
      "Epoch 118/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1907 - acc: 0.5475 - val_loss: 1.0223 - val_acc: 0.6177\n",
      "Epoch 119/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1845 - acc: 0.5527 - val_loss: 1.0480 - val_acc: 0.6064\n",
      "Epoch 120/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1931 - acc: 0.5490 - val_loss: 1.0346 - val_acc: 0.6106\n",
      "Epoch 121/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1904 - acc: 0.5485 - val_loss: 1.0365 - val_acc: 0.6110\n",
      "Epoch 122/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1872 - acc: 0.5511 - val_loss: 1.0864 - val_acc: 0.5913\n",
      "Epoch 123/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1890 - acc: 0.5474 - val_loss: 1.0300 - val_acc: 0.6144\n",
      "Epoch 124/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1862 - acc: 0.5515 - val_loss: 1.0328 - val_acc: 0.6112\n",
      "Epoch 125/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1888 - acc: 0.5511 - val_loss: 1.0658 - val_acc: 0.6039\n",
      "Epoch 126/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1825 - acc: 0.5502 - val_loss: 1.0253 - val_acc: 0.6135\n",
      "Epoch 127/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1910 - acc: 0.5501 - val_loss: 1.0265 - val_acc: 0.6112\n",
      "Epoch 128/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1849 - acc: 0.5507 - val_loss: 1.0281 - val_acc: 0.6142\n",
      "Epoch 129/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1788 - acc: 0.5507 - val_loss: 1.0253 - val_acc: 0.6119\n",
      "Epoch 130/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1859 - acc: 0.5477 - val_loss: 1.0235 - val_acc: 0.6163\n",
      "Epoch 131/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1849 - acc: 0.5497 - val_loss: 1.0250 - val_acc: 0.6108\n",
      "Epoch 132/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1836 - acc: 0.5498 - val_loss: 1.0366 - val_acc: 0.6115\n",
      "Epoch 133/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1809 - acc: 0.5510 - val_loss: 1.0357 - val_acc: 0.6103\n",
      "Epoch 134/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1810 - acc: 0.5528 - val_loss: 1.0379 - val_acc: 0.6074\n",
      "Epoch 135/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1869 - acc: 0.5512 - val_loss: 1.0291 - val_acc: 0.6124\n",
      "Epoch 136/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1825 - acc: 0.5506 - val_loss: 1.0307 - val_acc: 0.6138\n",
      "Epoch 137/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1813 - acc: 0.5482 - val_loss: 1.0917 - val_acc: 0.5851\n",
      "Epoch 138/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1759 - acc: 0.5532 - val_loss: 1.0262 - val_acc: 0.6147\n",
      "Epoch 139/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1834 - acc: 0.5510 - val_loss: 1.0209 - val_acc: 0.6137\n",
      "Epoch 140/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1789 - acc: 0.5503 - val_loss: 1.0244 - val_acc: 0.6147\n",
      "Epoch 141/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1809 - acc: 0.5520 - val_loss: 1.0224 - val_acc: 0.6170\n",
      "Epoch 142/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1798 - acc: 0.5515 - val_loss: 1.0270 - val_acc: 0.6099\n",
      "Epoch 143/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1843 - acc: 0.5520 - val_loss: 1.0429 - val_acc: 0.6091\n",
      "Epoch 144/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1806 - acc: 0.5508 - val_loss: 1.0180 - val_acc: 0.6167\n",
      "Epoch 145/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1798 - acc: 0.5505 - val_loss: 1.0219 - val_acc: 0.6127\n",
      "Epoch 146/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1765 - acc: 0.5526 - val_loss: 1.0184 - val_acc: 0.6170\n",
      "Epoch 147/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1720 - acc: 0.5539 - val_loss: 1.0376 - val_acc: 0.6166\n",
      "Epoch 148/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1753 - acc: 0.5516 - val_loss: 1.0052 - val_acc: 0.6194\n",
      "Epoch 149/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1824 - acc: 0.5492 - val_loss: 1.0327 - val_acc: 0.6078\n",
      "Epoch 150/1000\n",
      "897/897 [==============================] - 21s 23ms/step - loss: 1.1743 - acc: 0.5538 - val_loss: 1.0247 - val_acc: 0.6156\n",
      "Epoch 151/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1757 - acc: 0.5554 - val_loss: 1.0080 - val_acc: 0.6201\n",
      "Epoch 152/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1781 - acc: 0.5515 - val_loss: 1.0037 - val_acc: 0.6218\n",
      "Epoch 153/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1796 - acc: 0.5507 - val_loss: 1.0115 - val_acc: 0.6212\n",
      "Epoch 154/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1830 - acc: 0.5480 - val_loss: 1.0213 - val_acc: 0.6127\n",
      "Epoch 155/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1733 - acc: 0.5532 - val_loss: 1.0183 - val_acc: 0.6163\n",
      "Epoch 156/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1821 - acc: 0.5480 - val_loss: 1.0132 - val_acc: 0.6151\n",
      "Epoch 157/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1738 - acc: 0.5520 - val_loss: 1.0107 - val_acc: 0.6174\n",
      "Epoch 158/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1760 - acc: 0.5577 - val_loss: 1.0233 - val_acc: 0.6106\n",
      "Epoch 159/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1761 - acc: 0.5545 - val_loss: 1.0266 - val_acc: 0.6116\n",
      "Epoch 160/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1753 - acc: 0.5548 - val_loss: 1.0140 - val_acc: 0.6195\n",
      "Epoch 161/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1766 - acc: 0.5492 - val_loss: 1.0177 - val_acc: 0.6165\n",
      "Epoch 162/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1745 - acc: 0.5542 - val_loss: 1.0048 - val_acc: 0.6230\n",
      "Epoch 163/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1669 - acc: 0.5544 - val_loss: 1.0114 - val_acc: 0.6184\n",
      "Epoch 164/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1735 - acc: 0.5541 - val_loss: 1.0090 - val_acc: 0.6167\n",
      "Epoch 165/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1828 - acc: 0.5507 - val_loss: 1.0144 - val_acc: 0.6154\n",
      "Epoch 166/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1745 - acc: 0.5539 - val_loss: 1.0178 - val_acc: 0.6160\n",
      "Epoch 167/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1718 - acc: 0.5551 - val_loss: 1.0306 - val_acc: 0.6055\n",
      "Epoch 168/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1674 - acc: 0.5577 - val_loss: 1.0078 - val_acc: 0.6174\n",
      "Epoch 169/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1761 - acc: 0.5565 - val_loss: 1.0282 - val_acc: 0.6110\n",
      "Epoch 170/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1713 - acc: 0.5547 - val_loss: 1.0083 - val_acc: 0.6209\n",
      "Epoch 171/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1648 - acc: 0.5572 - val_loss: 0.9991 - val_acc: 0.6234\n",
      "Epoch 172/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1723 - acc: 0.5541 - val_loss: 1.0166 - val_acc: 0.6167\n",
      "Epoch 173/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1722 - acc: 0.5539 - val_loss: 1.0181 - val_acc: 0.6167\n",
      "Epoch 174/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1740 - acc: 0.5505 - val_loss: 1.0142 - val_acc: 0.6170\n",
      "Epoch 175/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1740 - acc: 0.5558 - val_loss: 1.0158 - val_acc: 0.6177\n",
      "Epoch 176/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1686 - acc: 0.5523 - val_loss: 1.0213 - val_acc: 0.6134\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1692 - acc: 0.5554 - val_loss: 1.0104 - val_acc: 0.6156\n",
      "Epoch 178/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1631 - acc: 0.5601 - val_loss: 1.0196 - val_acc: 0.6124\n",
      "Epoch 179/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1712 - acc: 0.5567 - val_loss: 1.0112 - val_acc: 0.6167\n",
      "Epoch 180/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1687 - acc: 0.5563 - val_loss: 1.0163 - val_acc: 0.6223\n",
      "Epoch 181/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1723 - acc: 0.5542 - val_loss: 1.0174 - val_acc: 0.6155\n",
      "Epoch 182/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1696 - acc: 0.5580 - val_loss: 1.0123 - val_acc: 0.6149\n",
      "Epoch 183/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1669 - acc: 0.5578 - val_loss: 1.0088 - val_acc: 0.6218\n",
      "Epoch 184/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1708 - acc: 0.5593 - val_loss: 1.0026 - val_acc: 0.6247\n",
      "Epoch 185/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1664 - acc: 0.5581 - val_loss: 0.9977 - val_acc: 0.6230\n",
      "Epoch 186/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1633 - acc: 0.5602 - val_loss: 1.0041 - val_acc: 0.6206\n",
      "Epoch 187/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1661 - acc: 0.5596 - val_loss: 1.0063 - val_acc: 0.6183\n",
      "Epoch 188/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1602 - acc: 0.5589 - val_loss: 1.0086 - val_acc: 0.6191\n",
      "Epoch 189/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1742 - acc: 0.5568 - val_loss: 1.0041 - val_acc: 0.6199\n",
      "Epoch 190/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1601 - acc: 0.5577 - val_loss: 1.0266 - val_acc: 0.6062\n",
      "Epoch 191/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1691 - acc: 0.5598 - val_loss: 0.9898 - val_acc: 0.6293\n",
      "Epoch 192/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1570 - acc: 0.5605 - val_loss: 1.0016 - val_acc: 0.6188\n",
      "Epoch 193/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1638 - acc: 0.5572 - val_loss: 1.0107 - val_acc: 0.6160\n",
      "Epoch 194/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1680 - acc: 0.5578 - val_loss: 1.0198 - val_acc: 0.6163\n",
      "Epoch 195/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1656 - acc: 0.5601 - val_loss: 1.0099 - val_acc: 0.6170\n",
      "Epoch 196/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1671 - acc: 0.5539 - val_loss: 1.0068 - val_acc: 0.6216\n",
      "Epoch 197/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1611 - acc: 0.5588 - val_loss: 1.0059 - val_acc: 0.6180\n",
      "Epoch 198/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1612 - acc: 0.5591 - val_loss: 0.9968 - val_acc: 0.6220\n",
      "Epoch 199/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1595 - acc: 0.5596 - val_loss: 1.0132 - val_acc: 0.6229\n",
      "Epoch 200/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1645 - acc: 0.5589 - val_loss: 0.9981 - val_acc: 0.6250\n",
      "Epoch 201/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1584 - acc: 0.5606 - val_loss: 0.9891 - val_acc: 0.6257\n",
      "Epoch 202/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1613 - acc: 0.5570 - val_loss: 1.0121 - val_acc: 0.6142\n",
      "Epoch 203/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1614 - acc: 0.5582 - val_loss: 1.0036 - val_acc: 0.6201\n",
      "Epoch 204/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1655 - acc: 0.5561 - val_loss: 0.9997 - val_acc: 0.6220\n",
      "Epoch 205/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1603 - acc: 0.5602 - val_loss: 1.0181 - val_acc: 0.6087\n",
      "Epoch 206/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1632 - acc: 0.5576 - val_loss: 0.9916 - val_acc: 0.6244\n",
      "Epoch 207/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1559 - acc: 0.5591 - val_loss: 1.0061 - val_acc: 0.6225\n",
      "Epoch 208/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1625 - acc: 0.5574 - val_loss: 1.0059 - val_acc: 0.6193\n",
      "Epoch 209/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1606 - acc: 0.5639 - val_loss: 1.0010 - val_acc: 0.6241\n",
      "Epoch 210/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1642 - acc: 0.5601 - val_loss: 1.0074 - val_acc: 0.6177\n",
      "Epoch 211/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1588 - acc: 0.5618 - val_loss: 1.0105 - val_acc: 0.6167\n",
      "Epoch 212/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1627 - acc: 0.5593 - val_loss: 1.0170 - val_acc: 0.6113\n",
      "Epoch 213/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1609 - acc: 0.5594 - val_loss: 1.0009 - val_acc: 0.6222\n",
      "Epoch 214/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1637 - acc: 0.5636 - val_loss: 1.0279 - val_acc: 0.6137\n",
      "Epoch 215/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1591 - acc: 0.5578 - val_loss: 1.0080 - val_acc: 0.6160\n",
      "Epoch 216/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1559 - acc: 0.5614 - val_loss: 0.9964 - val_acc: 0.6193\n",
      "Epoch 217/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1672 - acc: 0.5575 - val_loss: 0.9988 - val_acc: 0.6233\n",
      "Epoch 218/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1589 - acc: 0.5605 - val_loss: 0.9973 - val_acc: 0.6259\n",
      "Epoch 219/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1611 - acc: 0.5626 - val_loss: 1.0011 - val_acc: 0.6257\n",
      "Epoch 220/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1580 - acc: 0.5626 - val_loss: 1.0070 - val_acc: 0.6227\n",
      "Epoch 221/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1514 - acc: 0.5631 - val_loss: 1.0091 - val_acc: 0.6167\n",
      "Epoch 222/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1656 - acc: 0.5579 - val_loss: 1.0005 - val_acc: 0.6247\n",
      "Epoch 223/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1561 - acc: 0.5629 - val_loss: 1.0249 - val_acc: 0.6158\n",
      "Epoch 224/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1584 - acc: 0.5588 - val_loss: 1.0208 - val_acc: 0.6137\n",
      "Epoch 225/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1610 - acc: 0.5593 - val_loss: 1.0036 - val_acc: 0.6223\n",
      "Epoch 226/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1615 - acc: 0.5560 - val_loss: 1.0088 - val_acc: 0.6199\n",
      "Epoch 227/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1572 - acc: 0.5614 - val_loss: 0.9955 - val_acc: 0.6257\n",
      "Epoch 228/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1597 - acc: 0.5616 - val_loss: 1.0080 - val_acc: 0.6223\n",
      "Epoch 229/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1555 - acc: 0.5635 - val_loss: 0.9939 - val_acc: 0.6297\n",
      "Epoch 230/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1597 - acc: 0.5596 - val_loss: 0.9954 - val_acc: 0.6279\n",
      "Epoch 231/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1531 - acc: 0.5593 - val_loss: 0.9863 - val_acc: 0.6279\n",
      "Epoch 232/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1572 - acc: 0.5619 - val_loss: 0.9990 - val_acc: 0.6254\n",
      "Epoch 233/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1577 - acc: 0.5624 - val_loss: 1.0267 - val_acc: 0.6128\n",
      "Epoch 234/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1579 - acc: 0.5636 - val_loss: 0.9959 - val_acc: 0.6234\n",
      "Epoch 235/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1582 - acc: 0.5606 - val_loss: 0.9939 - val_acc: 0.6301\n",
      "Epoch 236/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1537 - acc: 0.5610 - val_loss: 1.0058 - val_acc: 0.6212\n",
      "Epoch 237/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1544 - acc: 0.5645 - val_loss: 0.9946 - val_acc: 0.6258\n",
      "Epoch 238/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1583 - acc: 0.5620 - val_loss: 0.9954 - val_acc: 0.6234\n",
      "Epoch 239/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1571 - acc: 0.5596 - val_loss: 1.0034 - val_acc: 0.6197\n",
      "Epoch 240/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1505 - acc: 0.5632 - val_loss: 1.0045 - val_acc: 0.6204\n",
      "Epoch 241/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1582 - acc: 0.5590 - val_loss: 0.9938 - val_acc: 0.6278\n",
      "Epoch 242/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1585 - acc: 0.5604 - val_loss: 0.9997 - val_acc: 0.6254\n",
      "Epoch 243/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1575 - acc: 0.5626 - val_loss: 0.9982 - val_acc: 0.6259\n",
      "Epoch 244/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1516 - acc: 0.5631 - val_loss: 0.9950 - val_acc: 0.6279\n",
      "Epoch 245/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1553 - acc: 0.5598 - val_loss: 1.0123 - val_acc: 0.6135\n",
      "Epoch 246/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1504 - acc: 0.5655 - val_loss: 0.9981 - val_acc: 0.6205\n",
      "Epoch 247/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1519 - acc: 0.5605 - val_loss: 1.0048 - val_acc: 0.6163\n",
      "Epoch 248/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1492 - acc: 0.5654 - val_loss: 1.0039 - val_acc: 0.6241\n",
      "Epoch 249/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1549 - acc: 0.5623 - val_loss: 1.0051 - val_acc: 0.6184\n",
      "Epoch 250/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1508 - acc: 0.5628 - val_loss: 0.9913 - val_acc: 0.6273\n",
      "Epoch 251/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1526 - acc: 0.5648 - val_loss: 0.9927 - val_acc: 0.6244\n",
      "Epoch 252/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1498 - acc: 0.5659 - val_loss: 1.0097 - val_acc: 0.6169\n",
      "Epoch 253/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1522 - acc: 0.5616 - val_loss: 1.0231 - val_acc: 0.6115\n",
      "Epoch 254/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1516 - acc: 0.5636 - val_loss: 1.0020 - val_acc: 0.6226\n",
      "Epoch 255/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1516 - acc: 0.5639 - val_loss: 1.0179 - val_acc: 0.6187\n",
      "Epoch 256/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1491 - acc: 0.5662 - val_loss: 0.9964 - val_acc: 0.6240\n",
      "Epoch 257/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1581 - acc: 0.5600 - val_loss: 0.9803 - val_acc: 0.6337\n",
      "Epoch 258/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1492 - acc: 0.5644 - val_loss: 0.9907 - val_acc: 0.6271\n",
      "Epoch 259/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1448 - acc: 0.5662 - val_loss: 0.9998 - val_acc: 0.6220\n",
      "Epoch 260/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1476 - acc: 0.5641 - val_loss: 1.0194 - val_acc: 0.6177\n",
      "Epoch 261/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1527 - acc: 0.5658 - val_loss: 0.9968 - val_acc: 0.6233\n",
      "Epoch 262/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1460 - acc: 0.5650 - val_loss: 0.9824 - val_acc: 0.6311\n",
      "Epoch 263/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1476 - acc: 0.5635 - val_loss: 1.0062 - val_acc: 0.6211\n",
      "Epoch 264/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1518 - acc: 0.5644 - val_loss: 0.9880 - val_acc: 0.6271\n",
      "Epoch 265/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1530 - acc: 0.5630 - val_loss: 0.9911 - val_acc: 0.6241\n",
      "Epoch 266/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1431 - acc: 0.5675 - val_loss: 0.9912 - val_acc: 0.6266\n",
      "Epoch 267/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1495 - acc: 0.5645 - val_loss: 0.9957 - val_acc: 0.6301\n",
      "Epoch 268/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1445 - acc: 0.5663 - val_loss: 0.9927 - val_acc: 0.6226\n",
      "Epoch 269/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1489 - acc: 0.5646 - val_loss: 0.9935 - val_acc: 0.6262\n",
      "Epoch 270/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1508 - acc: 0.5612 - val_loss: 0.9932 - val_acc: 0.6287\n",
      "Epoch 271/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1523 - acc: 0.5636 - val_loss: 1.0067 - val_acc: 0.6205\n",
      "Epoch 272/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1391 - acc: 0.5660 - val_loss: 1.0049 - val_acc: 0.6222\n",
      "Epoch 273/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1600 - acc: 0.5589 - val_loss: 0.9830 - val_acc: 0.6307\n",
      "Epoch 274/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1325 - acc: 0.5700 - val_loss: 0.9931 - val_acc: 0.6262\n",
      "Epoch 275/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1524 - acc: 0.5616 - val_loss: 0.9953 - val_acc: 0.6254\n",
      "Epoch 276/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1510 - acc: 0.5659 - val_loss: 0.9953 - val_acc: 0.6243\n",
      "Epoch 277/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1524 - acc: 0.5622 - val_loss: 0.9882 - val_acc: 0.6272\n",
      "Epoch 278/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1473 - acc: 0.5646 - val_loss: 0.9882 - val_acc: 0.6289\n",
      "Epoch 279/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1498 - acc: 0.5643 - val_loss: 0.9911 - val_acc: 0.6252\n",
      "Epoch 280/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1516 - acc: 0.5689 - val_loss: 0.9887 - val_acc: 0.6252\n",
      "Epoch 281/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1406 - acc: 0.5656 - val_loss: 0.9918 - val_acc: 0.6199\n",
      "Epoch 282/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1536 - acc: 0.5632 - val_loss: 1.0079 - val_acc: 0.6137\n",
      "Epoch 283/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1511 - acc: 0.5643 - val_loss: 0.9895 - val_acc: 0.6261\n",
      "Epoch 284/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1521 - acc: 0.5621 - val_loss: 0.9822 - val_acc: 0.6276\n",
      "Epoch 285/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1510 - acc: 0.5632 - val_loss: 0.9911 - val_acc: 0.6269\n",
      "Epoch 286/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1486 - acc: 0.5645 - val_loss: 0.9834 - val_acc: 0.6289\n",
      "Epoch 287/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1490 - acc: 0.5625 - val_loss: 1.0097 - val_acc: 0.6181\n",
      "Epoch 288/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1500 - acc: 0.5644 - val_loss: 0.9893 - val_acc: 0.6311\n",
      "Epoch 289/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1444 - acc: 0.5641 - val_loss: 0.9899 - val_acc: 0.6247\n",
      "Epoch 290/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1464 - acc: 0.5627 - val_loss: 0.9874 - val_acc: 0.6298\n",
      "Epoch 291/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1492 - acc: 0.5663 - val_loss: 0.9812 - val_acc: 0.6321\n",
      "Epoch 292/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1511 - acc: 0.5633 - val_loss: 0.9849 - val_acc: 0.6330\n",
      "Epoch 293/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1476 - acc: 0.5636 - val_loss: 0.9899 - val_acc: 0.6272\n",
      "Epoch 294/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1515 - acc: 0.5647 - val_loss: 1.0019 - val_acc: 0.6202\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1456 - acc: 0.5677 - val_loss: 1.0135 - val_acc: 0.6191\n",
      "Epoch 296/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1459 - acc: 0.5627 - val_loss: 1.0001 - val_acc: 0.6220\n",
      "Epoch 297/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1495 - acc: 0.5626 - val_loss: 0.9936 - val_acc: 0.6262\n",
      "Epoch 298/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1424 - acc: 0.5657 - val_loss: 1.0004 - val_acc: 0.6212\n",
      "Epoch 299/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1428 - acc: 0.5677 - val_loss: 1.0023 - val_acc: 0.6211\n",
      "Epoch 300/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1514 - acc: 0.5627 - val_loss: 0.9898 - val_acc: 0.6278\n",
      "Epoch 301/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1445 - acc: 0.5649 - val_loss: 0.9873 - val_acc: 0.6251\n",
      "Epoch 302/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1459 - acc: 0.5629 - val_loss: 0.9845 - val_acc: 0.6276\n",
      "Epoch 303/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1493 - acc: 0.5637 - val_loss: 1.0164 - val_acc: 0.6140\n",
      "Epoch 304/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1411 - acc: 0.5669 - val_loss: 0.9816 - val_acc: 0.6255\n",
      "Epoch 305/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1419 - acc: 0.5665 - val_loss: 1.0043 - val_acc: 0.6209\n",
      "Epoch 306/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1443 - acc: 0.5679 - val_loss: 1.0007 - val_acc: 0.6236\n",
      "Epoch 307/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1458 - acc: 0.5638 - val_loss: 1.0018 - val_acc: 0.6177\n",
      "Epoch 308/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1443 - acc: 0.5667 - val_loss: 1.0471 - val_acc: 0.6027\n",
      "Epoch 309/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1526 - acc: 0.5592 - val_loss: 0.9927 - val_acc: 0.6264\n",
      "Epoch 310/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1432 - acc: 0.5688 - val_loss: 1.0048 - val_acc: 0.6199\n",
      "Epoch 311/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1578 - acc: 0.5637 - val_loss: 1.0016 - val_acc: 0.6241\n",
      "Epoch 312/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1402 - acc: 0.5685 - val_loss: 0.9910 - val_acc: 0.6243\n",
      "Epoch 313/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1368 - acc: 0.5665 - val_loss: 0.9779 - val_acc: 0.6303\n",
      "Epoch 314/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1500 - acc: 0.5654 - val_loss: 1.0079 - val_acc: 0.6244\n",
      "Epoch 315/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1399 - acc: 0.5665 - val_loss: 0.9947 - val_acc: 0.6244\n",
      "Epoch 316/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1365 - acc: 0.5698 - val_loss: 0.9803 - val_acc: 0.6332\n",
      "Epoch 317/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1464 - acc: 0.5634 - val_loss: 0.9863 - val_acc: 0.6247\n",
      "Epoch 318/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1451 - acc: 0.5668 - val_loss: 0.9774 - val_acc: 0.6325\n",
      "Epoch 319/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1422 - acc: 0.5692 - val_loss: 0.9786 - val_acc: 0.6298\n",
      "Epoch 320/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1428 - acc: 0.5698 - val_loss: 1.0008 - val_acc: 0.6219\n",
      "Epoch 321/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1472 - acc: 0.5659 - val_loss: 0.9862 - val_acc: 0.6303\n",
      "Epoch 322/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1426 - acc: 0.5671 - val_loss: 0.9927 - val_acc: 0.6301\n",
      "Epoch 323/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1484 - acc: 0.5629 - val_loss: 0.9923 - val_acc: 0.6222\n",
      "Epoch 324/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1424 - acc: 0.5672 - val_loss: 0.9888 - val_acc: 0.6290\n",
      "Epoch 325/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1425 - acc: 0.5666 - val_loss: 0.9885 - val_acc: 0.6321\n",
      "Epoch 326/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1482 - acc: 0.5649 - val_loss: 0.9949 - val_acc: 0.6261\n",
      "Epoch 327/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1400 - acc: 0.5687 - val_loss: 0.9905 - val_acc: 0.6237\n",
      "Epoch 328/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1379 - acc: 0.5706 - val_loss: 0.9868 - val_acc: 0.6308\n",
      "Epoch 329/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1461 - acc: 0.5652 - val_loss: 0.9768 - val_acc: 0.6350\n",
      "Epoch 330/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1435 - acc: 0.5662 - val_loss: 0.9969 - val_acc: 0.6244\n",
      "Epoch 331/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1393 - acc: 0.5678 - val_loss: 0.9808 - val_acc: 0.6305\n",
      "Epoch 332/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1485 - acc: 0.5652 - val_loss: 0.9791 - val_acc: 0.6279\n",
      "Epoch 333/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1408 - acc: 0.5693 - val_loss: 0.9902 - val_acc: 0.6247\n",
      "Epoch 334/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1405 - acc: 0.5664 - val_loss: 0.9936 - val_acc: 0.6247\n",
      "Epoch 335/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1378 - acc: 0.5707 - val_loss: 0.9939 - val_acc: 0.6239\n",
      "Epoch 336/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1381 - acc: 0.5676 - val_loss: 0.9863 - val_acc: 0.6266\n",
      "Epoch 337/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1312 - acc: 0.5712 - val_loss: 0.9871 - val_acc: 0.6271\n",
      "Epoch 338/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1378 - acc: 0.5707 - val_loss: 0.9776 - val_acc: 0.6304\n",
      "Epoch 339/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1412 - acc: 0.5672 - val_loss: 0.9855 - val_acc: 0.6282\n",
      "Epoch 340/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1334 - acc: 0.5676 - val_loss: 0.9863 - val_acc: 0.6254\n",
      "Epoch 341/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1495 - acc: 0.5609 - val_loss: 0.9812 - val_acc: 0.6315\n",
      "Epoch 342/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1398 - acc: 0.5659 - val_loss: 0.9978 - val_acc: 0.6218\n",
      "Epoch 343/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1355 - acc: 0.5694 - val_loss: 0.9842 - val_acc: 0.6268\n",
      "Epoch 344/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1458 - acc: 0.5665 - val_loss: 0.9842 - val_acc: 0.6271\n",
      "Epoch 345/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1417 - acc: 0.5644 - val_loss: 0.9932 - val_acc: 0.6265\n",
      "Epoch 346/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1429 - acc: 0.5659 - val_loss: 1.0042 - val_acc: 0.6174\n",
      "Epoch 347/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1401 - acc: 0.5693 - val_loss: 0.9818 - val_acc: 0.6304\n",
      "Epoch 348/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1348 - acc: 0.5652 - val_loss: 0.9893 - val_acc: 0.6301\n",
      "Epoch 349/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1321 - acc: 0.5698 - val_loss: 0.9862 - val_acc: 0.6318\n",
      "Epoch 350/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1371 - acc: 0.5688 - val_loss: 0.9902 - val_acc: 0.6259\n",
      "Epoch 351/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1365 - acc: 0.5670 - val_loss: 0.9952 - val_acc: 0.6254\n",
      "Epoch 352/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1452 - acc: 0.5642 - val_loss: 0.9789 - val_acc: 0.6319\n",
      "Epoch 353/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1377 - acc: 0.5700 - val_loss: 0.9763 - val_acc: 0.6339\n",
      "Epoch 354/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1410 - acc: 0.5648 - val_loss: 0.9919 - val_acc: 0.6297\n",
      "Epoch 355/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1350 - acc: 0.5684 - val_loss: 0.9822 - val_acc: 0.6330\n",
      "Epoch 356/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1374 - acc: 0.5659 - val_loss: 0.9924 - val_acc: 0.6236\n",
      "Epoch 357/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1355 - acc: 0.5690 - val_loss: 0.9825 - val_acc: 0.6301\n",
      "Epoch 358/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1409 - acc: 0.5672 - val_loss: 0.9707 - val_acc: 0.6379\n",
      "Epoch 359/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1394 - acc: 0.5683 - val_loss: 0.9804 - val_acc: 0.6305\n",
      "Epoch 360/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1364 - acc: 0.5660 - val_loss: 0.9894 - val_acc: 0.6291\n",
      "Epoch 361/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1302 - acc: 0.5726 - val_loss: 0.9854 - val_acc: 0.6276\n",
      "Epoch 362/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1351 - acc: 0.5728 - val_loss: 0.9744 - val_acc: 0.6336\n",
      "Epoch 363/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1333 - acc: 0.5705 - val_loss: 0.9749 - val_acc: 0.6294\n",
      "Epoch 364/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1405 - acc: 0.5677 - val_loss: 0.9962 - val_acc: 0.6250\n",
      "Epoch 365/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1459 - acc: 0.5676 - val_loss: 1.0019 - val_acc: 0.6205\n",
      "Epoch 366/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1362 - acc: 0.5702 - val_loss: 0.9858 - val_acc: 0.6289\n",
      "Epoch 367/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1383 - acc: 0.5684 - val_loss: 0.9769 - val_acc: 0.6330\n",
      "Epoch 368/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1266 - acc: 0.5714 - val_loss: 0.9681 - val_acc: 0.6372\n",
      "Epoch 369/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1372 - acc: 0.5689 - val_loss: 0.9762 - val_acc: 0.6315\n",
      "Epoch 370/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1356 - acc: 0.5688 - val_loss: 0.9811 - val_acc: 0.6298\n",
      "Epoch 371/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1355 - acc: 0.5718 - val_loss: 0.9776 - val_acc: 0.6284\n",
      "Epoch 372/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1276 - acc: 0.5731 - val_loss: 0.9779 - val_acc: 0.6311\n",
      "Epoch 373/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1390 - acc: 0.5696 - val_loss: 0.9755 - val_acc: 0.6361\n",
      "Epoch 374/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1315 - acc: 0.5690 - val_loss: 0.9898 - val_acc: 0.6265\n",
      "Epoch 375/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1323 - acc: 0.5716 - val_loss: 0.9931 - val_acc: 0.6230\n",
      "Epoch 376/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1347 - acc: 0.5695 - val_loss: 0.9751 - val_acc: 0.6318\n",
      "Epoch 377/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1373 - acc: 0.5724 - val_loss: 0.9798 - val_acc: 0.6276\n",
      "Epoch 378/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1472 - acc: 0.5653 - val_loss: 0.9961 - val_acc: 0.6227\n",
      "Epoch 379/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1254 - acc: 0.5709 - val_loss: 0.9752 - val_acc: 0.6342\n",
      "Epoch 380/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1422 - acc: 0.5662 - val_loss: 0.9887 - val_acc: 0.6269\n",
      "Epoch 381/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1416 - acc: 0.5697 - val_loss: 0.9778 - val_acc: 0.6322\n",
      "Epoch 382/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1321 - acc: 0.5706 - val_loss: 0.9784 - val_acc: 0.6307\n",
      "Epoch 383/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1423 - acc: 0.5665 - val_loss: 1.0106 - val_acc: 0.6159\n",
      "Epoch 384/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1347 - acc: 0.5691 - val_loss: 1.0013 - val_acc: 0.6205\n",
      "Epoch 385/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1353 - acc: 0.5683 - val_loss: 0.9958 - val_acc: 0.6234\n",
      "Epoch 386/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1385 - acc: 0.5691 - val_loss: 0.9744 - val_acc: 0.6351\n",
      "Epoch 387/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1363 - acc: 0.5696 - val_loss: 0.9851 - val_acc: 0.6265\n",
      "Epoch 388/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1366 - acc: 0.5700 - val_loss: 0.9909 - val_acc: 0.6258\n",
      "Epoch 389/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1351 - acc: 0.5664 - val_loss: 0.9758 - val_acc: 0.6357\n",
      "Epoch 390/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1323 - acc: 0.5742 - val_loss: 0.9796 - val_acc: 0.6297\n",
      "Epoch 391/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1343 - acc: 0.5738 - val_loss: 0.9947 - val_acc: 0.6250\n",
      "Epoch 392/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1339 - acc: 0.5705 - val_loss: 0.9800 - val_acc: 0.6310\n",
      "Epoch 393/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1323 - acc: 0.5677 - val_loss: 0.9831 - val_acc: 0.6322\n",
      "Epoch 394/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1337 - acc: 0.5683 - val_loss: 0.9862 - val_acc: 0.6259\n",
      "Epoch 395/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1262 - acc: 0.5726 - val_loss: 1.0149 - val_acc: 0.6117\n",
      "Epoch 396/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1419 - acc: 0.5674 - val_loss: 0.9722 - val_acc: 0.6385\n",
      "Epoch 397/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1265 - acc: 0.5757 - val_loss: 0.9752 - val_acc: 0.6308\n",
      "Epoch 398/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1275 - acc: 0.5714 - val_loss: 0.9856 - val_acc: 0.6321\n",
      "Epoch 399/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1353 - acc: 0.5722 - val_loss: 0.9855 - val_acc: 0.6278\n",
      "Epoch 400/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1386 - acc: 0.5661 - val_loss: 0.9824 - val_acc: 0.6291\n",
      "Epoch 401/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1297 - acc: 0.5727 - val_loss: 0.9845 - val_acc: 0.6262\n",
      "Epoch 402/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1351 - acc: 0.5683 - val_loss: 0.9872 - val_acc: 0.6237\n",
      "Epoch 403/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1317 - acc: 0.5709 - val_loss: 0.9854 - val_acc: 0.6236\n",
      "Epoch 404/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1252 - acc: 0.5741 - val_loss: 0.9856 - val_acc: 0.6286\n",
      "Epoch 405/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1373 - acc: 0.5708 - val_loss: 0.9916 - val_acc: 0.6266\n",
      "Epoch 406/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1382 - acc: 0.5693 - val_loss: 0.9713 - val_acc: 0.6328\n",
      "Epoch 407/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1277 - acc: 0.5715 - val_loss: 0.9832 - val_acc: 0.6273\n",
      "Epoch 408/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1346 - acc: 0.5677 - val_loss: 0.9948 - val_acc: 0.6271\n",
      "Epoch 409/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1381 - acc: 0.5680 - val_loss: 0.9890 - val_acc: 0.6234\n",
      "Epoch 410/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1329 - acc: 0.5684 - val_loss: 0.9880 - val_acc: 0.6300\n",
      "Epoch 411/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1308 - acc: 0.5701 - val_loss: 0.9888 - val_acc: 0.6279\n",
      "Epoch 412/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1276 - acc: 0.5728 - val_loss: 0.9819 - val_acc: 0.6275\n",
      "Epoch 413/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1305 - acc: 0.5743 - val_loss: 0.9817 - val_acc: 0.6257\n",
      "Epoch 414/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1251 - acc: 0.5718 - val_loss: 0.9797 - val_acc: 0.6323\n",
      "Epoch 415/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1344 - acc: 0.5676 - val_loss: 0.9776 - val_acc: 0.6290\n",
      "Epoch 416/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1330 - acc: 0.5679 - val_loss: 0.9966 - val_acc: 0.6198\n",
      "Epoch 417/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1371 - acc: 0.5683 - val_loss: 0.9749 - val_acc: 0.6310\n",
      "Epoch 418/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1337 - acc: 0.5706 - val_loss: 0.9781 - val_acc: 0.6297\n",
      "Epoch 419/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1403 - acc: 0.5651 - val_loss: 0.9852 - val_acc: 0.6278\n",
      "Epoch 420/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1250 - acc: 0.5737 - val_loss: 0.9811 - val_acc: 0.6328\n",
      "Epoch 421/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1259 - acc: 0.5723 - val_loss: 0.9873 - val_acc: 0.6282\n",
      "Epoch 422/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1381 - acc: 0.5688 - val_loss: 0.9977 - val_acc: 0.6180\n",
      "Epoch 423/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1300 - acc: 0.5702 - val_loss: 0.9769 - val_acc: 0.6330\n",
      "Epoch 424/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1253 - acc: 0.5732 - val_loss: 0.9822 - val_acc: 0.6311\n",
      "Epoch 425/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1251 - acc: 0.5753 - val_loss: 0.9884 - val_acc: 0.6236\n",
      "Epoch 426/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1403 - acc: 0.5668 - val_loss: 0.9757 - val_acc: 0.6329\n",
      "Epoch 427/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1269 - acc: 0.5721 - val_loss: 0.9802 - val_acc: 0.6308\n",
      "Epoch 428/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1345 - acc: 0.5733 - val_loss: 0.9878 - val_acc: 0.6254\n",
      "Epoch 429/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1248 - acc: 0.5737 - val_loss: 0.9877 - val_acc: 0.6225\n",
      "Epoch 430/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1276 - acc: 0.5739 - val_loss: 0.9760 - val_acc: 0.6326\n",
      "Epoch 431/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1256 - acc: 0.5714 - val_loss: 0.9726 - val_acc: 0.6286\n",
      "Epoch 432/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1351 - acc: 0.5694 - val_loss: 0.9877 - val_acc: 0.6244\n",
      "Epoch 433/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1254 - acc: 0.5730 - val_loss: 1.0050 - val_acc: 0.6174\n",
      "Epoch 434/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1288 - acc: 0.5745 - val_loss: 0.9757 - val_acc: 0.6322\n",
      "Epoch 435/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1329 - acc: 0.5746 - val_loss: 0.9851 - val_acc: 0.6307\n",
      "Epoch 436/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1260 - acc: 0.5674 - val_loss: 0.9832 - val_acc: 0.6301\n",
      "Epoch 437/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1280 - acc: 0.5717 - val_loss: 0.9764 - val_acc: 0.6307\n",
      "Epoch 438/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1261 - acc: 0.5718 - val_loss: 0.9759 - val_acc: 0.6340\n",
      "Epoch 439/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1331 - acc: 0.5717 - val_loss: 0.9828 - val_acc: 0.6318\n",
      "Epoch 440/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1393 - acc: 0.5699 - val_loss: 0.9727 - val_acc: 0.6347\n",
      "Epoch 441/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1340 - acc: 0.5707 - val_loss: 0.9858 - val_acc: 0.6291\n",
      "Epoch 442/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1240 - acc: 0.5741 - val_loss: 0.9731 - val_acc: 0.6367\n",
      "Epoch 443/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1336 - acc: 0.5756 - val_loss: 0.9830 - val_acc: 0.6310\n",
      "Epoch 444/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1222 - acc: 0.5763 - val_loss: 0.9812 - val_acc: 0.6297\n",
      "Epoch 445/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1310 - acc: 0.5700 - val_loss: 0.9871 - val_acc: 0.6266\n",
      "Epoch 446/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1270 - acc: 0.5728 - val_loss: 0.9664 - val_acc: 0.6392\n",
      "Epoch 447/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1330 - acc: 0.5723 - val_loss: 0.9690 - val_acc: 0.6368\n",
      "Epoch 448/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1149 - acc: 0.5791 - val_loss: 0.9793 - val_acc: 0.6326\n",
      "Epoch 449/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1264 - acc: 0.5729 - val_loss: 0.9766 - val_acc: 0.6305\n",
      "Epoch 450/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1366 - acc: 0.5692 - val_loss: 0.9737 - val_acc: 0.6319\n",
      "Epoch 451/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1237 - acc: 0.5727 - val_loss: 0.9766 - val_acc: 0.6307\n",
      "Epoch 452/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1284 - acc: 0.5695 - val_loss: 0.9835 - val_acc: 0.6310\n",
      "Epoch 453/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1226 - acc: 0.5744 - val_loss: 0.9700 - val_acc: 0.6364\n",
      "Epoch 454/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1259 - acc: 0.5763 - val_loss: 0.9970 - val_acc: 0.6287\n",
      "Epoch 455/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1222 - acc: 0.5719 - val_loss: 0.9852 - val_acc: 0.6244\n",
      "Epoch 456/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1270 - acc: 0.5746 - val_loss: 0.9898 - val_acc: 0.6271\n",
      "Epoch 457/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1323 - acc: 0.5684 - val_loss: 0.9768 - val_acc: 0.6300\n",
      "Epoch 458/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1196 - acc: 0.5739 - val_loss: 0.9868 - val_acc: 0.6266\n",
      "Epoch 459/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1170 - acc: 0.5759 - val_loss: 0.9800 - val_acc: 0.6290\n",
      "Epoch 460/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1292 - acc: 0.5688 - val_loss: 0.9691 - val_acc: 0.6300\n",
      "Epoch 461/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1226 - acc: 0.5706 - val_loss: 0.9844 - val_acc: 0.6314\n",
      "Epoch 462/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1335 - acc: 0.5701 - val_loss: 0.9834 - val_acc: 0.6304\n",
      "Epoch 463/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1299 - acc: 0.5715 - val_loss: 0.9729 - val_acc: 0.6330\n",
      "Epoch 464/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1224 - acc: 0.5759 - val_loss: 0.9892 - val_acc: 0.6244\n",
      "Epoch 465/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1308 - acc: 0.5687 - val_loss: 0.9667 - val_acc: 0.6353\n",
      "Epoch 466/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1233 - acc: 0.5715 - val_loss: 0.9768 - val_acc: 0.6308\n",
      "Epoch 467/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1293 - acc: 0.5724 - val_loss: 0.9816 - val_acc: 0.6326\n",
      "Epoch 468/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1251 - acc: 0.5731 - val_loss: 0.9697 - val_acc: 0.6362\n",
      "Epoch 469/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1268 - acc: 0.5717 - val_loss: 0.9799 - val_acc: 0.6326\n",
      "Epoch 470/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1285 - acc: 0.5712 - val_loss: 0.9770 - val_acc: 0.6284\n",
      "Epoch 471/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1214 - acc: 0.5750 - val_loss: 0.9784 - val_acc: 0.6353\n",
      "Epoch 472/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1300 - acc: 0.5727 - val_loss: 0.9652 - val_acc: 0.6357\n",
      "Epoch 473/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1272 - acc: 0.5707 - val_loss: 0.9890 - val_acc: 0.6283\n",
      "Epoch 474/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1213 - acc: 0.5749 - val_loss: 0.9760 - val_acc: 0.6323\n",
      "Epoch 475/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1249 - acc: 0.5738 - val_loss: 0.9865 - val_acc: 0.6307\n",
      "Epoch 476/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1267 - acc: 0.5743 - val_loss: 0.9794 - val_acc: 0.6329\n",
      "Epoch 477/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1346 - acc: 0.5713 - val_loss: 0.9730 - val_acc: 0.6332\n",
      "Epoch 478/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1262 - acc: 0.5736 - val_loss: 0.9798 - val_acc: 0.6255\n",
      "Epoch 479/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1281 - acc: 0.5735 - val_loss: 0.9966 - val_acc: 0.6179\n",
      "Epoch 480/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1206 - acc: 0.5729 - val_loss: 0.9841 - val_acc: 0.6310\n",
      "Epoch 481/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1273 - acc: 0.5714 - val_loss: 0.9845 - val_acc: 0.6329\n",
      "Epoch 482/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1305 - acc: 0.5696 - val_loss: 0.9712 - val_acc: 0.6318\n",
      "Epoch 483/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1196 - acc: 0.5763 - val_loss: 0.9956 - val_acc: 0.6269\n",
      "Epoch 484/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1293 - acc: 0.5741 - val_loss: 0.9712 - val_acc: 0.6346\n",
      "Epoch 485/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1227 - acc: 0.5741 - val_loss: 0.9671 - val_acc: 0.6372\n",
      "Epoch 486/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1198 - acc: 0.5773 - val_loss: 0.9876 - val_acc: 0.6251\n",
      "Epoch 487/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1229 - acc: 0.5718 - val_loss: 0.9745 - val_acc: 0.6311\n",
      "Epoch 488/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1268 - acc: 0.5734 - val_loss: 0.9830 - val_acc: 0.6287\n",
      "Epoch 489/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1263 - acc: 0.5726 - val_loss: 0.9683 - val_acc: 0.6346\n",
      "Epoch 490/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1161 - acc: 0.5774 - val_loss: 0.9916 - val_acc: 0.6223\n",
      "Epoch 491/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1276 - acc: 0.5750 - val_loss: 0.9671 - val_acc: 0.6362\n",
      "Epoch 492/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1210 - acc: 0.5755 - val_loss: 0.9680 - val_acc: 0.6357\n",
      "Epoch 493/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1215 - acc: 0.5770 - val_loss: 0.9722 - val_acc: 0.6350\n",
      "Epoch 494/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1275 - acc: 0.5750 - val_loss: 0.9758 - val_acc: 0.6333\n",
      "Epoch 495/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1297 - acc: 0.5758 - val_loss: 0.9789 - val_acc: 0.6335\n",
      "Epoch 496/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1208 - acc: 0.5749 - val_loss: 0.9685 - val_acc: 0.6343\n",
      "Epoch 497/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1268 - acc: 0.5705 - val_loss: 0.9821 - val_acc: 0.6283\n",
      "Epoch 498/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1183 - acc: 0.5741 - val_loss: 0.9733 - val_acc: 0.6335\n",
      "Epoch 499/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1286 - acc: 0.5740 - val_loss: 0.9754 - val_acc: 0.6308\n",
      "Epoch 500/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1271 - acc: 0.5746 - val_loss: 0.9745 - val_acc: 0.6362\n",
      "Epoch 501/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1205 - acc: 0.5777 - val_loss: 0.9762 - val_acc: 0.6308\n",
      "Epoch 502/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1265 - acc: 0.5722 - val_loss: 0.9831 - val_acc: 0.6255\n",
      "Epoch 503/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1185 - acc: 0.5733 - val_loss: 0.9865 - val_acc: 0.6328\n",
      "Epoch 504/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1251 - acc: 0.5760 - val_loss: 0.9629 - val_acc: 0.6344\n",
      "Epoch 505/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1217 - acc: 0.5749 - val_loss: 0.9877 - val_acc: 0.6279\n",
      "Epoch 506/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1256 - acc: 0.5718 - val_loss: 1.0005 - val_acc: 0.6218\n",
      "Epoch 507/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1146 - acc: 0.5794 - val_loss: 0.9726 - val_acc: 0.6328\n",
      "Epoch 508/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1218 - acc: 0.5741 - val_loss: 0.9695 - val_acc: 0.6361\n",
      "Epoch 509/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1209 - acc: 0.5742 - val_loss: 0.9845 - val_acc: 0.6271\n",
      "Epoch 510/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1281 - acc: 0.5699 - val_loss: 0.9887 - val_acc: 0.6230\n",
      "Epoch 511/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1217 - acc: 0.5742 - val_loss: 0.9689 - val_acc: 0.6364\n",
      "Epoch 512/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1304 - acc: 0.5687 - val_loss: 0.9761 - val_acc: 0.6321\n",
      "Epoch 513/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1210 - acc: 0.5747 - val_loss: 0.9839 - val_acc: 0.6325loss: 1.1\n",
      "Epoch 514/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1267 - acc: 0.5739 - val_loss: 0.9808 - val_acc: 0.6339\n",
      "Epoch 515/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1208 - acc: 0.5740 - val_loss: 0.9902 - val_acc: 0.6284\n",
      "Epoch 516/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1220 - acc: 0.5741 - val_loss: 0.9789 - val_acc: 0.6303\n",
      "Epoch 517/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1227 - acc: 0.5726 - val_loss: 0.9779 - val_acc: 0.6318oss\n",
      "Epoch 518/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1158 - acc: 0.5790 - val_loss: 0.9607 - val_acc: 0.6356\n",
      "Epoch 519/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1265 - acc: 0.5721 - val_loss: 0.9759 - val_acc: 0.6321\n",
      "Epoch 520/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1215 - acc: 0.5736 - val_loss: 0.9829 - val_acc: 0.6301\n",
      "Epoch 521/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1230 - acc: 0.5781 - val_loss: 0.9641 - val_acc: 0.6378\n",
      "Epoch 522/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1252 - acc: 0.5714 - val_loss: 0.9747 - val_acc: 0.6329\n",
      "Epoch 523/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1136 - acc: 0.5773 - val_loss: 0.9743 - val_acc: 0.6351\n",
      "Epoch 524/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1188 - acc: 0.5725 - val_loss: 0.9731 - val_acc: 0.6357\n",
      "Epoch 525/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1233 - acc: 0.5756 - val_loss: 0.9734 - val_acc: 0.6337\n",
      "Epoch 526/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1305 - acc: 0.5699 - val_loss: 0.9804 - val_acc: 0.6286\n",
      "Epoch 527/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1224 - acc: 0.5732 - val_loss: 0.9707 - val_acc: 0.6378\n",
      "Epoch 528/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1206 - acc: 0.5770 - val_loss: 0.9923 - val_acc: 0.6248\n",
      "Epoch 529/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1282 - acc: 0.5709 - val_loss: 0.9778 - val_acc: 0.6300\n",
      "Epoch 530/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1205 - acc: 0.5770 - val_loss: 0.9758 - val_acc: 0.6336\n",
      "Epoch 531/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1205 - acc: 0.5765 - val_loss: 0.9750 - val_acc: 0.6314\n",
      "Epoch 532/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1230 - acc: 0.5744 - val_loss: 0.9705 - val_acc: 0.6321\n",
      "Epoch 533/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1188 - acc: 0.5742 - val_loss: 0.9699 - val_acc: 0.6353\n",
      "Epoch 534/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1172 - acc: 0.5743 - val_loss: 0.9891 - val_acc: 0.6278\n",
      "Epoch 535/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1261 - acc: 0.5737 - val_loss: 0.9680 - val_acc: 0.6362\n",
      "Epoch 536/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1201 - acc: 0.5753 - val_loss: 0.9658 - val_acc: 0.6371\n",
      "Epoch 537/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1233 - acc: 0.5746 - val_loss: 0.9923 - val_acc: 0.6273\n",
      "Epoch 538/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1236 - acc: 0.5762 - val_loss: 0.9713 - val_acc: 0.6350\n",
      "Epoch 539/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1221 - acc: 0.5751 - val_loss: 0.9796 - val_acc: 0.6318\n",
      "Epoch 540/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1197 - acc: 0.5780 - val_loss: 0.9768 - val_acc: 0.6326\n",
      "Epoch 541/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1187 - acc: 0.5717 - val_loss: 0.9861 - val_acc: 0.6269\n",
      "Epoch 542/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1228 - acc: 0.5758 - val_loss: 0.9799 - val_acc: 0.6280\n",
      "Epoch 543/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1185 - acc: 0.5741 - val_loss: 0.9742 - val_acc: 0.6342\n",
      "Epoch 544/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1150 - acc: 0.5776 - val_loss: 0.9687 - val_acc: 0.6356\n",
      "Epoch 545/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1228 - acc: 0.5713 - val_loss: 0.9936 - val_acc: 0.6225\n",
      "Epoch 546/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1191 - acc: 0.5790 - val_loss: 0.9713 - val_acc: 0.6372\n",
      "Epoch 547/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1244 - acc: 0.5740 - val_loss: 0.9590 - val_acc: 0.6397\n",
      "Epoch 548/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1157 - acc: 0.5762 - val_loss: 0.9767 - val_acc: 0.6319\n",
      "Epoch 549/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1215 - acc: 0.5741 - val_loss: 0.9817 - val_acc: 0.6275\n",
      "Epoch 550/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1141 - acc: 0.5781 - val_loss: 0.9886 - val_acc: 0.6252\n",
      "Epoch 551/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1164 - acc: 0.5750 - val_loss: 0.9679 - val_acc: 0.6386\n",
      "Epoch 552/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1181 - acc: 0.5736 - val_loss: 0.9775 - val_acc: 0.6272\n",
      "Epoch 553/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1118 - acc: 0.5822 - val_loss: 0.9707 - val_acc: 0.6353\n",
      "Epoch 554/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1142 - acc: 0.5762 - val_loss: 0.9723 - val_acc: 0.6307\n",
      "Epoch 555/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1232 - acc: 0.5749 - val_loss: 0.9742 - val_acc: 0.6374\n",
      "Epoch 556/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1280 - acc: 0.5742 - val_loss: 0.9802 - val_acc: 0.6287\n",
      "Epoch 557/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1174 - acc: 0.5737 - val_loss: 0.9758 - val_acc: 0.6339\n",
      "Epoch 558/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1117 - acc: 0.5797 - val_loss: 0.9544 - val_acc: 0.6442\n",
      "Epoch 559/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1204 - acc: 0.5752 - val_loss: 0.9746 - val_acc: 0.6351\n",
      "Epoch 560/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1199 - acc: 0.5714 - val_loss: 0.9744 - val_acc: 0.6367\n",
      "Epoch 561/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1141 - acc: 0.5777 - val_loss: 0.9751 - val_acc: 0.6357\n",
      "Epoch 562/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1157 - acc: 0.5763 - val_loss: 0.9901 - val_acc: 0.6250\n",
      "Epoch 563/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1141 - acc: 0.5733 - val_loss: 0.9785 - val_acc: 0.6361\n",
      "Epoch 564/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1199 - acc: 0.5818 - val_loss: 0.9773 - val_acc: 0.6298\n",
      "Epoch 565/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1273 - acc: 0.5747 - val_loss: 0.9677 - val_acc: 0.6358\n",
      "Epoch 566/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1126 - acc: 0.5788 - val_loss: 0.9783 - val_acc: 0.6349\n",
      "Epoch 567/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1197 - acc: 0.5784 - val_loss: 0.9691 - val_acc: 0.6375\n",
      "Epoch 568/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1192 - acc: 0.5755 - val_loss: 0.9686 - val_acc: 0.6374\n",
      "Epoch 569/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1215 - acc: 0.5755 - val_loss: 0.9824 - val_acc: 0.6298\n",
      "Epoch 570/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1175 - acc: 0.5755 - val_loss: 0.9739 - val_acc: 0.6335\n",
      "Epoch 571/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1219 - acc: 0.5747 - val_loss: 0.9565 - val_acc: 0.6432\n",
      "Epoch 572/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1306 - acc: 0.5704 - val_loss: 0.9759 - val_acc: 0.6368\n",
      "Epoch 573/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1130 - acc: 0.5777 - val_loss: 0.9839 - val_acc: 0.6303\n",
      "Epoch 574/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1009 - acc: 0.5798 - val_loss: 0.9733 - val_acc: 0.6336\n",
      "Epoch 575/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1202 - acc: 0.5760 - val_loss: 0.9837 - val_acc: 0.6311\n",
      "Epoch 576/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1190 - acc: 0.5747 - val_loss: 0.9706 - val_acc: 0.6357\n",
      "Epoch 577/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1152 - acc: 0.5782 - val_loss: 0.9720 - val_acc: 0.6353\n",
      "Epoch 578/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1143 - acc: 0.5761 - val_loss: 0.9757 - val_acc: 0.6311\n",
      "Epoch 579/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1116 - acc: 0.5766 - val_loss: 0.9813 - val_acc: 0.6278\n",
      "Epoch 580/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1183 - acc: 0.5749 - val_loss: 0.9694 - val_acc: 0.6372\n",
      "Epoch 581/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1185 - acc: 0.5777 - val_loss: 0.9629 - val_acc: 0.6372\n",
      "Epoch 582/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1187 - acc: 0.5773 - val_loss: 0.9620 - val_acc: 0.6357\n",
      "Epoch 583/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1152 - acc: 0.5788 - val_loss: 0.9738 - val_acc: 0.6337\n",
      "Epoch 584/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1189 - acc: 0.5779 - val_loss: 0.9804 - val_acc: 0.6276\n",
      "Epoch 585/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1113 - acc: 0.5793 - val_loss: 0.9688 - val_acc: 0.6350\n",
      "Epoch 586/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1127 - acc: 0.5759 - val_loss: 0.9697 - val_acc: 0.6372\n",
      "Epoch 587/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1243 - acc: 0.5727 - val_loss: 0.9816 - val_acc: 0.6290\n",
      "Epoch 588/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1262 - acc: 0.5737 - val_loss: 0.9712 - val_acc: 0.6328\n",
      "Epoch 589/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1127 - acc: 0.5762 - val_loss: 0.9855 - val_acc: 0.6278\n",
      "Epoch 590/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1223 - acc: 0.5752 - val_loss: 0.9839 - val_acc: 0.6315\n",
      "Epoch 591/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1188 - acc: 0.5767 - val_loss: 0.9764 - val_acc: 0.6305\n",
      "Epoch 592/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1160 - acc: 0.5762 - val_loss: 0.9751 - val_acc: 0.6340\n",
      "Epoch 593/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1179 - acc: 0.5776 - val_loss: 0.9850 - val_acc: 0.6257\n",
      "Epoch 594/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1096 - acc: 0.5812 - val_loss: 0.9686 - val_acc: 0.6343\n",
      "Epoch 595/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1236 - acc: 0.5746 - val_loss: 0.9740 - val_acc: 0.6354\n",
      "Epoch 596/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1176 - acc: 0.5768 - val_loss: 0.9824 - val_acc: 0.6337\n",
      "Epoch 597/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1156 - acc: 0.5742 - val_loss: 0.9929 - val_acc: 0.6236\n",
      "Epoch 598/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1163 - acc: 0.5806 - val_loss: 0.9795 - val_acc: 0.6282\n",
      "Epoch 599/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1243 - acc: 0.5725 - val_loss: 0.9689 - val_acc: 0.6325\n",
      "Epoch 600/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1209 - acc: 0.5749 - val_loss: 0.9725 - val_acc: 0.6368\n",
      "Epoch 601/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1139 - acc: 0.5786 - val_loss: 0.9749 - val_acc: 0.6347\n",
      "Epoch 602/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1207 - acc: 0.5730 - val_loss: 0.9849 - val_acc: 0.6257\n",
      "Epoch 603/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1156 - acc: 0.5796 - val_loss: 0.9761 - val_acc: 0.6293\n",
      "Epoch 604/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1190 - acc: 0.5745 - val_loss: 0.9936 - val_acc: 0.6261\n",
      "Epoch 605/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1157 - acc: 0.5790 - val_loss: 0.9682 - val_acc: 0.6335\n",
      "Epoch 606/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1122 - acc: 0.5799 - val_loss: 0.9629 - val_acc: 0.6388\n",
      "Epoch 607/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1188 - acc: 0.5778 - val_loss: 0.9694 - val_acc: 0.6325\n",
      "Epoch 608/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1218 - acc: 0.5729 - val_loss: 0.9728 - val_acc: 0.6319\n",
      "Epoch 609/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1193 - acc: 0.5780 - val_loss: 0.9604 - val_acc: 0.6388\n",
      "Epoch 610/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1124 - acc: 0.5802 - val_loss: 0.9667 - val_acc: 0.6365\n",
      "Epoch 611/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1199 - acc: 0.5744 - val_loss: 0.9678 - val_acc: 0.6388\n",
      "Epoch 612/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1159 - acc: 0.5787 - val_loss: 0.9785 - val_acc: 0.6318\n",
      "Epoch 613/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1131 - acc: 0.5803 - val_loss: 0.9917 - val_acc: 0.6268\n",
      "Epoch 614/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1205 - acc: 0.5792 - val_loss: 0.9717 - val_acc: 0.6343\n",
      "Epoch 615/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1134 - acc: 0.5770 - val_loss: 0.9767 - val_acc: 0.6342\n",
      "Epoch 616/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1136 - acc: 0.5803 - val_loss: 0.9758 - val_acc: 0.6307\n",
      "Epoch 617/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1117 - acc: 0.5774 - val_loss: 0.9664 - val_acc: 0.6358\n",
      "Epoch 618/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1197 - acc: 0.5760 - val_loss: 0.9759 - val_acc: 0.6336\n",
      "Epoch 619/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1134 - acc: 0.5765 - val_loss: 0.9680 - val_acc: 0.6332\n",
      "Epoch 620/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1176 - acc: 0.5760 - val_loss: 0.9678 - val_acc: 0.6372\n",
      "Epoch 621/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1137 - acc: 0.5792 - val_loss: 0.9748 - val_acc: 0.6323127 - acc: \n",
      "Epoch 622/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1139 - acc: 0.5813 - val_loss: 0.9819 - val_acc: 0.6322\n",
      "Epoch 623/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1127 - acc: 0.5789 - val_loss: 0.9747 - val_acc: 0.6342\n",
      "Epoch 624/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1248 - acc: 0.5731 - val_loss: 0.9715 - val_acc: 0.6291\n",
      "Epoch 625/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1102 - acc: 0.5785 - val_loss: 0.9539 - val_acc: 0.6436\n",
      "Epoch 626/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1060 - acc: 0.5808 - val_loss: 0.9719 - val_acc: 0.6379\n",
      "Epoch 627/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1185 - acc: 0.5768 - val_loss: 0.9769 - val_acc: 0.6315\n",
      "Epoch 628/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1034 - acc: 0.5849 - val_loss: 0.9806 - val_acc: 0.6275\n",
      "Epoch 629/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1166 - acc: 0.5773 - val_loss: 0.9702 - val_acc: 0.6305\n",
      "Epoch 630/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1179 - acc: 0.5747 - val_loss: 0.9786 - val_acc: 0.6342\n",
      "Epoch 631/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1078 - acc: 0.5825 - val_loss: 0.9732 - val_acc: 0.6335\n",
      "Epoch 632/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1111 - acc: 0.5767 - val_loss: 0.9594 - val_acc: 0.6397\n",
      "Epoch 633/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1195 - acc: 0.5763 - val_loss: 0.9728 - val_acc: 0.6337\n",
      "Epoch 634/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1130 - acc: 0.5783 - val_loss: 0.9668 - val_acc: 0.6365\n",
      "Epoch 635/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1075 - acc: 0.5797 - val_loss: 0.9797 - val_acc: 0.6296\n",
      "Epoch 636/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1185 - acc: 0.5766 - val_loss: 0.9883 - val_acc: 0.6208\n",
      "Epoch 637/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1117 - acc: 0.5741 - val_loss: 0.9708 - val_acc: 0.6321\n",
      "Epoch 638/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1152 - acc: 0.5779 - val_loss: 0.9661 - val_acc: 0.6357\n",
      "Epoch 639/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1137 - acc: 0.5759 - val_loss: 0.9664 - val_acc: 0.6374\n",
      "Epoch 640/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1169 - acc: 0.5796 - val_loss: 0.9662 - val_acc: 0.6356\n",
      "Epoch 641/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1091 - acc: 0.5807 - val_loss: 0.9695 - val_acc: 0.6332\n",
      "Epoch 642/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1177 - acc: 0.5768 - val_loss: 0.9845 - val_acc: 0.6259\n",
      "Epoch 643/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1135 - acc: 0.5771 - val_loss: 0.9894 - val_acc: 0.6229 loss: 1.1139 \n",
      "Epoch 644/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1119 - acc: 0.5796 - val_loss: 0.9860 - val_acc: 0.6290\n",
      "Epoch 645/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1148 - acc: 0.5761 - val_loss: 0.9717 - val_acc: 0.6312\n",
      "Epoch 646/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1138 - acc: 0.5784 - val_loss: 0.9714 - val_acc: 0.6319\n",
      "Epoch 647/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1085 - acc: 0.5813 - val_loss: 0.9648 - val_acc: 0.6392\n",
      "Epoch 648/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1146 - acc: 0.5788 - val_loss: 0.9690 - val_acc: 0.6354\n",
      "Epoch 649/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1165 - acc: 0.5774 - val_loss: 0.9736 - val_acc: 0.6356\n",
      "Epoch 650/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1098 - acc: 0.5819 - val_loss: 0.9594 - val_acc: 0.6354\n",
      "Epoch 651/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1186 - acc: 0.5773 - val_loss: 0.9688 - val_acc: 0.6328\n",
      "Epoch 652/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1206 - acc: 0.5749 - val_loss: 0.9755 - val_acc: 0.6322\n",
      "Epoch 653/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1157 - acc: 0.5777 - val_loss: 0.9697 - val_acc: 0.6329\n",
      "Epoch 654/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1077 - acc: 0.5832 - val_loss: 0.9834 - val_acc: 0.6265\n",
      "Epoch 655/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1155 - acc: 0.5786 - val_loss: 0.9680 - val_acc: 0.6361\n",
      "Epoch 656/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1073 - acc: 0.5818 - val_loss: 0.9799 - val_acc: 0.6360\n",
      "Epoch 657/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1118 - acc: 0.5808 - val_loss: 0.9667 - val_acc: 0.6395\n",
      "Epoch 658/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1144 - acc: 0.5790 - val_loss: 1.0019 - val_acc: 0.6173\n",
      "Epoch 659/1000\n",
      "897/897 [==============================] - 21s 23ms/step - loss: 1.1130 - acc: 0.5785 - val_loss: 0.9621 - val_acc: 0.6376\n",
      "Epoch 660/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1208 - acc: 0.5749 - val_loss: 0.9644 - val_acc: 0.6367\n",
      "Epoch 661/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1089 - acc: 0.5770 - val_loss: 0.9643 - val_acc: 0.6388\n",
      "Epoch 662/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1109 - acc: 0.5815 - val_loss: 0.9623 - val_acc: 0.6369\n",
      "Epoch 663/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1165 - acc: 0.5774 - val_loss: 0.9780 - val_acc: 0.6337\n",
      "Epoch 664/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1052 - acc: 0.5822 - val_loss: 0.9705 - val_acc: 0.6325\n",
      "Epoch 665/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1165 - acc: 0.5759 - val_loss: 0.9739 - val_acc: 0.6349\n",
      "Epoch 666/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1074 - acc: 0.5783 - val_loss: 0.9801 - val_acc: 0.6328\n",
      "Epoch 667/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1046 - acc: 0.5829 - val_loss: 0.9624 - val_acc: 0.6367\n",
      "Epoch 668/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1171 - acc: 0.5789 - val_loss: 0.9659 - val_acc: 0.6402\n",
      "Epoch 669/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1171 - acc: 0.5785 - val_loss: 0.9660 - val_acc: 0.6388\n",
      "Epoch 670/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1082 - acc: 0.5758 - val_loss: 0.9872 - val_acc: 0.6243\n",
      "Epoch 671/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1118 - acc: 0.5812 - val_loss: 0.9750 - val_acc: 0.6322\n",
      "Epoch 672/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1178 - acc: 0.5815 - val_loss: 0.9713 - val_acc: 0.6372\n",
      "Epoch 673/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1185 - acc: 0.5782 - val_loss: 0.9755 - val_acc: 0.6317\n",
      "Epoch 674/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1119 - acc: 0.5786 - val_loss: 0.9736 - val_acc: 0.6339\n",
      "Epoch 675/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1078 - acc: 0.5788 - val_loss: 0.9770 - val_acc: 0.6315\n",
      "Epoch 676/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1114 - acc: 0.5792 - val_loss: 0.9857 - val_acc: 0.6287\n",
      "Epoch 677/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1131 - acc: 0.5804 - val_loss: 0.9772 - val_acc: 0.6271\n",
      "Epoch 678/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1036 - acc: 0.5819 - val_loss: 0.9686 - val_acc: 0.6383\n",
      "Epoch 679/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1132 - acc: 0.5838 - val_loss: 0.9731 - val_acc: 0.6318\n",
      "Epoch 680/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1112 - acc: 0.5791 - val_loss: 0.9677 - val_acc: 0.6349\n",
      "Epoch 681/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1003 - acc: 0.5836 - val_loss: 0.9757 - val_acc: 0.6349\n",
      "Epoch 682/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1142 - acc: 0.5785 - val_loss: 0.9678 - val_acc: 0.6368\n",
      "Epoch 683/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1105 - acc: 0.5801 - val_loss: 0.9639 - val_acc: 0.6364\n",
      "Epoch 684/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1083 - acc: 0.5791 - val_loss: 0.9731 - val_acc: 0.6378\n",
      "Epoch 685/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1099 - acc: 0.5808 - val_loss: 0.9634 - val_acc: 0.6396\n",
      "Epoch 686/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1087 - acc: 0.5804 - val_loss: 0.9697 - val_acc: 0.6343\n",
      "Epoch 687/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1092 - acc: 0.5793 - val_loss: 0.9858 - val_acc: 0.6276\n",
      "Epoch 688/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1119 - acc: 0.5789 - val_loss: 0.9780 - val_acc: 0.6321\n",
      "Epoch 689/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1077 - acc: 0.5804 - val_loss: 0.9728 - val_acc: 0.6340\n",
      "Epoch 690/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1075 - acc: 0.5801 - val_loss: 0.9792 - val_acc: 0.6307\n",
      "Epoch 691/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1174 - acc: 0.5768 - val_loss: 0.9789 - val_acc: 0.6275\n",
      "Epoch 692/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1146 - acc: 0.5781 - val_loss: 0.9643 - val_acc: 0.6371\n",
      "Epoch 693/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1083 - acc: 0.5787 - val_loss: 0.9661 - val_acc: 0.6378\n",
      "Epoch 694/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1096 - acc: 0.5805 - val_loss: 0.9744 - val_acc: 0.6303\n",
      "Epoch 695/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1142 - acc: 0.5762 - val_loss: 0.9621 - val_acc: 0.6397\n",
      "Epoch 696/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1101 - acc: 0.5792 - val_loss: 0.9680 - val_acc: 0.6358\n",
      "Epoch 697/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1094 - acc: 0.5792 - val_loss: 0.9756 - val_acc: 0.6311\n",
      "Epoch 698/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1119 - acc: 0.5775 - val_loss: 0.9662 - val_acc: 0.6368\n",
      "Epoch 699/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1076 - acc: 0.5814 - val_loss: 0.9894 - val_acc: 0.6236\n",
      "Epoch 700/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1074 - acc: 0.5817 - val_loss: 0.9621 - val_acc: 0.6382\n",
      "Epoch 701/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1158 - acc: 0.5741 - val_loss: 0.9630 - val_acc: 0.6388\n",
      "Epoch 702/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1109 - acc: 0.5782 - val_loss: 0.9945 - val_acc: 0.6247\n",
      "Epoch 703/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1099 - acc: 0.5797 - val_loss: 0.9672 - val_acc: 0.6371\n",
      "Epoch 704/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1031 - acc: 0.5855 - val_loss: 0.9727 - val_acc: 0.6347\n",
      "Epoch 705/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1074 - acc: 0.5817 - val_loss: 0.9689 - val_acc: 0.6329\n",
      "Epoch 706/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1115 - acc: 0.5793 - val_loss: 0.9601 - val_acc: 0.6446\n",
      "Epoch 707/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1189 - acc: 0.5767 - val_loss: 0.9677 - val_acc: 0.6344\n",
      "Epoch 708/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1115 - acc: 0.5765 - val_loss: 0.9658 - val_acc: 0.6375\n",
      "Epoch 709/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1124 - acc: 0.5781 - val_loss: 0.9631 - val_acc: 0.6365\n",
      "Epoch 710/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1068 - acc: 0.5771 - val_loss: 0.9596 - val_acc: 0.6367\n",
      "Epoch 711/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1090 - acc: 0.5781 - val_loss: 0.9564 - val_acc: 0.6418\n",
      "Epoch 712/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1111 - acc: 0.5756 - val_loss: 0.9661 - val_acc: 0.6353\n",
      "Epoch 713/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1087 - acc: 0.5813 - val_loss: 0.9630 - val_acc: 0.6385\n",
      "Epoch 714/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1086 - acc: 0.5816 - val_loss: 0.9600 - val_acc: 0.6379\n",
      "Epoch 715/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1101 - acc: 0.5765 - val_loss: 0.9623 - val_acc: 0.6382\n",
      "Epoch 716/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1043 - acc: 0.5811 - val_loss: 0.9643 - val_acc: 0.6343\n",
      "Epoch 717/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1136 - acc: 0.5777 - val_loss: 0.9625 - val_acc: 0.6402\n",
      "Epoch 718/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1082 - acc: 0.5809 - val_loss: 0.9694 - val_acc: 0.6354\n",
      "Epoch 719/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1133 - acc: 0.5771 - val_loss: 0.9777 - val_acc: 0.6241\n",
      "Epoch 720/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1055 - acc: 0.5808 - val_loss: 0.9803 - val_acc: 0.6265\n",
      "Epoch 721/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1119 - acc: 0.5791 - val_loss: 0.9609 - val_acc: 0.6385\n",
      "Epoch 722/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1042 - acc: 0.5831 - val_loss: 0.9743 - val_acc: 0.6349\n",
      "Epoch 723/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1111 - acc: 0.5808 - val_loss: 0.9666 - val_acc: 0.6383\n",
      "Epoch 724/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1157 - acc: 0.5770 - val_loss: 0.9804 - val_acc: 0.6317\n",
      "Epoch 725/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1044 - acc: 0.5774 - val_loss: 0.9575 - val_acc: 0.6393\n",
      "Epoch 726/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1093 - acc: 0.5793 - val_loss: 0.9558 - val_acc: 0.6407\n",
      "Epoch 727/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1035 - acc: 0.5804 - val_loss: 0.9717 - val_acc: 0.6346\n",
      "Epoch 728/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1093 - acc: 0.5796 - val_loss: 0.9769 - val_acc: 0.6276\n",
      "Epoch 729/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1126 - acc: 0.5808 - val_loss: 0.9865 - val_acc: 0.6247\n",
      "Epoch 730/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1113 - acc: 0.5779 - val_loss: 0.9713 - val_acc: 0.6328\n",
      "Epoch 731/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1024 - acc: 0.5812 - val_loss: 0.9635 - val_acc: 0.6389\n",
      "Epoch 732/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1126 - acc: 0.5774 - val_loss: 0.9676 - val_acc: 0.6325\n",
      "Epoch 733/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1021 - acc: 0.5819 - val_loss: 0.9534 - val_acc: 0.6389\n",
      "Epoch 734/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1105 - acc: 0.5826 - val_loss: 0.9548 - val_acc: 0.6443\n",
      "Epoch 735/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1147 - acc: 0.5808 - val_loss: 0.9597 - val_acc: 0.6410\n",
      "Epoch 736/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1111 - acc: 0.5771 - val_loss: 0.9594 - val_acc: 0.6400\n",
      "Epoch 737/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1073 - acc: 0.5802 - val_loss: 0.9696 - val_acc: 0.6310\n",
      "Epoch 738/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1081 - acc: 0.5791 - val_loss: 0.9592 - val_acc: 0.6410\n",
      "Epoch 739/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1033 - acc: 0.5833 - val_loss: 0.9562 - val_acc: 0.6413\n",
      "Epoch 740/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1086 - acc: 0.5774 - val_loss: 0.9648 - val_acc: 0.6350\n",
      "Epoch 741/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1044 - acc: 0.5823 - val_loss: 0.9730 - val_acc: 0.6305\n",
      "Epoch 742/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1100 - acc: 0.5784 - val_loss: 0.9721 - val_acc: 0.6321\n",
      "Epoch 743/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1036 - acc: 0.5828 - val_loss: 0.9686 - val_acc: 0.6347\n",
      "Epoch 744/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1093 - acc: 0.5794 - val_loss: 0.9707 - val_acc: 0.6346\n",
      "Epoch 745/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1113 - acc: 0.5795 - val_loss: 0.9644 - val_acc: 0.6429\n",
      "Epoch 746/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1094 - acc: 0.5766 - val_loss: 0.9691 - val_acc: 0.6365\n",
      "Epoch 747/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0986 - acc: 0.5816 - val_loss: 0.9672 - val_acc: 0.6415\n",
      "Epoch 748/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1120 - acc: 0.5772 - val_loss: 0.9592 - val_acc: 0.6425\n",
      "Epoch 749/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1024 - acc: 0.5856 - val_loss: 0.9667 - val_acc: 0.6402\n",
      "Epoch 750/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1058 - acc: 0.5788 - val_loss: 0.9556 - val_acc: 0.6413\n",
      "Epoch 751/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1072 - acc: 0.5837 - val_loss: 0.9717 - val_acc: 0.6350\n",
      "Epoch 752/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1106 - acc: 0.5819 - val_loss: 0.9812 - val_acc: 0.6273\n",
      "Epoch 753/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1014 - acc: 0.5832 - val_loss: 0.9750 - val_acc: 0.6342\n",
      "Epoch 754/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1035 - acc: 0.5837 - val_loss: 0.9616 - val_acc: 0.6397\n",
      "Epoch 755/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1128 - acc: 0.5777 - val_loss: 0.9630 - val_acc: 0.6392\n",
      "Epoch 756/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1102 - acc: 0.5820 - val_loss: 0.9650 - val_acc: 0.6395\n",
      "Epoch 757/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1040 - acc: 0.5824 - val_loss: 0.9852 - val_acc: 0.6301\n",
      "Epoch 758/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1077 - acc: 0.5771 - val_loss: 0.9734 - val_acc: 0.6304\n",
      "Epoch 759/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1069 - acc: 0.5794 - val_loss: 0.9633 - val_acc: 0.6396\n",
      "Epoch 760/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1073 - acc: 0.5823 - val_loss: 0.9701 - val_acc: 0.6343\n",
      "Epoch 761/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1140 - acc: 0.5773 - val_loss: 0.9594 - val_acc: 0.6368\n",
      "Epoch 762/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1091 - acc: 0.5790 - val_loss: 0.9815 - val_acc: 0.6269\n",
      "Epoch 763/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1082 - acc: 0.5787 - val_loss: 0.9724 - val_acc: 0.6357\n",
      "Epoch 764/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1043 - acc: 0.5807 - val_loss: 0.9863 - val_acc: 0.6257\n",
      "Epoch 765/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1097 - acc: 0.5792 - val_loss: 0.9664 - val_acc: 0.6375\n",
      "Epoch 766/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1030 - acc: 0.5809 - val_loss: 0.9593 - val_acc: 0.6381\n",
      "Epoch 767/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1144 - acc: 0.5799 - val_loss: 0.9718 - val_acc: 0.6314\n",
      "Epoch 768/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1015 - acc: 0.5817 - val_loss: 0.9553 - val_acc: 0.6375\n",
      "Epoch 769/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1108 - acc: 0.5770 - val_loss: 0.9696 - val_acc: 0.6336\n",
      "Epoch 770/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1080 - acc: 0.5816 - val_loss: 0.9518 - val_acc: 0.6460\n",
      "Epoch 771/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1058 - acc: 0.5787 - val_loss: 0.9621 - val_acc: 0.6351\n",
      "Epoch 772/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1058 - acc: 0.5823 - val_loss: 0.9695 - val_acc: 0.6364\n",
      "Epoch 773/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0978 - acc: 0.5837 - val_loss: 0.9668 - val_acc: 0.6388\n",
      "Epoch 774/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1089 - acc: 0.5814 - val_loss: 0.9614 - val_acc: 0.6399\n",
      "Epoch 775/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1032 - acc: 0.5821 - val_loss: 0.9738 - val_acc: 0.6346\n",
      "Epoch 776/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1091 - acc: 0.5812 - val_loss: 0.9764 - val_acc: 0.6315\n",
      "Epoch 777/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1095 - acc: 0.5775 - val_loss: 0.9661 - val_acc: 0.6371\n",
      "Epoch 778/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1037 - acc: 0.5817 - val_loss: 0.9810 - val_acc: 0.6305\n",
      "Epoch 779/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1052 - acc: 0.5805 - val_loss: 0.9628 - val_acc: 0.6339\n",
      "Epoch 780/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1051 - acc: 0.5809 - val_loss: 0.9679 - val_acc: 0.6362\n",
      "Epoch 781/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1167 - acc: 0.5824 - val_loss: 0.9633 - val_acc: 0.6404\n",
      "Epoch 782/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1048 - acc: 0.5809 - val_loss: 0.9694 - val_acc: 0.6332\n",
      "Epoch 783/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1072 - acc: 0.5803 - val_loss: 0.9639 - val_acc: 0.6408\n",
      "Epoch 784/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1049 - acc: 0.5808 - val_loss: 0.9756 - val_acc: 0.6346\n",
      "Epoch 785/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1003 - acc: 0.5821 - val_loss: 0.9648 - val_acc: 0.6378\n",
      "Epoch 786/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1075 - acc: 0.5823 - val_loss: 0.9783 - val_acc: 0.6300\n",
      "Epoch 787/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1058 - acc: 0.5829 - val_loss: 0.9760 - val_acc: 0.6326\n",
      "Epoch 788/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1058 - acc: 0.5809 - val_loss: 0.9673 - val_acc: 0.6385\n",
      "Epoch 789/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1067 - acc: 0.5815 - val_loss: 0.9760 - val_acc: 0.6300\n",
      "Epoch 790/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1102 - acc: 0.5792 - val_loss: 0.9667 - val_acc: 0.6357\n",
      "Epoch 791/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1033 - acc: 0.5815 - val_loss: 0.9571 - val_acc: 0.6434\n",
      "Epoch 792/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1081 - acc: 0.5807 - val_loss: 0.9551 - val_acc: 0.6464\n",
      "Epoch 793/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1109 - acc: 0.5780 - val_loss: 0.9600 - val_acc: 0.6414\n",
      "Epoch 794/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1078 - acc: 0.5796 - val_loss: 0.9658 - val_acc: 0.6381\n",
      "Epoch 795/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1089 - acc: 0.5795 - val_loss: 0.9696 - val_acc: 0.6367\n",
      "Epoch 796/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1039 - acc: 0.5820 - val_loss: 0.9602 - val_acc: 0.6424\n",
      "Epoch 797/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1079 - acc: 0.5818 - val_loss: 0.9796 - val_acc: 0.6305\n",
      "Epoch 798/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1061 - acc: 0.5813 - val_loss: 0.9610 - val_acc: 0.6374\n",
      "Epoch 799/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1048 - acc: 0.5791 - val_loss: 0.9634 - val_acc: 0.6410\n",
      "Epoch 800/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1070 - acc: 0.5806 - val_loss: 0.9746 - val_acc: 0.6393\n",
      "Epoch 801/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1025 - acc: 0.5802 - val_loss: 0.9715 - val_acc: 0.6358\n",
      "Epoch 802/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1116 - acc: 0.5780 - val_loss: 0.9782 - val_acc: 0.6335\n",
      "Epoch 803/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1109 - acc: 0.5790 - val_loss: 0.9627 - val_acc: 0.6432\n",
      "Epoch 804/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1043 - acc: 0.5837 - val_loss: 0.9661 - val_acc: 0.6403\n",
      "Epoch 805/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1029 - acc: 0.5826 - val_loss: 0.9721 - val_acc: 0.6343\n",
      "Epoch 806/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1140 - acc: 0.5749 - val_loss: 0.9637 - val_acc: 0.6364\n",
      "Epoch 807/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1016 - acc: 0.5825 - val_loss: 0.9538 - val_acc: 0.6429\n",
      "Epoch 808/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1118 - acc: 0.5766 - val_loss: 0.9664 - val_acc: 0.6367\n",
      "Epoch 809/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1017 - acc: 0.5852 - val_loss: 0.9802 - val_acc: 0.6296\n",
      "Epoch 810/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1065 - acc: 0.5816 - val_loss: 0.9553 - val_acc: 0.6431\n",
      "Epoch 811/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1082 - acc: 0.5763 - val_loss: 0.9730 - val_acc: 0.6321\n",
      "Epoch 812/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1037 - acc: 0.5783 - val_loss: 0.9690 - val_acc: 0.6365\n",
      "Epoch 813/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1078 - acc: 0.5801 - val_loss: 0.9587 - val_acc: 0.6410\n",
      "Epoch 814/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1053 - acc: 0.5823 - val_loss: 0.9678 - val_acc: 0.6353\n",
      "Epoch 815/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1019 - acc: 0.5800 - val_loss: 0.9592 - val_acc: 0.6432\n",
      "Epoch 816/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1030 - acc: 0.5799 - val_loss: 0.9642 - val_acc: 0.6374\n",
      "Epoch 817/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1075 - acc: 0.5819 - val_loss: 0.9651 - val_acc: 0.6393\n",
      "Epoch 818/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1051 - acc: 0.5794 - val_loss: 0.9878 - val_acc: 0.6262\n",
      "Epoch 819/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1043 - acc: 0.5844 - val_loss: 0.9663 - val_acc: 0.6390\n",
      "Epoch 820/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1021 - acc: 0.5803 - val_loss: 0.9837 - val_acc: 0.6276\n",
      "Epoch 821/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1035 - acc: 0.5805 - val_loss: 0.9722 - val_acc: 0.6362\n",
      "Epoch 822/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1003 - acc: 0.5839 - val_loss: 0.9712 - val_acc: 0.6388\n",
      "Epoch 823/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1011 - acc: 0.5864 - val_loss: 0.9594 - val_acc: 0.6468\n",
      "Epoch 824/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1084 - acc: 0.5804 - val_loss: 0.9619 - val_acc: 0.6390\n",
      "Epoch 825/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1040 - acc: 0.5805 - val_loss: 0.9690 - val_acc: 0.6417\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1095 - acc: 0.5789 - val_loss: 0.9610 - val_acc: 0.6390\n",
      "Epoch 827/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0973 - acc: 0.5817 - val_loss: 0.9583 - val_acc: 0.6431\n",
      "Epoch 828/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1099 - acc: 0.5806 - val_loss: 0.9589 - val_acc: 0.6383\n",
      "Epoch 829/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0997 - acc: 0.5845 - val_loss: 0.9586 - val_acc: 0.6443\n",
      "Epoch 830/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1071 - acc: 0.5816 - val_loss: 0.9671 - val_acc: 0.6376\n",
      "Epoch 831/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1024 - acc: 0.5805 - val_loss: 0.9577 - val_acc: 0.6404\n",
      "Epoch 832/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1044 - acc: 0.5831 - val_loss: 0.9666 - val_acc: 0.6393\n",
      "Epoch 833/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1062 - acc: 0.5828 - val_loss: 0.9535 - val_acc: 0.6436\n",
      "Epoch 834/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1018 - acc: 0.5820 - val_loss: 0.9789 - val_acc: 0.6343\n",
      "Epoch 835/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1032 - acc: 0.5815 - val_loss: 0.9800 - val_acc: 0.6294\n",
      "Epoch 836/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1093 - acc: 0.5788 - val_loss: 0.9643 - val_acc: 0.6383\n",
      "Epoch 837/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1029 - acc: 0.5837 - val_loss: 0.9636 - val_acc: 0.6395\n",
      "Epoch 838/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1041 - acc: 0.5817 - val_loss: 0.9465 - val_acc: 0.6452\n",
      "Epoch 839/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1051 - acc: 0.5799 - val_loss: 0.9787 - val_acc: 0.6308\n",
      "Epoch 840/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1114 - acc: 0.5791 - val_loss: 0.9601 - val_acc: 0.6408\n",
      "Epoch 841/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1072 - acc: 0.5791 - val_loss: 0.9764 - val_acc: 0.6336\n",
      "Epoch 842/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1064 - acc: 0.5804 - val_loss: 0.9715 - val_acc: 0.6343\n",
      "Epoch 843/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1005 - acc: 0.5853 - val_loss: 0.9635 - val_acc: 0.6386\n",
      "Epoch 844/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1053 - acc: 0.5813 - val_loss: 0.9703 - val_acc: 0.6336\n",
      "Epoch 845/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1049 - acc: 0.5796 - val_loss: 0.9660 - val_acc: 0.6385\n",
      "Epoch 846/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0981 - acc: 0.5824 - val_loss: 0.9569 - val_acc: 0.6415\n",
      "Epoch 847/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1066 - acc: 0.5793 - val_loss: 0.9560 - val_acc: 0.6452\n",
      "Epoch 848/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1101 - acc: 0.5811 - val_loss: 0.9587 - val_acc: 0.6471\n",
      "Epoch 849/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0982 - acc: 0.5855 - val_loss: 0.9535 - val_acc: 0.6443\n",
      "Epoch 850/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.0997 - acc: 0.5815 - val_loss: 0.9824 - val_acc: 0.6300\n",
      "Epoch 851/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1027 - acc: 0.5839 - val_loss: 0.9652 - val_acc: 0.6393\n",
      "Epoch 852/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1046 - acc: 0.5837 - val_loss: 0.9594 - val_acc: 0.6428\n",
      "Epoch 853/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1072 - acc: 0.5811 - val_loss: 0.9684 - val_acc: 0.6371\n",
      "Epoch 854/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1057 - acc: 0.5796 - val_loss: 0.9760 - val_acc: 0.6354\n",
      "Epoch 855/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0991 - acc: 0.5855 - val_loss: 0.9514 - val_acc: 0.6477\n",
      "Epoch 856/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1016 - acc: 0.5843 - val_loss: 0.9623 - val_acc: 0.6406\n",
      "Epoch 857/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0998 - acc: 0.5850 - val_loss: 0.9662 - val_acc: 0.6395\n",
      "Epoch 858/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1030 - acc: 0.5824 - val_loss: 0.9729 - val_acc: 0.6344\n",
      "Epoch 859/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0988 - acc: 0.5836 - val_loss: 0.9525 - val_acc: 0.6435\n",
      "Epoch 860/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1065 - acc: 0.5827 - val_loss: 0.9668 - val_acc: 0.6393\n",
      "Epoch 861/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1028 - acc: 0.5845 - val_loss: 0.9558 - val_acc: 0.6392\n",
      "Epoch 862/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1007 - acc: 0.5816 - val_loss: 0.9602 - val_acc: 0.6408\n",
      "Epoch 863/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1034 - acc: 0.5835 - val_loss: 0.9737 - val_acc: 0.6376\n",
      "Epoch 864/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1020 - acc: 0.5842 - val_loss: 0.9707 - val_acc: 0.6358\n",
      "Epoch 865/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1042 - acc: 0.5816 - val_loss: 0.9675 - val_acc: 0.6365\n",
      "Epoch 866/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0973 - acc: 0.5855 - val_loss: 0.9590 - val_acc: 0.6422\n",
      "Epoch 867/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1025 - acc: 0.5856 - val_loss: 0.9835 - val_acc: 0.6301\n",
      "Epoch 868/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1059 - acc: 0.5818 - val_loss: 0.9619 - val_acc: 0.6415\n",
      "Epoch 869/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1019 - acc: 0.5835 - val_loss: 0.9614 - val_acc: 0.6354\n",
      "Epoch 870/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0968 - acc: 0.5832 - val_loss: 0.9577 - val_acc: 0.6399\n",
      "Epoch 871/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0981 - acc: 0.5858 - val_loss: 0.9654 - val_acc: 0.6392\n",
      "Epoch 872/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1007 - acc: 0.5860 - val_loss: 0.9712 - val_acc: 0.6330\n",
      "Epoch 873/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1058 - acc: 0.5780 - val_loss: 0.9610 - val_acc: 0.6404\n",
      "Epoch 874/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0964 - acc: 0.5845 - val_loss: 0.9825 - val_acc: 0.6322\n",
      "Epoch 875/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1053 - acc: 0.5823 - val_loss: 0.9602 - val_acc: 0.6424\n",
      "Epoch 876/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1087 - acc: 0.5793 - val_loss: 0.9680 - val_acc: 0.6371\n",
      "Epoch 877/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1013 - acc: 0.5824 - val_loss: 0.9751 - val_acc: 0.6335\n",
      "Epoch 878/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0980 - acc: 0.5829 - val_loss: 0.9694 - val_acc: 0.6375\n",
      "Epoch 879/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1001 - acc: 0.5817 - val_loss: 0.9634 - val_acc: 0.6422\n",
      "Epoch 880/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1020 - acc: 0.5827 - val_loss: 0.9660 - val_acc: 0.6371\n",
      "Epoch 881/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1025 - acc: 0.5861 - val_loss: 0.9619 - val_acc: 0.6392\n",
      "Epoch 882/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1052 - acc: 0.5829 - val_loss: 0.9664 - val_acc: 0.6375\n",
      "Epoch 883/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1031 - acc: 0.5802 - val_loss: 0.9869 - val_acc: 0.6296\n",
      "Epoch 884/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0982 - acc: 0.5845 - val_loss: 0.9759 - val_acc: 0.6308\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1047 - acc: 0.5833 - val_loss: 0.9498 - val_acc: 0.6505\n",
      "Epoch 886/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1042 - acc: 0.5798 - val_loss: 0.9614 - val_acc: 0.6392\n",
      "Epoch 887/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0927 - acc: 0.5870 - val_loss: 0.9656 - val_acc: 0.6339\n",
      "Epoch 888/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0982 - acc: 0.5870 - val_loss: 0.9640 - val_acc: 0.6383\n",
      "Epoch 889/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1043 - acc: 0.5814 - val_loss: 0.9597 - val_acc: 0.6418\n",
      "Epoch 890/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1078 - acc: 0.5795 - val_loss: 0.9752 - val_acc: 0.6343\n",
      "Epoch 891/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1040 - acc: 0.5841 - val_loss: 0.9979 - val_acc: 0.6244\n",
      "Epoch 892/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0983 - acc: 0.5862 - val_loss: 0.9632 - val_acc: 0.6399\n",
      "Epoch 893/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1068 - acc: 0.5804 - val_loss: 0.9677 - val_acc: 0.6376\n",
      "Epoch 894/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1034 - acc: 0.5832 - val_loss: 0.9736 - val_acc: 0.6364\n",
      "Epoch 895/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1001 - acc: 0.5831 - val_loss: 0.9682 - val_acc: 0.6417\n",
      "Epoch 896/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1028 - acc: 0.5841 - val_loss: 0.9515 - val_acc: 0.6471\n",
      "Epoch 897/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1010 - acc: 0.5795 - val_loss: 0.9510 - val_acc: 0.6461\n",
      "Epoch 898/1000\n",
      "897/897 [==============================] - 24s 26ms/step - loss: 1.1009 - acc: 0.5817 - val_loss: 0.9747 - val_acc: 0.6319\n",
      "Epoch 899/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0975 - acc: 0.5832 - val_loss: 0.9595 - val_acc: 0.6404\n",
      "Epoch 900/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1001 - acc: 0.5828 - val_loss: 0.9681 - val_acc: 0.6353\n",
      "Epoch 901/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0976 - acc: 0.5841 - val_loss: 0.9657 - val_acc: 0.6381\n",
      "Epoch 902/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0963 - acc: 0.5834 - val_loss: 0.9556 - val_acc: 0.6418\n",
      "Epoch 903/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1019 - acc: 0.5835 - val_loss: 0.9537 - val_acc: 0.6431\n",
      "Epoch 904/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1053 - acc: 0.5794 - val_loss: 0.9697 - val_acc: 0.6386\n",
      "Epoch 905/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1004 - acc: 0.5832 - val_loss: 0.9637 - val_acc: 0.6390\n",
      "Epoch 906/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0958 - acc: 0.5872 - val_loss: 0.9607 - val_acc: 0.6407\n",
      "Epoch 907/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0982 - acc: 0.5841 - val_loss: 0.9679 - val_acc: 0.6321\n",
      "Epoch 908/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1040 - acc: 0.5836 - val_loss: 0.9584 - val_acc: 0.6389\n",
      "Epoch 909/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1008 - acc: 0.5839 - val_loss: 0.9550 - val_acc: 0.6418\n",
      "Epoch 910/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0962 - acc: 0.5869 - val_loss: 0.9617 - val_acc: 0.6381\n",
      "Epoch 911/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0967 - acc: 0.5832 - val_loss: 0.9582 - val_acc: 0.6396\n",
      "Epoch 912/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1045 - acc: 0.5811 - val_loss: 0.9657 - val_acc: 0.6374\n",
      "Epoch 913/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1062 - acc: 0.5813 - val_loss: 0.9600 - val_acc: 0.6439\n",
      "Epoch 914/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0940 - acc: 0.5884 - val_loss: 0.9543 - val_acc: 0.6439\n",
      "Epoch 915/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1000 - acc: 0.5867 - val_loss: 0.9607 - val_acc: 0.6389\n",
      "Epoch 916/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1018 - acc: 0.5812 - val_loss: 0.9676 - val_acc: 0.6379\n",
      "Epoch 917/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1074 - acc: 0.5799 - val_loss: 0.9548 - val_acc: 0.6425\n",
      "Epoch 918/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1022 - acc: 0.5804 - val_loss: 0.9563 - val_acc: 0.6393\n",
      "Epoch 919/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0992 - acc: 0.5821 - val_loss: 0.9658 - val_acc: 0.6365\n",
      "Epoch 920/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0954 - acc: 0.5835 - val_loss: 0.9731 - val_acc: 0.6310\n",
      "Epoch 921/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0985 - acc: 0.5813 - val_loss: 0.9694 - val_acc: 0.6308\n",
      "Epoch 922/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0978 - acc: 0.5858 - val_loss: 0.9634 - val_acc: 0.6385\n",
      "Epoch 923/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.1064 - acc: 0.5839 - val_loss: 0.9562 - val_acc: 0.6395\n",
      "Epoch 924/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0982 - acc: 0.5850 - val_loss: 0.9553 - val_acc: 0.6427\n",
      "Epoch 925/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1010 - acc: 0.5843 - val_loss: 0.9656 - val_acc: 0.6364\n",
      "Epoch 926/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1024 - acc: 0.5817 - val_loss: 0.9655 - val_acc: 0.6386\n",
      "Epoch 927/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1003 - acc: 0.5825 - val_loss: 0.9652 - val_acc: 0.6369\n",
      "Epoch 928/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0980 - acc: 0.5834 - val_loss: 0.9826 - val_acc: 0.6284\n",
      "Epoch 929/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1050 - acc: 0.5806 - val_loss: 0.9620 - val_acc: 0.6395\n",
      "Epoch 930/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0950 - acc: 0.5852 - val_loss: 0.9643 - val_acc: 0.6411\n",
      "Epoch 931/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1035 - acc: 0.5863 - val_loss: 0.9607 - val_acc: 0.6407\n",
      "Epoch 932/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0969 - acc: 0.5832 - val_loss: 0.9608 - val_acc: 0.6413\n",
      "Epoch 933/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1069 - acc: 0.5811 - val_loss: 0.9720 - val_acc: 0.6356\n",
      "Epoch 934/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1055 - acc: 0.5822 - val_loss: 0.9804 - val_acc: 0.6282\n",
      "Epoch 935/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1007 - acc: 0.5839 - val_loss: 0.9534 - val_acc: 0.6443\n",
      "Epoch 936/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0974 - acc: 0.5843 - val_loss: 0.9649 - val_acc: 0.6354\n",
      "Epoch 937/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1019 - acc: 0.5821 - val_loss: 0.9595 - val_acc: 0.6406\n",
      "Epoch 938/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.0994 - acc: 0.5848 - val_loss: 0.9618 - val_acc: 0.6413\n",
      "Epoch 939/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1024 - acc: 0.5832 - val_loss: 0.9665 - val_acc: 0.6361\n",
      "Epoch 940/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1004 - acc: 0.5814 - val_loss: 0.9673 - val_acc: 0.6358\n",
      "Epoch 941/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1007 - acc: 0.5806 - val_loss: 0.9632 - val_acc: 0.6367\n",
      "Epoch 942/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0978 - acc: 0.5836 - val_loss: 0.9697 - val_acc: 0.6346\n",
      "Epoch 943/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1044 - acc: 0.5834 - val_loss: 0.9725 - val_acc: 0.6294\n",
      "Epoch 944/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1010 - acc: 0.5859 - val_loss: 0.9620 - val_acc: 0.6392\n",
      "Epoch 945/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1012 - acc: 0.5832 - val_loss: 0.9587 - val_acc: 0.6449\n",
      "Epoch 946/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0978 - acc: 0.5872 - val_loss: 0.9619 - val_acc: 0.6397\n",
      "Epoch 947/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1042 - acc: 0.5835 - val_loss: 0.9651 - val_acc: 0.6396\n",
      "Epoch 948/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0993 - acc: 0.5817 - val_loss: 0.9853 - val_acc: 0.6262\n",
      "Epoch 949/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1007 - acc: 0.5841 - val_loss: 0.9609 - val_acc: 0.6390\n",
      "Epoch 950/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1013 - acc: 0.5831 - val_loss: 0.9497 - val_acc: 0.6459\n",
      "Epoch 951/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1021 - acc: 0.5816 - val_loss: 0.9658 - val_acc: 0.6382\n",
      "Epoch 952/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0992 - acc: 0.5838 - val_loss: 0.9571 - val_acc: 0.6371\n",
      "Epoch 953/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0971 - acc: 0.5844 - val_loss: 0.9552 - val_acc: 0.6393\n",
      "Epoch 954/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0947 - acc: 0.5856 - val_loss: 0.9562 - val_acc: 0.6417\n",
      "Epoch 955/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1036 - acc: 0.5821 - val_loss: 0.9609 - val_acc: 0.6349\n",
      "Epoch 956/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0950 - acc: 0.5869 - val_loss: 0.9638 - val_acc: 0.6410\n",
      "Epoch 957/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0955 - acc: 0.5865 - val_loss: 0.9577 - val_acc: 0.6403\n",
      "Epoch 958/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1030 - acc: 0.5816 - val_loss: 0.9521 - val_acc: 0.6411\n",
      "Epoch 959/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0941 - acc: 0.5880 - val_loss: 0.9567 - val_acc: 0.6422\n",
      "Epoch 960/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0993 - acc: 0.5844 - val_loss: 0.9664 - val_acc: 0.6351\n",
      "Epoch 961/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0996 - acc: 0.5856 - val_loss: 0.9584 - val_acc: 0.6395\n",
      "Epoch 962/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1017 - acc: 0.5823 - val_loss: 0.9643 - val_acc: 0.6367\n",
      "Epoch 963/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0993 - acc: 0.5804 - val_loss: 0.9599 - val_acc: 0.6365\n",
      "Epoch 964/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1064 - acc: 0.5796 - val_loss: 0.9614 - val_acc: 0.6396\n",
      "Epoch 965/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1016 - acc: 0.5800 - val_loss: 0.9572 - val_acc: 0.6400\n",
      "Epoch 966/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0967 - acc: 0.5840 - val_loss: 0.9536 - val_acc: 0.6403\n",
      "Epoch 967/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0939 - acc: 0.5833 - val_loss: 0.9516 - val_acc: 0.6425\n",
      "Epoch 968/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0998 - acc: 0.5822 - val_loss: 0.9628 - val_acc: 0.6403\n",
      "Epoch 969/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.1058 - acc: 0.5801 - val_loss: 0.9614 - val_acc: 0.6399\n",
      "Epoch 970/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0981 - acc: 0.5850 - val_loss: 0.9593 - val_acc: 0.6429\n",
      "Epoch 971/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1058 - acc: 0.5800 - val_loss: 0.9645 - val_acc: 0.6379\n",
      "Epoch 972/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0981 - acc: 0.5843 - val_loss: 0.9720 - val_acc: 0.6319\n",
      "Epoch 973/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0983 - acc: 0.5844 - val_loss: 0.9614 - val_acc: 0.6403\n",
      "Epoch 974/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.0949 - acc: 0.5851 - val_loss: 0.9651 - val_acc: 0.6332\n",
      "Epoch 975/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1050 - acc: 0.5837 - val_loss: 0.9490 - val_acc: 0.6406\n",
      "Epoch 976/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0995 - acc: 0.5830 - val_loss: 0.9549 - val_acc: 0.6397\n",
      "Epoch 977/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0891 - acc: 0.5864 - val_loss: 0.9707 - val_acc: 0.6375\n",
      "Epoch 978/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1014 - acc: 0.5827 - val_loss: 0.9522 - val_acc: 0.6439\n",
      "Epoch 979/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0974 - acc: 0.5882 - val_loss: 0.9587 - val_acc: 0.6383\n",
      "Epoch 980/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1035 - acc: 0.5824 - val_loss: 0.9573 - val_acc: 0.6375\n",
      "Epoch 981/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0982 - acc: 0.5829 - val_loss: 0.9485 - val_acc: 0.6467\n",
      "Epoch 982/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1007 - acc: 0.5826 - val_loss: 0.9516 - val_acc: 0.6445\n",
      "Epoch 983/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1049 - acc: 0.5798 - val_loss: 0.9635 - val_acc: 0.6395\n",
      "Epoch 984/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0944 - acc: 0.5864 - val_loss: 0.9539 - val_acc: 0.6443\n",
      "Epoch 985/1000\n",
      "897/897 [==============================] - 19s 22ms/step - loss: 1.0943 - acc: 0.5857 - val_loss: 0.9524 - val_acc: 0.6420\n",
      "Epoch 986/1000\n",
      "897/897 [==============================] - 19s 21ms/step - loss: 1.1001 - acc: 0.5832 - val_loss: 0.9567 - val_acc: 0.6425\n",
      "Epoch 987/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0941 - acc: 0.5903 - val_loss: 0.9734 - val_acc: 0.6347\n",
      "Epoch 988/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0940 - acc: 0.5864 - val_loss: 0.9524 - val_acc: 0.6396\n",
      "Epoch 989/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1032 - acc: 0.5824 - val_loss: 0.9683 - val_acc: 0.6336\n",
      "Epoch 990/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1002 - acc: 0.5817 - val_loss: 0.9563 - val_acc: 0.6414\n",
      "Epoch 991/1000\n",
      "897/897 [==============================] - 20s 23ms/step - loss: 1.0958 - acc: 0.5865 - val_loss: 0.9756 - val_acc: 0.6337\n",
      "Epoch 992/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0995 - acc: 0.5833 - val_loss: 0.9531 - val_acc: 0.6468\n",
      "Epoch 993/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1001 - acc: 0.5826 - val_loss: 0.9666 - val_acc: 0.6364\n",
      "Epoch 994/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1011 - acc: 0.5820 - val_loss: 0.9538 - val_acc: 0.6397\n",
      "Epoch 995/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1066 - acc: 0.5780 - val_loss: 0.9573 - val_acc: 0.6442\n",
      "Epoch 996/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0962 - acc: 0.5866 - val_loss: 0.9588 - val_acc: 0.6390\n",
      "Epoch 997/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0959 - acc: 0.5864 - val_loss: 0.9600 - val_acc: 0.6369\n",
      "Epoch 998/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.0999 - acc: 0.5845 - val_loss: 0.9496 - val_acc: 0.6454\n",
      "Epoch 999/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1005 - acc: 0.5821 - val_loss: 0.9655 - val_acc: 0.6322\n",
      "Epoch 1000/1000\n",
      "897/897 [==============================] - 20s 22ms/step - loss: 1.1008 - acc: 0.5863 - val_loss: 0.9588 - val_acc: 0.6381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2298e1c3a20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
    "\n",
    "x_train = x_train.reshape(len(x_train),48,48,1)   #Reshape for CNN\n",
    "x_test = x_test.reshape(len(x_test),48,48,1)\n",
    "\n",
    "\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit_generator(data_generator.flow(x_train, y_train,\n",
    "                                            batch_size),\n",
    "        epochs = num_epochs,steps_per_epoch= int(len(x_train) / batch_size), \n",
    "        validation_data = (x_test,y_test),\n",
    "        validation_steps = int(len(x_test) / batch_size) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in a file\n",
    "\n",
    "model.save(\"emotion_detection_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
